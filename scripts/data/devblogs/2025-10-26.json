[
  {
    "title": "Using Chonkie",
    "date": "Fri, 24 Oct 2025 09:40:22 +0000",
    "summary": "<p>Testing Chonkie ðŸ§ª</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fvq6ccq8ftaviqeoj0b3e.png\"><img alt=\" \" height=\"426\" src=",
    "url": "https://dev.to/aairom/using-chonkie-4glg",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "A Beginner's Guide to Ollama Cloud Models",
    "date": "Sun, 19 Oct 2025 22:35:08 +0000",
    "summary": "<p>Ollama's cloud models are a new feature that allows users to run large language models without needing a powerful local GPU. These models are automatically offloaded to Ollama's cloud service, providing the same capabilities as local models while enabling the use of larger models that would typic",
    "url": "https://dev.to/coderforfun/a-beginners-guide-to-ollama-cloud-models-3lc2",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Building 100% local AI memory with cognee",
    "date": "Sat, 18 Oct 2025 09:21:55 +0000",
    "summary": "<p>If you've explored AI memory frameworks, you've probably encountered Cognee </p>\n<div class=\"ltag-github-readme-tag\">\n  <div class=\"readme-overview\">\n    <h2>\n      <img alt=\"GitHub logo\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/ht",
    "url": "https://dev.to/chinmay_bhosale_9ceed796b/cognee-with-ollama-3pp8",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "PyLlamaUI Update",
    "date": "Sat, 18 Oct 2025 07:48:30 +0000",
    "summary": "<h2>\n  \n  \n  Markdown Output\n</h2>\n\n<h2>\n  \n  \n  Offline Agentic Mode Coming Soon\n</h2>\n\n<p>I'm thrilled to share that <strong>PyLlamaUI now supports structured Markdown output â€” fully offline</strong>.<br /><br />\nThis lets you view beautifully formatted text, code blocks, tables, and responses dir",
    "url": "https://dev.to/bhuvaneshm_dev/pyllamaui-update-1fmh",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Testing qwen3-vlâ€¦ quite impressive!",
    "date": "Fri, 17 Oct 2025 09:56:00 +0000",
    "summary": "<p>Rapid test using qwen3 vision language</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F8kwmbntbs6spnj4rvz4e.png\"><img alt=",
    "url": "https://dev.to/aairom/testing-qwen3-vl-quite-impressive-3e3o",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Building a Multi-Agent Crypto Trading Bot with Local LLMs, Recall, and Agno",
    "date": "Tue, 14 Oct 2025 06:33:00 +0000",
    "summary": "<p>In this post, I'll walk you through how I built a fully autonomous, multi-agent crypto trading team. This system uses a local LLM (via <strong>Ollama</strong>) for its reasoning, fetches real-time news from the web, and executes sandboxed trades on the <strong>Recall Network</strong>, a decentral",
    "url": "https://dev.to/harishkotra/building-a-multi-agent-crypto-trading-bot-with-local-llms-recall-and-agno-46mg",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Ollama SDKs in Go: Overview and Code Examples",
    "date": "Sun, 12 Oct 2025 00:37:13 +0000",
    "summary": "<p>Here is a little guide to <a href=\"https://www.glukhov.org/post/2025/10/using-ollama-in-go/\" rel=\"noopener noreferrer\">Ollama SDKs in Go</a>: Packages, Usage, and Comparison.</p>\n\n<p>Integrating Ollama models into Go applications is streamlined by several SDK options, each suited to different dev",
    "url": "https://dev.to/rosgluk/ollama-sdks-in-go-overview-and-code-examples-42n3",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Local LLMs: Running Ollama and Openâ€¯WebUI in Docker on Ubuntu",
    "date": "Wed, 08 Oct 2025 13:00:00 +0000",
    "summary": "<p><a href=\"https://docs.ollama.com/\" rel=\"noopener noreferrer\">Ollama</a> is a popular tool for running large language models (LLMs) locally on your machine. It provides a simple interface to interact with various models without needing an internet connection. <a href=\"https://docs.openwebui.com\" r",
    "url": "https://dev.to/pauldotyu/running-ollama-locally-with-open-webui-ol1",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Mixture of Experts Implementation using Granite4: Harnessing Specialization with the Latest Granite Family Model",
    "date": "Sun, 05 Oct 2025 12:39:12 +0000",
    "summary": "<p>A sample implementation of Mixture of Experts (MOE) using the latest Granite family LLM!</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fupload",
    "url": "https://dev.to/aairom/mixture-of-experts-implementation-using-granite4-harnessing-specialization-with-the-latest-granite-5c",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Building Your First AI Agent in PHP with Symfonyâ€™s New AI Component and Ollama",
    "date": "Sat, 04 Oct 2025 15:38:43 +0000",
    "summary": "<blockquote>\n<p>Learn how to build an AI agent in PHP using Symfonyâ€™s new AI Component and Ollama. This hands-on guide walks you through the installation, configuration, and running of a simple real-world example that rewrites and improves Markdown content locally with Gemma 3. Perfect for developer",
    "url": "https://dev.to/robertobutti/building-your-first-ai-agent-in-php-with-symfonys-new-ai-component-and-ollama-399a",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "ðŸª¨ â€˜Granite 4â€™ Meets â€˜Kubectl-AIâ€™: Building Your Own Local, Executable Kubernetes Assistant",
    "date": "Fri, 03 Oct 2025 12:37:11 +0000",
    "summary": "<p>Stop Googling Commands: A Personal Kubernetes AI Shell Powered by IBM Granite 4 and Googleâ€™s kubectl-ai</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazona",
    "url": "https://dev.to/aairom/granite-4-meets-kubectl-ai-building-your-own-local-executable-kubernetes-assistant-16hj",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Decoding AIâ€™s Inner Language: How to Test Your Embedding Models",
    "date": "Mon, 29 Sep 2025 16:34:33 +0000",
    "summary": "<p>Testing some embeddingsâ€¦ with Ollama</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fl4jq0w9tcbeem77om88o.png\"><img alt=\" ",
    "url": "https://dev.to/aairom/decoding-ais-inner-language-how-to-test-your-embedding-models-126",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "ollama pullâ€Šâ€”â€ŠNext-Level: Update Every Model Safely (with Pretty Output, Skips, and Error Handling)",
    "date": "Sun, 26 Oct 2025 16:04:33 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@rafal.kedziorski/ollama-pull-next-level-update-every-model-safely-with-pretty-output-skips-and-error-handling-b730b19a775b?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1536/1*5673JAkjyk",
    "url": "https://medium.com/@rafal.kedziorski/ollama-pull-next-level-update-every-model-safely-with-pretty-output-skips-and-error-handling-b730b19a775b?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "The Profile Scanner with AIâ€Šâ€”â€ŠGradio and Ollamaâ€Šâ€”â€ŠPart 2",
    "date": "Sun, 26 Oct 2025 12:11:16 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/anditb/the-profile-scanner-with-ai-gradio-and-ollama-part-2-08c7d9f5065e?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1595/1*WM1RT-o2Y7pooot5UliGcg.png\" width=\"1595\" /></a></p><p class=\"",
    "url": "https://medium.com/anditb/the-profile-scanner-with-ai-gradio-and-ollama-part-2-08c7d9f5065e?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "NVIDIA DGX Spark vs Mac Studio vs RTX-4080: Ollama Performance Comparison",
    "date": "Sun, 26 Oct 2025 08:28:13 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@rosgluk/nvidia-dgx-spark-vs-mac-studio-vs-rtx-4080-ollama-performance-comparison-08d975d9c132?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/672/0*a5wUWS0Rn_f8OohM.jpg\" width=\"672\" /></a>",
    "url": "https://medium.com/@rosgluk/nvidia-dgx-spark-vs-mac-studio-vs-rtx-4080-ollama-performance-comparison-08d975d9c132?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "How LLMs Think with Tools: The Power of the Model Context Protocol (MCP)",
    "date": "Sun, 26 Oct 2025 02:20:48 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@nileshsalpe/how-llms-think-with-tools-the-power-of-the-model-context-protocol-mcp-89431790b774?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1024/1*i4tlaNeCkS21nG630wO9qQ.png\" width=\"102",
    "url": "https://medium.com/@nileshsalpe/how-llms-think-with-tools-the-power-of-the-model-context-protocol-mcp-89431790b774?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Smart Shopping Assistants with Spring AI: Turning LLMs into Guided Sales Pros",
    "date": "Sat, 25 Oct 2025 22:41:59 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://lime5005.medium.com/smart-shopping-assistants-with-spring-ai-turning-llms-into-guided-sales-pros-7bab0eb27a86?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/2600/1*LuP2BkelJXBge_rbuk_dUg.jpeg\" width=",
    "url": "https://lime5005.medium.com/smart-shopping-assistants-with-spring-ai-turning-llms-into-guided-sales-pros-7bab0eb27a86?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Using Chonkie",
    "date": "Fri, 24 Oct 2025 09:13:47 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://alain-airom.medium.com/using-chonkie-b829b52f73a3?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/2600/1*9rPECY6wLMNhj3-CPBh2cQ.png\" width=\"3350\" /></a></p><p class=\"medium-feed-snippet\">Testing Chonk",
    "url": "https://alain-airom.medium.com/using-chonkie-b829b52f73a3?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Build an AI That Writes HTML While You Watch It Come to Life",
    "date": "Fri, 24 Oct 2025 02:10:07 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@wl8380/build-an-ai-that-writes-html-while-you-watch-it-come-to-life-8c1f440b87bc?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/2600/1*iVDTCl0W1BjonbnXwIySNA.png\" width=\"4736\" /></a></p><",
    "url": "https://medium.com/@wl8380/build-an-ai-that-writes-html-while-you-watch-it-come-to-life-8c1f440b87bc?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "I tried 5 LLM models that can run on only CPU for my Legal Appâ€Šâ€”â€Šhereâ€™s what worked",
    "date": "Thu, 23 Oct 2025 12:06:16 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://bilalkazim.medium.com/i-tried-5-llm-models-that-can-run-on-only-cpu-for-my-legal-app-heres-what-worked-233466a57eb4?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*INJUVl6KEcP-28XK\" width=\"5120",
    "url": "https://bilalkazim.medium.com/i-tried-5-llm-models-that-can-run-on-only-cpu-for-my-legal-app-heres-what-worked-233466a57eb4?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Practical LLMOps: Observability, Prompt CI, and Cost Control",
    "date": "Thu, 23 Oct 2025 02:14:23 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://python.plainenglish.io/practical-llmops-observability-prompt-ci-and-cost-control-4ade5465a449?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1536/1*zsT02-bbNJluKADwFqA8fA.png\" width=\"1536\" /></a></p>",
    "url": "https://python.plainenglish.io/practical-llmops-observability-prompt-ci-and-cost-control-4ade5465a449?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "How to Run a Local LLM with Ollama and Node JS for Beginners",
    "date": "Wed, 22 Oct 2025 22:26:48 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@krishnasinghprojects/how-to-run-a-local-llm-with-ollama-and-node-js-for-beginners-a4d13e49737c?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/2600/1*U8YuAbz3rXnfEHU3rlPfXA.png\" width=\"294",
    "url": "https://medium.com/@krishnasinghprojects/how-to-run-a-local-llm-with-ollama-and-node-js-for-beginners-a4d13e49737c?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  }
]