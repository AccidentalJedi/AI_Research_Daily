[
  {
    "title": "AgentWorkflow doesn't call functions when using Ollama",
    "date": "2025-10-21T03:46:28",
    "summary": "Stack Overflow question with 0 answers, 36 views",
    "url": "https://stackoverflow.com/questions/79795621/agentworkflow-doesnt-call-functions-when-using-ollama",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 36",
      "answers: 0",
      "score: 0",
      "tags: python, typescript, artificial-intelligence"
    ]
  },
  {
    "title": "How do I pass an image to DSPy for analysis?",
    "date": "2025-05-28T06:28:21",
    "summary": "Stack Overflow question with 1 answers, 544 views",
    "url": "https://stackoverflow.com/questions/79642103/how-do-i-pass-an-image-to-dspy-for-analysis",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 544",
      "answers: 1",
      "score: 1",
      "tags: ollama, dspy"
    ]
  },
  {
    "title": "Model not found Scrapegraph-ai",
    "date": "2024-08-12T04:32:01",
    "summary": "Stack Overflow question with 2 answers, 578 views",
    "url": "https://stackoverflow.com/questions/78860941/model-not-found-scrapegraph-ai",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 578",
      "answers: 2",
      "score: 0",
      "tags: python, web-scraping, artificial-intelligence"
    ]
  },
  {
    "title": "How to stop Ollama model streaming",
    "date": "2024-07-12T18:11:33",
    "summary": "Stack Overflow question with 1 answers, 2185 views",
    "url": "https://stackoverflow.com/questions/78742490/how-to-stop-ollama-model-streaming",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 2185",
      "answers: 1",
      "score: 1",
      "tags: python, websocket, fastapi"
    ]
  },
  {
    "title": "How to stream LLM responses in a Shiny app instead of waiting for full output?",
    "date": "2025-09-17T10:41:54",
    "summary": "Stack Overflow question with 1 answers, 235 views",
    "url": "https://stackoverflow.com/questions/79767548/how-to-stream-llm-responses-in-a-shiny-app-instead-of-waiting-for-full-output",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 235",
      "answers: 1",
      "score: 5",
      "tags: r, shiny, large-language-model"
    ]
  },
  {
    "title": "Llama Stack Agent not invoking MCP server in Docker setup despite tool group being registered",
    "date": "2025-09-24T04:10:13",
    "summary": "Stack Overflow question with 0 answers, 66 views",
    "url": "https://stackoverflow.com/questions/79773500/llama-stack-agent-not-invoking-mcp-server-in-docker-setup-despite-tool-group-bei",
    "source": "stackoverflow",
    "turbo_score": 0.6,
    "highlights": [
      "views: 66",
      "answers: 0",
      "score: 1",
      "tags: amazon-web-services, docker, docker-compose"
    ]
  },
  {
    "title": "Running Ollama on local computer and prompting from jupyter notebook - does the model recall prior prompts like if it was the same chat?",
    "date": "2025-09-23T18:35:57",
    "summary": "Stack Overflow question with 0 answers, 25 views",
    "url": "https://stackoverflow.com/questions/79773153/running-ollama-on-local-computer-and-prompting-from-jupyter-notebook-does-the",
    "source": "stackoverflow",
    "turbo_score": 0.25,
    "highlights": [
      "views: 25",
      "answers: 0",
      "score: 0",
      "tags: large-language-model, llama, ollama"
    ]
  },
  {
    "title": "langgraph with ollama not responding with a response",
    "date": "2025-09-23T09:01:30",
    "summary": "Stack Overflow question with 0 answers, 84 views",
    "url": "https://stackoverflow.com/questions/79772697/langgraph-with-ollama-not-responding-with-a-response",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 84",
      "answers: 0",
      "score: 0",
      "tags: python, langchain, ollama"
    ]
  },
  {
    "title": "Pycharm: \"Python Interpreter exited with non-zero exit code -1\" when connecting to an existing Docker Compose Service",
    "date": "2025-09-16T06:25:45",
    "summary": "Stack Overflow question with 1 answers, 152 views",
    "url": "https://stackoverflow.com/questions/79766168/pycharm-python-interpreter-exited-with-non-zero-exit-code-1-when-connecting",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 152",
      "answers: 1",
      "score: 3",
      "tags: python, docker, pycharm"
    ]
  },
  {
    "title": "FastAPI streaming response getting buffered instead of word by word using fetchEventSource in NextJS 14",
    "date": "2025-09-16T03:07:23",
    "summary": "Stack Overflow question with 0 answers, 20 views",
    "url": "https://stackoverflow.com/questions/79765935/fastapi-streaming-response-getting-buffered-instead-of-word-by-word-using-fetche",
    "source": "stackoverflow",
    "turbo_score": 0.2,
    "highlights": [
      "views: 20",
      "answers: 0",
      "score: 0",
      "tags: next.js, fastapi, ollama"
    ]
  },
  {
    "title": "Why is my dependent container not starting?",
    "date": "2025-09-11T12:21:51",
    "summary": "Stack Overflow question with 1 answers, 89 views",
    "url": "https://stackoverflow.com/questions/79762226/why-is-my-dependent-container-not-starting",
    "source": "stackoverflow",
    "turbo_score": -0.8,
    "highlights": [
      "views: 89",
      "answers: 1",
      "score: -5",
      "tags: docker, docker-compose"
    ]
  },
  {
    "title": "Getting inconsistent structured output from Ollama models with Genkit",
    "date": "2025-09-02T23:36:57",
    "summary": "Stack Overflow question with 0 answers, 79 views",
    "url": "https://stackoverflow.com/questions/79754131/getting-inconsistent-structured-output-from-ollama-models-with-genkit",
    "source": "stackoverflow",
    "turbo_score": 0.9,
    "highlights": [
      "views: 79",
      "answers: 0",
      "score: 2",
      "tags: node.js, typescript, ollama"
    ]
  },
  {
    "title": "Smolagents CodeAgent gets error from correct code",
    "date": "2025-08-24T13:32:36",
    "summary": "Stack Overflow question with 0 answers, 49 views",
    "url": "https://stackoverflow.com/questions/79745092/smolagents-codeagent-gets-error-from-correct-code",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 49",
      "answers: 0",
      "score: 0",
      "tags: python-3.x, large-language-model, agent"
    ]
  },
  {
    "title": "ragas with Ollama does not terminate",
    "date": "2025-08-29T09:41:03",
    "summary": "Stack Overflow question with 0 answers, 58 views",
    "url": "https://stackoverflow.com/questions/79750438/ragas-with-ollama-does-not-terminate",
    "source": "stackoverflow",
    "turbo_score": 0.6,
    "highlights": [
      "views: 58",
      "answers: 0",
      "score: 1",
      "tags: python, rag, ragas"
    ]
  },
  {
    "title": "Can't connect to Ollama hosted locally from python script",
    "date": "2025-08-28T10:24:16",
    "summary": "Stack Overflow question with 1 answers, 74 views",
    "url": "https://stackoverflow.com/questions/79749305/cant-connect-to-ollama-hosted-locally-from-python-script",
    "source": "stackoverflow",
    "turbo_score": 0.7,
    "highlights": [
      "views: 74",
      "answers: 1",
      "score: 0",
      "tags: docker, docker-compose, etl"
    ]
  },
  {
    "title": "How to print input requests and output responses in Ollama server?",
    "date": "2024-06-11T13:19:55",
    "summary": "Stack Overflow question with 1 answers, 14843 views",
    "url": "https://stackoverflow.com/questions/78609187/how-to-print-input-requests-and-output-responses-in-ollama-server",
    "source": "stackoverflow",
    "turbo_score": 0.7,
    "highlights": [
      "views: 14843",
      "answers: 1",
      "score: 0",
      "tags: prompt, langchain, ollama"
    ]
  },
  {
    "title": "Import \"llama_index.llms.ollama\" could not be resolved",
    "date": "2025-08-13T10:07:32",
    "summary": "Stack Overflow question with 1 answers, 93 views",
    "url": "https://stackoverflow.com/questions/79734455/import-llama-index-llms-ollama-could-not-be-resolved",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 93",
      "answers: 1",
      "score: 1",
      "tags: python, python-venv, llama"
    ]
  },
  {
    "title": "Function call with OpenAI Agent SDK with Ollama fails",
    "date": "2025-08-10T07:41:28",
    "summary": "Stack Overflow question with 1 answers, 191 views",
    "url": "https://stackoverflow.com/questions/79731216/function-call-with-openai-agent-sdk-with-ollama-fails",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 191",
      "answers: 1",
      "score: 3",
      "tags: python, openai-api, agent"
    ]
  },
  {
    "title": "Is there a way to manually set the first part of a model's response in Ollama?",
    "date": "2025-07-05T18:57:01",
    "summary": "Stack Overflow question with 1 answers, 162 views",
    "url": "https://stackoverflow.com/questions/79691404/is-there-a-way-to-manually-set-the-first-part-of-a-models-response-in-ollama",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 162",
      "answers: 1",
      "score: 1",
      "tags: python, artificial-intelligence, large-language-model"
    ]
  },
  {
    "title": "Langchain unpredicted behavior create_sql_query_chain",
    "date": "2024-08-12T18:26:12",
    "summary": "Stack Overflow question with 4 answers, 2215 views",
    "url": "https://stackoverflow.com/questions/78863892/langchain-unpredicted-behavior-create-sql-query-chain",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 2215",
      "answers: 4",
      "score: 0",
      "tags: langchain, large-language-model"
    ]
  },
  {
    "title": "Qwen 2.5 7B randomly hangs for 67 minutes when called using Ollama while running on EC2 Instance",
    "date": "2024-09-30T14:10:03",
    "summary": "Stack Overflow question with 0 answers, 841 views",
    "url": "https://stackoverflow.com/questions/79040747/qwen-2-5-7b-randomly-hangs-for-67-minutes-when-called-using-ollama-while-running",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 841",
      "answers: 0",
      "score: 0",
      "tags: large-language-model, ollama"
    ]
  },
  {
    "title": "Fine-tuned Qwen2.5-7B model loops infinitely in Ollama but works fine with transformers",
    "date": "2025-07-23T13:26:08",
    "summary": "Stack Overflow question with 1 answers, 241 views",
    "url": "https://stackoverflow.com/questions/79712412/fine-tuned-qwen2-5-7b-model-loops-infinitely-in-ollama-but-works-fine-with-trans",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 241",
      "answers: 1",
      "score: 1",
      "tags: large-language-model, ollama"
    ]
  },
  {
    "title": "How to use OllamaSharp Embeddings to get Cosine Similarity",
    "date": "2025-07-25T02:21:03",
    "summary": "Stack Overflow question with 0 answers, 176 views",
    "url": "https://stackoverflow.com/questions/79714339/how-to-use-ollamasharp-embeddings-to-get-cosine-similarity",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 176",
      "answers: 0",
      "score: 0",
      "tags: c#, cosine-similarity, ollama"
    ]
  },
  {
    "title": "MCPToolConversionError: Failed to get tools from MCP server: 404",
    "date": "2025-07-17T23:09:55",
    "summary": "Stack Overflow question with 1 answers, 325 views",
    "url": "https://stackoverflow.com/questions/79705666/mcptoolconversionerror-failed-to-get-tools-from-mcp-server-404",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 325",
      "answers: 1",
      "score: 3",
      "tags: python, langchain, model-context-protocol"
    ]
  },
  {
    "title": "Postgresql MCP server not running. Tool showing error",
    "date": "2025-07-21T16:31:42",
    "summary": "Stack Overflow question with 0 answers, 240 views",
    "url": "https://stackoverflow.com/questions/79709658/postgresql-mcp-server-not-running-tool-showing-error",
    "source": "stackoverflow",
    "turbo_score": 0.9,
    "highlights": [
      "views: 240",
      "answers: 0",
      "score: 2",
      "tags: python, postgresql, large-language-model"
    ]
  },
  {
    "title": "cannot import name 'LangChainBridge' from 'python_a2a.langchain'",
    "date": "2025-07-17T22:07:15",
    "summary": "Stack Overflow question with 2 answers, 232 views",
    "url": "https://stackoverflow.com/questions/79705629/cannot-import-name-langchainbridge-from-python-a2a-langchain",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 232",
      "answers: 2",
      "score: 2",
      "tags: python, langchain, model-context-protocol"
    ]
  },
  {
    "title": "How to prevent LlamaIndex queryengine from reloading LLM on each query?",
    "date": "2024-05-24T01:56:14",
    "summary": "Stack Overflow question with 1 answers, 737 views",
    "url": "https://stackoverflow.com/questions/78526926/how-to-prevent-llamaindex-queryengine-from-reloading-llm-on-each-query",
    "source": "stackoverflow",
    "turbo_score": 0.7,
    "highlights": [
      "views: 737",
      "answers: 1",
      "score: 0",
      "tags: llama-index"
    ]
  },
  {
    "title": "An simple MCP Client which adds employ using pojo throws json parse error invoking the tool",
    "date": "2025-07-09T16:32:51",
    "summary": "Stack Overflow question with 1 answers, 143 views",
    "url": "https://stackoverflow.com/questions/79696280/an-simple-mcp-client-which-adds-employ-using-pojo-throws-json-parse-error-invoki",
    "source": "stackoverflow",
    "turbo_score": 0.7,
    "highlights": [
      "views: 143",
      "answers: 1",
      "score: 0",
      "tags: java, ollama, spring-ai"
    ]
  },
  {
    "title": "How to implement context-aware tool routing with local models like Ollama?",
    "date": "2025-06-25T03:10:37",
    "summary": "Stack Overflow question with 0 answers, 88 views",
    "url": "https://stackoverflow.com/questions/79678678/how-to-implement-context-aware-tool-routing-with-local-models-like-ollama",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 88",
      "answers: 0",
      "score: 0",
      "tags: python, large-language-model, llama3"
    ]
  },
  {
    "title": "Ollama Python Unable to set Client host, httpx.ConnectError",
    "date": "2024-10-04T11:11:00",
    "summary": "Stack Overflow question with 2 answers, 3591 views",
    "url": "https://stackoverflow.com/questions/79055093/ollama-python-unable-to-set-client-host-httpx-connecterror",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 3591",
      "answers: 2",
      "score: 1",
      "tags: python, py-langchain, ollama"
    ]
  }
]