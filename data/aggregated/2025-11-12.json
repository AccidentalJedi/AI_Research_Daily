[
  {
    "arxiv_id": "2511.07343v1",
    "title": "TNT: Improving Chunkwise Training for Test-Time Memorization",
    "summary": "Recurrent neural networks (RNNs) with deep test-time memorization modules, such as Titans and TTT, represent a promising, linearly-scaling paradigm distinct from Transformers. While these expressive models do not yet match the peak performance of state-of-the-art Transformers, their potential has been largely untapped due to prohibitively slow training and low hardware utilization. Existing parallelization methods force a fundamental conflict governed by the chunksize hyperparameter: large chunks boost speed but degrade performance, necessitating a fixed, suboptimal compromise. To solve this challenge, we introduce TNT, a novel training paradigm that decouples training efficiency from inference performance through a two-stage process. Stage one is an efficiency-focused pre-training phase utilizing a hierarchical memory. A global module processes large, hardware-friendly chunks for long-range context, while multiple parallel local modules handle fine-grained details. Crucially, by periodically resetting local memory states, we break sequential dependencies to enable massive context parallelization. Stage two is a brief fine-tuning phase where only the local memory modules are adapted to a smaller, high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated on Titans and TTT models, TNT achieves a substantial acceleration in training speed-up to 17 times faster than the most accurate baseline configuration - while simultaneously improving model accuracy. This improvement removes a critical scalability barrier, establishing a practical foundation for developing expressive RNNs and facilitating future work to close the performance gap with Transformers.",
    "authors": [
      "Zeman Li",
      "Ali Behrouz",
      "Yuan Deng",
      "Peilin Zhong",
      "Praneeth Kacham",
      "Mahdi Karami",
      "Meisam Razaviyayn",
      "Vahab Mirrokni"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07343v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07343v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.91
  },
  {
    "arxiv_id": "2511.07329v1",
    "title": "Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis",
    "summary": "It introduces FractalNet, a fractal-inspired computational architectures for advanced large language model analysis that mainly challenges model diversity on a large scale in an efficient manner. The new set-up involves a template-driven generator, runner, and evaluation framework that, through systematic permutations of convolutional, normalization, activation, and dropout layers, can create more than 1,200 variants of neural networks. Fractal templates allow for structural recursion and multi-column pathways, thus, models become deeper and wider in a balanced way. Training utilizes PyTorch, Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based architectures are capable of strong performance and are computationally efficient. The paper positions fractal design as a feasible and resource-efficient method of automated architecture exploration.",
    "authors": [
      "Yash Mittal",
      "Dmitry Ignatov",
      "Radu Timofte"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07329v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07329v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.9
  },
  {
    "arxiv_id": "2511.06609v1",
    "title": "A Weak Penalty Neural ODE for Learning Chaotic Dynamics from Noisy Time Series",
    "summary": "Accurate forecasting of complex high-dimensional dynamical systems from observational data is essential for several applications across science and engineering. A key challenge, however, is that real-world measurements are often corrupted by noise, which severely degrades the performance of data-driven models. Particularly, in chaotic dynamical systems, where small errors amplify rapidly, it is challenging to identify a data-driven model from noisy data that achieves short-term accuracy while preserving long-term invariant properties. In this paper, we propose the use of the weak formulation as a complementary approach to the classical strong formulation of data-driven time-series forecasting models. Specifically, we focus on the neural ordinary differential equation (NODE) architecture. Unlike the standard strong formulation, which relies on the discretization of the NODE followed by optimization, the weak formulation constrains the model using a set of integrated residuals over temporal subdomains. While such a formulation yields an effective NODE model, we discover that the performance of a NODE can be further enhanced by employing this weak formulation as a penalty alongside the classical strong formulation-based learning. Through numerical demonstrations, we illustrate that our proposed training strategy, which we coined as the Weak-Penalty NODE (WP-NODE), achieves state-of-the-art forecasting accuracy and exceptional robustness across benchmark chaotic dynamical systems.",
    "authors": [
      "Xuyang Li",
      "John Harlim",
      "Romit Maulik"
    ],
    "categories": [
      "cs.LG",
      "math.DS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06609v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06609v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.89
  },
  {
    "arxiv_id": "2511.07308v1",
    "title": "Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by the Thermodynamics of an Ideal Gas?",
    "summary": "Understanding the training dynamics of deep neural networks remains a major open problem, with physics-inspired approaches offering promising insights. Building on this perspective, we develop a thermodynamic framework to describe the stationary distributions of stochastic gradient descent (SGD) with weight decay for scale-invariant neural networks, a setting that both reflects practical architectures with normalization layers and permits theoretical analysis. We establish analogies between training hyperparameters (e.g., learning rate, weight decay) and thermodynamic variables such as temperature, pressure, and volume. Starting with a simplified isotropic noise model, we uncover a close correspondence between SGD dynamics and ideal gas behavior, validated through theory and simulation. Extending to training of neural networks, we show that key predictions of the framework, including the behavior of stationary entropy, align closely with experimental observations. This framework provides a principled foundation for interpreting training dynamics and may guide future work on hyperparameter tuning and the design of learning rate schedulers.",
    "authors": [
      "Ildus Sadrtdinov",
      "Ekaterina Lobacheva",
      "Ivan Klimov",
      "Mikhail I. Katsnelson",
      "Dmitry Vetrov"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07308v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07308v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.81
  },
  {
    "arxiv_id": "2511.07068v1",
    "title": "ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora",
    "summary": "Large-scale visual out-of-distribution (OOD) detection has witnessed remarkable progress by leveraging vision-language models such as CLIP. However, a significant limitation of current methods is their reliance on a pre-defined set of in-distribution (ID) ground-truth label names (positives). These fixed label names can be unavailable, unreliable at scale, or become less relevant due to in-distribution shifts after deployment. Towards truly unsupervised OOD detection, we utilize widely available text corpora for positive label mining, bypassing the need for positives. In this paper, we utilize widely available text corpora for positive label mining under a general concept mining paradigm. Within this framework, we propose ClusterMine, a novel positive label mining method. ClusterMine is the first method to achieve state-of-the-art OOD detection performance without access to positive labels. It extracts positive concepts from a large text corpus by combining visual-only sample consistency (via clustering) and zero-shot image-text consistency. Our experimental study reveals that ClusterMine is scalable across a plethora of CLIP models and achieves state-of-the-art robustness to covariate in-distribution shifts. The code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.",
    "authors": [
      "Nikolas Adaloglou",
      "Diana Petrusheva",
      "Mohamed Asker",
      "Felix Michels",
      "Markus Kollmann"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07068v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07068v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.06716v1",
    "title": "MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos",
    "summary": "Video mirror detection has received significant research attention, yet existing methods suffer from limited performance and robustness. These approaches often over-rely on single, unreliable dynamic features, and are typically built on CNNs with limited receptive fields or Transformers with quadratic computational complexity. To address these limitations, we propose a new effective and scalable video mirror detection method, called MirrorMamba. Our approach leverages multiple cues to adapt to diverse conditions, incorporating perceived depth, correspondence and optical. We also introduce an innovative Mamba-based Multidirection Correspondence Extractor, which benefits from the global receptive field and linear complexity of the emerging Mamba spatial state model to effectively capture correspondence properties. Additionally, we design a Mamba-based layer-wise boundary enforcement decoder to resolve the unclear boundary caused by the blurred depth map. Notably, this work marks the first successful application of the Mamba-based architecture in the field of mirror detection. Extensive experiments demonstrate that our method outperforms existing state-of-the-art approaches for video mirror detection on the benchmark datasets. Furthermore, on the most challenging and representative image-based mirror detection dataset, our approach achieves state-of-the-art performance, proving its robustness and generalizability.",
    "authors": [
      "Rui Song",
      "Jiaying Lin",
      "Rynson W. H. Lau"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06716v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06716v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.06696v1",
    "title": "Magnitude-Modulated Equivariant Adapter for Parameter-Efficient Fine-Tuning of Equivariant Graph Neural Networks",
    "summary": "Pretrained equivariant graph neural networks based on spherical harmonics offer efficient and accurate alternatives to computationally expensive ab-initio methods, yet adapting them to new tasks and chemical environments still requires fine-tuning. Conventional parameter-efficient fine-tuning (PEFT) techniques, such as Adapters and LoRA, typically break symmetry, making them incompatible with those equivariant architectures. ELoRA, recently proposed, is the first equivariant PEFT method. It achieves improved parameter efficiency and performance on many benchmarks. However, the relatively high degrees of freedom it retains within each tensor order can still perturb pretrained feature distributions and ultimately degrade performance. To address this, we present Magnitude-Modulated Equivariant Adapter (MMEA), a novel equivariant fine-tuning method which employs lightweight scalar gating to modulate feature magnitudes on a per-order and per-multiplicity basis. We demonstrate that MMEA preserves strict equivariance and, across multiple benchmarks, consistently improves energy and force predictions to state-of-the-art levels while training fewer parameters than competing approaches. These results suggest that, in many practical scenarios, modulating channel magnitudes is sufficient to adapt equivariant models to new chemical environments without breaking symmetry, pointing toward a new paradigm for equivariant PEFT design.",
    "authors": [
      "Dian Jin",
      "Yancheng Yuan",
      "Xiaoming Tao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06696v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06696v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.07418v1",
    "title": "Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields",
    "summary": "Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation.",
    "authors": [
      "Zhao-Heng Yin",
      "Pieter Abbeel"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.GR"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07418v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07418v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.06665v1",
    "title": "Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks",
    "summary": "Despite significant progress in pixel-level medical image analysis, existing medical image segmentation models rarely explore medical segmentation and diagnosis tasks jointly. However, it is crucial for patients that models can provide explainable diagnoses along with medical segmentation results. In this paper, we introduce a medical vision-language task named Medical Diagnosis Segmentation (MDS), which aims to understand clinical queries for medical images and generate the corresponding segmentation masks as well as diagnostic results. To facilitate this task, we first present the Multimodal Multi-disease Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal multi-disease medical images paired with their corresponding segmentation masks and diagnosis chain-of-thought, created via an automated diagnosis chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel framework that improves the performance of diagnosis segmentation by taking advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M) module. To improve overall performance, we investigate a test-time scaling strategy for MDS tasks. Experimental results demonstrate that our method outperforms the baselines in both segmentation and diagnosis.",
    "authors": [
      "Lingran Song",
      "Yucheng Zhou",
      "Jianbing Shen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06665v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06665v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.06838v1",
    "title": "P3-LLM: An Integrated NPU-PIM Accelerator for LLM Inference Using Hybrid Numerical Formats",
    "summary": "The substantial memory bandwidth and computational demand of large language models (LLMs) present critical challenges for efficient inference. To tackle this, the literature has explored heterogeneous systems that combine neural processing units (NPUs) with DRAM-based processing-in-memory (PIM) for LLM acceleration. However, existing high-precision (e.g., FP16) PIM compute units incur significant area and power overhead in DRAM technology, limiting the effective computation throughput. In this paper, we introduce P3-LLM, a novel NPU-PIM integrated accelerator for LLM inference using hybrid numerical formats. Our approach is threefold: First, we propose a flexible mixed-precision quantization scheme, which leverages hybrid numerical formats to quantize different LLM operands with high compression efficiency and minimal accuracy loss. Second, we architect an efficient PIM accelerator co-design for P3-LLM, featuring lightweight compute units to support our hybrid numerical formats. The enhanced PIM compute units significantly boost the computation throughput under iso-area constraints. Third, we optimize the low-precision dataflow of different LLM modules by applying operator fusion to minimize the overhead of runtime dequantization. Our evaluation on a diverse set of representative LLMs and tasks demonstrates that P3-LLM achieves state-of-the-art quantization accuracy in terms of both KV-cache-only quantization and weight-activation quantization. Combining the proposed quantization scheme with PIM architecture co-design, P3-LLM yields an average of $4.9\\times$, $2.0\\times$, and $3.4\\times$ speedups over the state-of-the-art LLM accelerators HBM-PIM, Ecco, and Pimba, respectively. Our quantization code is available at https://github.com/yc2367/P3-LLM.git",
    "authors": [
      "Yuzong Chen",
      "Chao Fang",
      "Xilai Dai",
      "Yuheng Wu",
      "Thierry Tambe",
      "Marian Verhelst",
      "Mohamed S. Abdelfattah"
    ],
    "categories": [
      "cs.AR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06838v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06838v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.06658v1",
    "title": "Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling",
    "summary": "Animal Re-ID has recently gained substantial attention in the AI research community due to its high impact on biodiversity monitoring and unique research challenges arising from environmental factors. The subtle distinguishing patterns, handling new species and the inherent open-set nature make the problem even harder. To address these complexities, foundation models trained on labeled, large-scale and multi-species animal Re-ID datasets have recently been introduced to enable zero-shot Re-ID. However, our benchmarking reveals significant gaps in their zero-shot Re-ID performance for both known and unknown species. While this highlights the need for collecting labeled data in new domains, exhaustive annotation for Re-ID is laborious and requires domain expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID methods underperform for animal Re-ID. To address these limitations, we introduce a novel AL Re-ID framework that leverages complementary clustering methods to uncover and target structurally ambiguous regions in the embedding space for mining pairs of samples that are both informative and broadly representative. Oracle feedback on these pairs, in the form of must-link and cannot-link constraints, facilitates a simple annotation interface, which naturally integrates with existing USL methods through our proposed constrained clustering refinement algorithm. Through extensive experiments, we demonstrate that, by utilizing only 0.033% of all annotations, our approach consistently outperforms existing foundational, USL and AL baselines. Specifically, we report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife datasets over foundational, USL and AL methods, respectively, while attaining state-of-the-art performance on each dataset. Furthermore, we also show an improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world setting.",
    "authors": [
      "Depanshu Sani",
      "Mehar Khurana",
      "Saket Anand"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06658v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06658v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.06785v1",
    "title": "Resource Efficient Sleep Staging via Multi-Level Masking and Prompt Learning",
    "summary": "Automatic sleep staging plays a vital role in assessing sleep quality and diagnosing sleep disorders. Most existing methods rely heavily on long and continuous EEG recordings, which poses significant challenges for data acquisition in resource-constrained systems, such as wearable or home-based monitoring systems. In this paper, we propose the task of resource-efficient sleep staging, which aims to reduce the amount of signal collected per sleep epoch while maintaining reliable classification performance. To solve this task, we adopt the masking and prompt learning strategy and propose a novel framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a multi-level masking strategy to promote effective feature modeling under partial and irregular observations. To mitigate the loss of contextual information introduced by masking, we further propose a hierarchical prompt learning mechanism that aggregates unmasked data into a global prompt, serving as a semantic anchor for guiding both patch-level and epoch-level feature modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art performance, especially when the amount of data is very limited. This result highlights its potential for efficient and scalable deployment in real-world low-resource sleep monitoring environments.",
    "authors": [
      "Lejun Ai",
      "Yulong Li",
      "Haodong Yi",
      "Jixuan Xie",
      "Yue Wang",
      "Jia Liu",
      "Min Chen",
      "Rui Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06785v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06785v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.07379v1",
    "title": "LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic Graphs",
    "summary": "Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes domains, such as financial forecasting, recommendation systems, and fraud detection. However, their susceptibility to poisoning attacks poses a critical security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades TGNN performance by an average of 29.47% across 4 widely benchmark datasets and 4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage approach: (1) sparsify the graph by removing high-impact edges using any of the 16 tested temporal importance metrics, (2) strategically replace removed edges with adversarial negatives via LoReTTA's novel degree-preserving negative sampling algorithm. Our plug-and-play design eliminates the need for expensive surrogate models while adhering to realistic unnoticeability constraints. LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8% on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA adversarial defense training methods, establishing its effectiveness, unnoticeability, and robustness.",
    "authors": [
      "Himanshu Pal",
      "Venkata Sai Pranav Bachina",
      "Ankit Gangwal",
      "Charu Sharma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07379v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07379v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.06836v1",
    "title": "NeuroBridge: Bio-Inspired Self-Supervised EEG-to-Image Decoding via Cognitive Priors and Bidirectional Semantic Alignment",
    "summary": "Visual neural decoding seeks to reconstruct or infer perceived visual stimuli from brain activity patterns, providing critical insights into human cognition and enabling transformative applications in brain-computer interfaces and artificial intelligence. Current approaches, however, remain constrained by the scarcity of high-quality stimulus-brain response pairs and the inherent semantic mismatch between neural representations and visual content. Inspired by perceptual variability and co-adaptive strategy of the biological systems, we propose a novel self-supervised architecture, named NeuroBridge, which integrates Cognitive Prior Augmentation (CPA) with Shared Semantic Projector (SSP) to promote effective cross-modality alignment. Specifically, CPA simulates perceptual variability by applying asymmetric, modality-specific transformations to both EEG signals and images, enhancing semantic diversity. Unlike previous approaches, SSP establishes a bidirectional alignment process through a co-adaptive strategy, which mutually aligns features from two modalities into a shared semantic space for effective cross-modal learning. NeuroBridge surpasses previous state-of-the-art methods under both intra-subject and inter-subject settings. In the intra-subject scenario, it achieves the improvements of 12.3% in top-1 accuracy and 10.2% in top-5 accuracy, reaching 63.2% and 89.9% respectively on a 200-way zero-shot retrieval task. Extensive experiments demonstrate the effectiveness, robustness, and scalability of the proposed framework for neural visual decoding.",
    "authors": [
      "Wenjiang Zhang",
      "Sifeng Wang",
      "Yuwei Su",
      "Xinyu Li",
      "Chen Zhang",
      "Suyu Zhong"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06836v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06836v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.07233v1",
    "title": "Noise & pattern: identity-anchored Tikhonov regularization for robust structural anomaly detection",
    "summary": "Anomaly detection plays a pivotal role in automated industrial inspection, aiming to identify subtle or rare defects in otherwise uniform visual patterns. As collecting representative examples of all possible anomalies is infeasible, we tackle structural anomaly detection using a self-supervised autoencoder that learns to repair corrupted inputs. To this end, we introduce a corruption model that injects artificial disruptions into training images to mimic structural defects. While reminiscent of denoising autoencoders, our approach differs in two key aspects. First, instead of unstructured i.i.d.\\ noise, we apply structured, spatially coherent perturbations that make the task a hybrid of segmentation and inpainting. Second, and counterintuitively, we add and preserve Gaussian noise on top of the occlusions, which acts as a Tikhonov regularizer anchoring the Jacobian of the reconstruction function toward identity. This identity-anchored regularization stabilizes reconstruction and further improves both detection and segmentation accuracy. On the MVTec AD benchmark, our method achieves state-of-the-art results (I/P-AUROC: 99.9/99.4), supporting our theoretical framework and demonstrating its practical relevance for automatic inspection.",
    "authors": [
      "Alexander Bauer",
      "Klaus-Robert M\u00fcller"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07233v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07233v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2511.06898v1",
    "title": "A Hybrid Autoencoder-Transformer Model for Robust Day-Ahead Electricity Price Forecasting under Extreme Conditions",
    "summary": "Accurate day-ahead electricity price forecasting (DAEPF) is critical for the efficient operation of power systems, but extreme condition and market anomalies pose significant challenges to existing forecasting methods. To overcome these challenges, this paper proposes a novel hybrid deep learning framework that integrates a Distilled Attention Transformer (DAT) model and an Autoencoder Self-regression Model (ASM). The DAT leverages a self-attention mechanism to dynamically assign higher weights to critical segments of historical data, effectively capturing both long-term trends and short-term fluctuations. Concurrently, the ASM employs unsupervised learning to detect and isolate anomalous patterns induced by extreme conditions, such as heavy rain, heat waves, or human festivals. Experiments on datasets sampled from California and Shandong Province demonstrate that our framework significantly outperforms state-of-the-art methods in prediction accuracy, robustness, and computational efficiency. Our framework thus holds promise for enhancing grid resilience and optimizing market operations in future power systems.",
    "authors": [
      "Boyan Tang",
      "Xuanhao Ren",
      "Peng Xiao",
      "Shunbo Lei",
      "Xiaorong Sun",
      "Jianghua Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06898v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06898v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.06776v1",
    "title": "Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics",
    "summary": "General-purpose large language models (LLMs) are increasingly deployed in verticals such as telecommunications, where adaptation is hindered by scarce, low-information-density corpora and tight mobile/edge constraints. We propose Data Trajectory Alignment (DTA), a two-phase, model-agnostic data curation framework that treats solution processes - not only final answers - as first-class supervision. Phase I (Initializing) synthesizes diverse, high-coverage candidates using an ensemble of strong teachers. Phase II (DTA) rewrites teacher solutions to align intermediate steps and presentation style with the target student's inductive biases and then performs signal-aware exemplar selection via agreement checks and reflection-based judging. Instantiated on telecommunications mathematics (e.g., link budgets, SNR/AMC selection, and power-control feasibility), DTA yields state-of-the-art (SOTA) accuracy on TELEMATH without enabling explicit \"thinking\" modes: 72.45% pass@1, surpassing distilled-only training by +17.65 points and outperforming a strong baseline (Qwen3-32B with thinking enabled) by +2.94 points. Token-shift analyses indicate that DTA concentrates gains on logical-structural discourse markers rather than merely amplifying domain nouns, indicating improved reasoning scaffolding. Under edge-like inference settings, DTA improves efficiency by reducing reliance on multi-sample voting and disabling expensive reasoning heuristics, cutting energy per output token by ~42% versus Qwen3-32B (thinking mode enabled) and end-to-end latency by ~60% versus Qwen3-32B (thinking mode disabled). These results demonstrate that aligning how solutions are produced enables compact, high-yield supervision that is effective for both accuracy and efficiency, offering a practical recipe for domain adaptation in low-resource verticals beyond telecom.",
    "authors": [
      "Zhicheng Zhou",
      "Jing Li",
      "Suming Qiu",
      "Junjie Huang",
      "Linyuan Qiu",
      "Zhijie Sun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06776v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06776v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.07171v1",
    "title": "Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use",
    "summary": "Deep learning-based video surveillance increasingly demands privacy-preserving architectures with low computational and environmental overhead. Federated learning preserves privacy but deploying large vision-language models (VLMs) introduces major energy and sustainability challenges. We compare three strategies for federated violence detection under realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed 90% accuracy in binary violence detection. The 3D CNN achieves superior calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570 Wh) of federated LoRA, while VLMs provide richer multimodal reasoning. Hierarchical category grouping (based on semantic similarity and class exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime dataset. To our knowledge, this is the first comparative simulation study of LoRA-tuned VLMs and personalized CNNs for federated violence detection, with explicit energy and CO2e quantification. Our results inform hybrid deployment strategies that default to efficient CNNs for routine inference and selectively engage VLMs for complex contextual reasoning.",
    "authors": [
      "S\u00e9bastien Thuau",
      "Siba Haidar",
      "Rachid Chelouah"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07171v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07171v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06682v1",
    "title": "Textual Self-attention Network: Test-Time Preference Optimization through Textual Gradient-based Attention",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable generalization capabilities, but aligning their outputs with human preferences typically requires expensive supervised fine-tuning. Recent test-time methods leverage textual feedback to overcome this, but they often critique and revise a single candidate response, lacking a principled mechanism to systematically analyze, weigh, and synthesize the strengths of multiple promising candidates. Such a mechanism is crucial because different responses may excel in distinct aspects (e.g., clarity, factual accuracy, or tone), and combining their best elements may produce a far superior outcome. This paper proposes the Textual Self-Attention Network (TSAN), a new paradigm for test-time preference optimization that requires no parameter updates. TSAN emulates self-attention entirely in natural language to overcome this gap: it analyzes multiple candidates by formatting them into textual keys and values, weighs their relevance using an LLM-based attention module, and synthesizes their strengths into a new, preference-aligned response under the guidance of the learned textual attention. This entire process operates in a textual gradient space, enabling iterative and interpretable optimization. Empirical evaluations demonstrate that with just three test-time iterations on a base SFT model, TSAN outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the current state-of-the-art test-time alignment method by effectively leveraging multiple candidate solutions.",
    "authors": [
      "Shibing Mo",
      "Haoyang Ruan",
      "Kai Wu",
      "Jing Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06682v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06682v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06751v1",
    "title": "Hierarchical Spatial-Frequency Aggregation for Spectral Deconvolution Imaging",
    "summary": "Computational spectral imaging (CSI) achieves real-time hyperspectral imaging through co-designed optics and algorithms, but typical CSI methods suffer from a bulky footprint and limited fidelity. Therefore, Spectral Deconvolution imaging (SDI) methods based on PSF engineering have been proposed to achieve high-fidelity compact CSI design recently. However, the composite convolution-integration operations of SDI render the normal-equation coefficient matrix scene-dependent, which hampers the efficient exploitation of imaging priors and poses challenges for accurate reconstruction. To tackle the inherent data-dependent operators in SDI, we introduce a Hierarchical Spatial-Spectral Aggregation Unfolding Framework (HSFAUF). By decomposing subproblems and projecting them into the frequency domain, HSFAUF transforms nonlinear processes into linear mappings, thereby enabling efficient solutions. Furthermore, to integrate spatial-spectral priors during iterative refinement, we propose a Spatial-Frequency Aggregation Transformer (SFAT), which explicitly aggregates information across spatial and frequency domains. By integrating SFAT into HSFAUF, we develop a Transformer-based deep unfolding method, \\textbf{H}ierarchical \\textbf{S}patial-\\textbf{F}requency \\textbf{A}ggregation \\textbf{U}nfolding \\textbf{T}ransformer (HSFAUT), to solve the inverse problem of SDI. Systematic simulated and real experiments show that HSFAUT surpasses SOTA methods with cheaper memory and computational costs, while exhibiting optimal performance on different SDI systems.",
    "authors": [
      "Tao Lv",
      "Daoming Zhou",
      "Chenglong Huang",
      "Chongde Zi",
      "Linsen Chen",
      "Xun Cao"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06751v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06751v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06719v1",
    "title": "MobileLLM-Pro Technical Report",
    "summary": "Efficient on-device language models around 1 billion parameters are essential for powering low-latency AI applications on mobile and wearable devices. However, achieving strong performance in this model class, while supporting long context windows and practical deployment remains a significant challenge. We introduce MobileLLM-Pro, a 1-billion-parameter language model optimized for on-device deployment. MobileLLM-Pro achieves state-of-the-art results across 11 standard benchmarks, significantly outperforming both Gemma 3-1B and Llama 3.2-1B, while supporting context windows of up to 128,000 tokens and showing only minor performance regressions at 4-bit quantization. These improvements are enabled by four core innovations: (1) implicit positional distillation, a novel technique that effectively instills long-context capabilities through knowledge distillation; (2) a specialist model merging framework that fuses multiple domain experts into a compact model without parameter growth; (3) simulation-driven data mixing using utility estimation; and (4) 4-bit quantization-aware training with self-distillation. We release our model weights and code to support future research in efficient on-device language models.",
    "authors": [
      "Patrick Huber",
      "Ernie Chang",
      "Wei Wen",
      "Igor Fedorov",
      "Tarek Elgamal",
      "Hanxian Huang",
      "Naveen Suda",
      "Chinnadhurai Sankar",
      "Vish Vogeti",
      "Yanghan Wang",
      "Alex Gladkov",
      "Kai Sheng Tai",
      "Abdelrahman Elogeel",
      "Tarek Hefny",
      "Vikas Chandra",
      "Ahmed Aly",
      "Anuj Kumar",
      "Raghuraman Krishnamoorthi",
      "Adithya Sagar"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06719v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06719v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.07098v1",
    "title": "Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization",
    "summary": "Fine-grained urban flow inference is crucial for urban planning and intelligent transportation systems, enabling precise traffic management and resource allocation. However, the practical deployment of existing methods is hindered by two key challenges: the prohibitive computational cost of over-parameterized models and the suboptimal performance of conventional loss functions on the highly skewed distribution of urban flows. To address these challenges, we propose a unified solution that synergizes architectural efficiency with adaptive optimization. Specifically, we first introduce PLGF, a lightweight yet powerful architecture that employs a Progressive Local-Global Fusion strategy to effectively capture both fine-grained details and global contextual dependencies. Second, we propose DualFocal Loss, a novel function that integrates dual-space supervision with a difficulty-aware focusing mechanism, enabling the model to adaptively concentrate on hard-to-predict regions. Extensive experiments on 4 real-world scenarios validate the effectiveness and scalability of our method. Notably, while achieving state-of-the-art performance, PLGF reduces the model size by up to 97% compared to current high-performing methods. Furthermore, under comparable parameter budgets, our model yields an accuracy improvement of over 10% against strong baselines. The implementation is included in the https://github.com/Yasoz/PLGF.",
    "authors": [
      "Yuanshao Zhu",
      "Xiangyu Zhao",
      "Zijian Zhang",
      "Xuetao Wei",
      "James Jianqiao Yu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07098v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07098v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.07006v1",
    "title": "S$^2$Drug: Bridging Protein Sequence and 3D Structure in Contrastive Representation Learning for Virtual Screening",
    "summary": "Virtual screening (VS) is an essential task in drug discovery, focusing on the identification of small-molecule ligands that bind to specific protein pockets. Existing deep learning methods, from early regression models to recent contrastive learning approaches, primarily rely on structural data while overlooking protein sequences, which are more accessible and can enhance generalizability. However, directly integrating protein sequences poses challenges due to the redundancy and noise in large-scale protein-ligand datasets. To address these limitations, we propose \\textbf{S$^2$Drug}, a two-stage framework that explicitly incorporates protein \\textbf{S}equence information and 3D \\textbf{S}tructure context in protein-ligand contrastive representation learning. In the first stage, we perform protein sequence pretraining on ChemBL using an ESM2-based backbone, combined with a tailored data sampling strategy to reduce redundancy and noise on both protein and ligand sides. In the second stage, we fine-tune on PDBBind by fusing sequence and structure information through a residue-level gating module, while introducing an auxiliary binding site prediction task. This auxiliary task guides the model to accurately localize binding residues within the protein sequence and capture their 3D spatial arrangement, thereby refining protein-ligand matching. Across multiple benchmarks, S$^2$Drug consistently improves virtual screening performance and achieves strong results on binding site prediction, demonstrating the value of bridging sequence and structure in contrastive learning.",
    "authors": [
      "Bowei He",
      "Bowen Gao",
      "Yankai Chen",
      "Yanyan Lan",
      "Chen Ma",
      "Philip S. Yu",
      "Ya-Qin Zhang",
      "Wei-Ying Ma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07006v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07006v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07377v1",
    "title": "Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion",
    "summary": "LiDAR super-resolution addresses the challenge of achieving high-quality 3D perception from cost-effective, low-resolution sensors. While recent transformer-based approaches like TULIP show promise, they remain limited to spatial-domain processing with restricted receptive fields. We introduce FLASH (Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a novel framework that overcomes these limitations through dual-domain processing. FLASH integrates two key innovations: (i) Frequency-Aware Window Attention that combines local spatial attention with global frequency-domain analysis via FFT, capturing both fine-grained geometry and periodic scanning patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that replaces conventional skip connections with learned position-specific feature aggregation, enhanced by CBAM attention for dynamic feature selection. Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art performance across all evaluation metrics, surpassing even uncertainty-enhanced baselines that require multiple forward passes. Notably, FLASH outperforms TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which enables real-time deployment. The consistent superiority across all distance ranges validates that our dual-domain approach effectively handles uncertainty through architectural design rather than computationally expensive stochastic inference, making it practical for autonomous systems.",
    "authors": [
      "June Moh Goo",
      "Zichao Zeng",
      "Jan Boehm"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07377v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07377v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06893v1",
    "title": "DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series Forecasting",
    "summary": "Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most forecasting methods display compromised robustness to concept drift, despite the prevalent application of instance normalization. We tackle this challenge by first analysing concept drift through a bias-variance lens and proving that weighted ensemble reduces variance without increasing bias. These insights motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting method that progressively reconstructs the intrinsic signal. In our design, each block of a deep model becomes an ensemble of learners with an auxiliary output branch forming a highway to the final prediction. The block-wise outputs correct the residuals of previous blocks, leading to a learning-driven decomposition of both inputs and targets. This method enhances versatility and interpretability while substantially improving robustness to concept drift. Extensive experiments, including those on large-scale datasets, show that the proposed method outperforms existing methods by a large margin, yielding an average performance improvement of 15.8% across various datasets, establishing a new benchmark for TS forecasting.",
    "authors": [
      "Daojun Liang",
      "Jing Chen",
      "Xiao Wang",
      "Yinglong Wang",
      "Suo Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06893v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06893v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06757v1",
    "title": "Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning",
    "summary": "As large language models continue to develop and expand, the extensive public data they rely on faces the risk of depletion. Consequently, leveraging private data within organizations to enhance the performance of large models has emerged as a key challenge. The federated learning paradigm, combined with model fine-tuning techniques, effectively reduces the number of trainable parameters. However,the necessity to process high-dimensional feature spaces results in substantial overall computational overhead. To address this issue, we propose the Implicit Federated In-Context Learning (IFed-ICL) framework. IFed-ICL draws inspiration from federated learning to establish a novel distributed collaborative paradigm, by converting client local context examples into implicit vector representations, it enables distributed collaborative computation during the inference phase and injects model residual streams to enhance model performance. Experiments demonstrate that our proposed method achieves outstanding performance across multiple text classification tasks. Compared to traditional methods, IFed-ICL avoids the extensive parameter updates required by conventional fine-tuning methods while reducing data transmission and local computation at the client level in federated learning. This enables efficient distributed context learning using local private-domain data, significantly improving model performance on specific tasks.",
    "authors": [
      "Dongcheng Li",
      "Junhan Chen",
      "Aoxiang Zhou",
      "Chunpei Li",
      "Youquan Xian",
      "Peng Liu",
      "Xianxian Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06757v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06757v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07301v1",
    "title": "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection",
    "summary": "Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object detector to a target domain without access to source data. However, existing SFOD methods predominantly rely on internal knowledge from the source model, which limits their capacity to generalize across domains and often results in biased pseudo-labels, thereby hindering both transferability and discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on massive and diverse data, exhibit strong perception capabilities and broad generalization, yet their potential remains largely untapped in the SFOD setting. In this paper, we propose a novel SFOD framework that leverages VFMs as external knowledge sources to jointly enhance feature alignment and label quality. Specifically, we design three VFM-based modules: (1) Patch-weighted Global Feature Alignment (PGFA) distills global features from VFMs using patch-similarity-based weighting to enhance global feature transferability; (2) Prototype-based Instance Feature Alignment (PIFA) performs instance-level contrastive learning guided by momentum-updated VFM prototypes; and (3) Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from detection VFMs and teacher models via an entropy-aware strategy to yield more reliable supervision. Extensive experiments on six benchmarks demonstrate that our method achieves state-of-the-art SFOD performance, validating the effectiveness of integrating VFMs to simultaneously improve transferability and discriminability.",
    "authors": [
      "Huizai Yao",
      "Sicheng Zhao",
      "Pengteng Li",
      "Yi Cui",
      "Shuo Lu",
      "Weiyu Guo",
      "Yunfan Lu",
      "Yijie Xu",
      "Hui Xiong"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07301v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07301v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06943v1",
    "title": "PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data",
    "summary": "Global plant maps of plant traits, such as leaf nitrogen or plant height, are essential for understanding ecosystem processes, including the carbon and energy cycles of the Earth system. However, existing trait maps remain limited by the high cost and sparse geographic coverage of field-based measurements. Citizen science initiatives offer a largely untapped resource to overcome these limitations, with over 50 million geotagged plant photographs worldwide capturing valuable visual information on plant morphology and physiology. In this study, we introduce PlantTraitNet, a multi-modal, multi-task uncertainty-aware deep learning framework that predictsfour key plant traits (plant height, leaf area, specific leaf area, and nitrogen content) from citizen science photos using weak supervision. By aggregating individual trait predictions across space, we generate global maps of trait distributions. We validate these maps against independent vegetation survey data (sPlotOpen) and benchmark them against leading global trait products. Our results show that PlantTraitNet consistently outperforms existing trait maps across all evaluated traits, demonstrating that citizen science imagery, when integrated with computer vision and geospatial AI, enables not only scalable but also more accurate global trait mapping. This approach offers a powerful new pathway for ecological research and Earth system modeling.",
    "authors": [
      "Ayushi Sharma",
      "Johanna Trost",
      "Daniel Lusk",
      "Johannes Dollinger",
      "Julian Schrader",
      "Christian Rossi",
      "Javier Lopatin",
      "Etienne Lalibert\u00e9",
      "Simon Haberstroh",
      "Jana Eichel",
      "Daniel Mederer",
      "Jose Miguel Cerda-Paredes",
      "Shyam S. Phartyal",
      "Lisa-Maricia Schwarz",
      "Anja Linst\u00e4dter",
      "Maria Concei\u00e7\u00e3o Caldeira",
      "Teja Kattenborn"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06943v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06943v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06767v1",
    "title": "QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration by Exploiting Common Patterns in Nonlinear Operations",
    "summary": "Transformer-based models have revolutionized computer vision (CV) and natural language processing (NLP) by achieving state-of-the-art performance across a range of benchmarks. However, nonlinear operations in models significantly contribute to inference latency, presenting unique challenges for efficient hardware acceleration. To this end, we propose QUARK, a quantization-enabled FPGA acceleration framework that leverages common patterns in nonlinear operations to enable efficient circuit sharing, thereby reducing hardware resource requirements. QUARK targets all nonlinear operations within Transformer-based models, achieving high-performance approximation through a novel circuit-sharing design tailored to accelerate these operations. Our evaluation demonstrates that QUARK significantly reduces the computational overhead of nonlinear operators in mainstream Transformer architectures, achieving up to a 1.96 times end-to-end speedup over GPU implementations. Moreover, QUARK lowers the hardware overhead of nonlinear modules by more than 50% compared to prior approaches, all while maintaining high model accuracy -- and even substantially boosting accuracy under ultra-low-bit quantization.",
    "authors": [
      "Zhixiong Zhao",
      "Haomin Li",
      "Fangxin Liu",
      "Yuncheng Lu",
      "Zongwu Wang",
      "Tao Yang",
      "Li Jiang",
      "Haibing Guan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06767v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06767v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07311v1",
    "title": "ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding",
    "summary": "Automatic ICD coding, the task of assigning disease and procedure codes to electronic medical records, is crucial for clinical documentation and billing. While existing methods primarily enhance model understanding of code hierarchies and synonyms, they often overlook the pervasive use of medical acronyms in clinical notes, a key factor in ICD code inference. To address this gap, we propose a novel effective data augmentation technique that leverages large language models to expand medical acronyms, allowing models to be trained on their full form representations. Moreover, we incorporate consistency training to regularize predictions by enforcing agreement between the original and augmented documents. Extensive experiments on the MIMIC-III dataset demonstrate that our approach, ACE-ICD establishes new state-of-the-art performance across multiple settings, including common codes, rare codes, and full-code assignments. Our code is publicly available.",
    "authors": [
      "Tuan-Dung Le",
      "Shohreh Haddadan",
      "Thanh Q. Thieu"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07311v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07311v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06625v1",
    "title": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT",
    "summary": "Low-dose chest computed tomography (LDCT) inherently captures both pulmonary and cardiac structures, offering a unique opportunity for joint assessment of lung and cardiovascular health. However, most existing approaches treat these domains as independent tasks, overlooking their physiological interplay and shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning Framework that enables interpretable cardiopulmonary risk assessment from a single LDCT scan. The framework introduces an agentic reasoning process that emulates clinical diagnostic thinking-first perceiving pulmonary findings, then reasoning through established medical knowledge, and finally deriving a cardiovascular judgment with explanatory rationale. It integrates three synergistic components: a pulmonary perception module that summarizes lung abnormalities, a knowledge-guided reasoning module that infers their cardiovascular implications, and a cardiac representation module that encodes structural biomarkers. Their outputs are fused to produce a holistic cardiovascular risk prediction that is both accurate and physiologically grounded. Experiments on the NLST cohort demonstrate that the proposed framework achieves state-of-the-art performance for CVD screening and mortality prediction, outperforming single-disease and purely image-based baselines. Beyond quantitative gains, the framework provides human-verifiable reasoning that aligns with cardiological understanding, revealing coherent links between pulmonary abnormalities and cardiac stress mechanisms. Overall, this work establishes a unified and explainable paradigm for cardiovascular analysis from LDCT, bridging the gap between image-based prediction and mechanism-based medical interpretation.",
    "authors": [
      "Yifei Zhang",
      "Jiashuo Zhang",
      "Xiaofeng Yang",
      "Liang Zhao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06625v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06625v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07399v1",
    "title": "StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation",
    "summary": "Generative models are reshaping the live-streaming industry by redefining how content is created, styled, and delivered. Previous image-based streaming diffusion models have powered efficient and creative live streaming products but have hit limits on temporal consistency due to the foundation of image-based designs. Recent advances in video diffusion have markedly improved temporal consistency and sampling efficiency for offline generation. However, offline generation systems primarily optimize throughput by batching large workloads. In contrast, live online streaming operates under strict service-level objectives (SLOs): time-to-first-frame must be minimal, and every frame must meet a per-frame deadline with low jitter. Besides, scalable multi-GPU serving for real-time streams remains largely unresolved so far. To address this, we present StreamDiffusionV2, a training-free pipeline for interactive live streaming with video diffusion models. StreamDiffusionV2 integrates an SLO-aware batching scheduler and a block scheduler, together with a sink-token--guided rolling KV cache, a motion-aware noise controller, and other system-level optimizations. Moreover, we introduce a scalable pipeline orchestration that parallelizes the diffusion process across denoising steps and network layers, achieving near-linear FPS scaling without violating latency guarantees. The system scales seamlessly across heterogeneous GPU environments and supports flexible denoising steps (e.g., 1--4), enabling both ultra-low-latency and higher-quality modes. Without TensorRT or quantization, StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four H100 GPUs, making state-of-the-art generative live streaming practical and accessible--from individual creators to enterprise-scale platforms.",
    "authors": [
      "Tianrui Feng",
      "Zhi Li",
      "Shuo Yang",
      "Haocheng Xi",
      "Muyang Li",
      "Xiuyu Li",
      "Lvmin Zhang",
      "Keting Yang",
      "Kelly Peng",
      "Song Han",
      "Maneesh Agrawala",
      "Kurt Keutzer",
      "Akio Kodaira",
      "Chenfeng Xu"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07399v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07399v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06794v1",
    "title": "Beyond Uniform Deletion: A Data Value-Weighted Framework for Certified Machine Unlearning",
    "summary": "As the right to be forgotten becomes legislated worldwide, machine unlearning mechanisms have emerged to efficiently update models for data deletion and enhance user privacy protection. However, existing machine unlearning algorithms frequently neglect the fact that different data points may contribute unequally to model performance (i.e., heterogeneous data values). Treat them equally in machine unlearning procedure can potentially degrading the performance of updated models. To address this limitation, we propose Data Value-Weighted Unlearning (DVWU), a general unlearning framework that accounts for data value heterogeneity into the unlearning process. Specifically, we design a weighting strategy based on data values, which are then integrated into the unlearning procedure to enable differentiated unlearning for data points with varying utility to the model. The DVWU framework can be broadly adapted to various existing machine unlearning methods. We use the one-step Newton update as an example for implementation, developing both output and objective perturbation algorithms to achieve certified unlearning. Experiments on both synthetic and real-world datasets demonstrate that our methods achieve superior predictive performance and robustness compared to conventional unlearning approaches. We further show the extensibility of our framework on gradient ascent method by incorporating the proposed weighting strategy into the gradient terms, highlighting the adaptability of DVWU for broader gradient-based deep unlearning methods.",
    "authors": [
      "Lisong He",
      "Yi Yang",
      "Xiangyu Chang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06794v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06794v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07293v1",
    "title": "Verifying rich robustness properties for neural networks",
    "summary": "Robustness is a important problem in AI alignment and safety, with models such as neural networks being increasingly used in safety-critical systems. In the last decade, a large body of work has emerged on local robustness, i.e., checking if the decision of a neural network remains unchanged when the input is slightly perturbed. However, many of these approaches require specialized encoding and often ignore the confidence of a neural network on its output. In this paper, our goal is to build a generalized framework to specify and verify variants of robustness in neural network verification. We propose a specification framework using a simple grammar, which is flexible enough to capture most existing variants. This allows us to introduce new variants of robustness that take into account the confidence of the neural network in its outputs. Next, we develop a novel and powerful unified technique to verify all such variants in a homogeneous way, viz., by adding a few additional layers to the neural network. This enables us to use any state-of-the-art neural network verification tool, without having to tinker with the encoding within, while incurring an approximation error that we show is bounded. We perform an extensive experimental evaluation over a large suite of 8870 benchmarks having 138M parameters in a largest network, and show that we are able to capture a wide set of robustness variants and outperform direct encoding approaches by a significant margin.",
    "authors": [
      "Mohammad Afzal",
      "S. Akshay",
      "Ashutosh Gupta"
    ],
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07293v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07293v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06944v1",
    "title": "From Attribution to Action: Jointly ALIGNing Predictions and Explanations",
    "summary": "Explanation-guided learning (EGL) has shown promise in aligning model predictions with interpretable reasoning, particularly in computer vision tasks. However, most approaches rely on external annotations or heuristic-based segmentation to supervise model explanations, which can be noisy, imprecise and difficult to scale. In this work, we provide both empirical and theoretical evidence that low-quality supervision signals can degrade model performance rather than improve it. In response, we propose ALIGN, a novel framework that jointly trains a classifier and a masker in an iterative manner. The masker learns to produce soft, task-relevant masks that highlight informative regions, while the classifier is optimized for both prediction accuracy and alignment between its saliency maps and the learned masks. By leveraging high-quality masks as guidance, ALIGN improves both interpretability and generalizability, showing its superiority across various settings. Experiments on the two domain generalization benchmarks, VLCS and Terra Incognita, show that ALIGN consistently outperforms six strong baselines in both in-distribution and out-of-distribution settings. Besides, ALIGN also yields superior explanation quality concerning sufficiency and comprehensiveness, highlighting its effectiveness in producing accurate and interpretable models.",
    "authors": [
      "Dongsheng Hong",
      "Chao Chen",
      "Yanhui Chen",
      "Shanshan Lin",
      "Zhihao Chen",
      "Xiangwen Liao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06944v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06944v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07238v1",
    "title": "Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation",
    "summary": "In autonomous driving and robotics, ensuring road safety and reliable decision-making critically depends on out-of-distribution (OOD) segmentation. While numerous methods have been proposed to detect anomalous objects on the road, leveraging the vision-language space-which provides rich linguistic knowledge-remains an underexplored field. We hypothesize that incorporating these linguistic cues can be especially beneficial in the complex contexts found in real-world autonomous driving scenarios.   To this end, we present a novel approach that trains a Text-Driven OOD Segmentation model to learn a semantically diverse set of objects in the vision-language space. Concretely, our approach combines a vision-language model's encoder with a transformer decoder, employs Distance-Based OOD prompts located at varying semantic distances from in-distribution (ID) classes, and utilizes OOD Semantic Augmentation for OOD representations. By aligning visual and textual information, our approach effectively generalizes to unseen objects and provides robust OOD segmentation in diverse driving environments.   We conduct extensive experiments on publicly available OOD segmentation datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets, demonstrating that our approach achieves state-of-the-art performance across both pixel-level and object-level evaluations. This result underscores the potential of vision-language-based OOD segmentation to bolster the safety and reliability of future autonomous driving systems.",
    "authors": [
      "Seungheon Song",
      "Jaekoo Lee"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07238v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07238v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07085v1",
    "title": "Achieving Effective Virtual Reality Interactions via Acoustic Gesture Recognition based on Large Language Models",
    "summary": "Natural and efficient interaction remains a critical challenge for virtual reality and augmented reality (VR/AR) systems. Vision-based gesture recognition suffers from high computational cost, sensitivity to lighting conditions, and privacy leakage concerns. Acoustic sensing provides an attractive alternative: by emitting inaudible high-frequency signals and capturing their reflections, channel impulse response (CIR) encodes how gestures perturb the acoustic field in a low-cost and user-transparent manner. However, existing CIR-based gesture recognition methods often rely on extensive training of models on large labeled datasets, making them unsuitable for few-shot VR scenarios. In this work, we propose the first framework that leverages large language models (LLMs) for CIR-based gesture recognition in VR/AR systems. Despite LLMs' strengths, it is non-trivial to achieve few-shot and zero-shot learning of CIR gestures due to their inconspicuous features. To tackle this challenge, we collect differential CIR rather than original CIR data. Moreover, we construct a real-world dataset collected from 10 participants performing 15 gestures across three categories (digits, letters, and shapes), with 10 repetitions each. We then conduct extensive experiments on this dataset using an LLM-adopted classifier. Results show that our LLM-based framework achieves accuracy comparable to classical machine learning baselines, while requiring no domain-specific retraining.",
    "authors": [
      "Xijie Zhang",
      "Fengliang He",
      "Hong-Ning Dai"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07085v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07085v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07327v1",
    "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction",
    "summary": "Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models.",
    "authors": [
      "Guoxin Chen",
      "Zile Qiao",
      "Xuanzhong Chen",
      "Donglei Yu",
      "Haotian Xu",
      "Wayne Xin Zhao",
      "Ruihua Song",
      "Wenbiao Yin",
      "Huifeng Yin",
      "Liwen Zhang",
      "Kuan Li",
      "Minpeng Liao",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07327v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07327v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07262v1",
    "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning",
    "summary": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.",
    "authors": [
      "Qile Jiang",
      "George Karniadakis"
    ],
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07262v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07262v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07290v1",
    "title": "CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference Quality Assessment of Compressed Video",
    "summary": "The prevalence of user-generated content (UGC) on platforms such as YouTube and TikTok has rendered no-reference (NR) perceptual video quality assessment (VQA) vital for optimizing video delivery. Nonetheless, the characteristics of non-professional acquisition and the subsequent transcoding of UGC video on sharing platforms present significant challenges for NR-VQA. Although NR-VQA models attempt to infer mean opinion scores (MOS), their modeling of subjective scores for compressed content remains limited due to the absence of fine-grained perceptual annotations of artifact types. To address these challenges, we propose CAMP-VQA, a novel NR-VQA framework that exploits the semantic understanding capabilities of large vision-language models. Our approach introduces a quality-aware prompting mechanism that integrates video metadata (e.g., resolution, frame rate, bitrate) with key fragments extracted from inter-frame variations to guide the BLIP-2 pretraining approach in generating fine-grained quality captions. A unified architecture has been designed to model perceptual quality across three dimensions: semantic alignment, temporal characteristics, and spatial characteristics. These multimodal features are extracted and fused, then regressed to video quality scores. Extensive experiments on a wide variety of UGC datasets demonstrate that our model consistently outperforms existing NR-VQA methods, achieving improved accuracy without the need for costly manual fine-grained annotations. Our method achieves the best performance in terms of average rank and linear correlation (SRCC: 0.928, PLCC: 0.938) compared to state-of-the-art methods. The source code and trained models, along with a user-friendly demo, are available at: https://github.com/xinyiW915/CAMP-VQA.",
    "authors": [
      "Xinyi Wang",
      "Angeliki Katsenou",
      "Junxiao Shen",
      "David Bull"
    ],
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.MM"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07290v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07290v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07338v1",
    "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas",
    "summary": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.",
    "authors": [
      "Zhen Wang",
      "Yufan Zhou",
      "Zhongyan Luo",
      "Lyumanshan Ye",
      "Adam Wood",
      "Man Yao",
      "Luoshang Pan"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07338v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07338v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.06859v1",
    "title": "TuckA: Hierarchical Compact Tensor Experts for Efficient Fine-Tuning",
    "summary": "Efficiently fine-tuning pre-trained models for downstream tasks is a key challenge in the era of foundation models. Parameter-efficient fine-tuning (PEFT) presents a promising solution, achieving performance comparable to full fine-tuning by updating only a small number of adaptation weights per layer. Traditional PEFT methods typically rely on a single expert, where the adaptation weight is a low-rank matrix. However, for complex tasks, the data's inherent diversity poses a significant challenge for such models, as a single adaptation weight cannot adequately capture the features of all samples. To address this limitation, we explore how to integrate multiple small adaptation experts into a compact structure to defeat a large adapter. Specifically, we propose Tucker Adaptation (TuckA), a method with four key properties: (i) We use Tucker decomposition to create a compact 3D tensor where each slice naturally serves as an expert. The low-rank nature of this decomposition ensures that the number of parameters scales efficiently as more experts are added. (ii) We introduce a hierarchical strategy that organizes these experts into groups at different granularities, allowing the model to capture both local and global data patterns. (iii) We develop an efficient batch-level routing mechanism, which reduces the router's parameter size by a factor of $L$ compared to routing at every adapted layer (where $L$ is the number of adapted layers) (iv) We propose data-aware initialization to achieve loss-free expert load balancing based on theoretical analysis. Extensive experiments on benchmarks in natural language understanding, image classification, and mathematical reasoning speak to the efficacy of TuckA, offering a new and effective solution to the PEFT problem.",
    "authors": [
      "Qifeng Lei",
      "Zhiyong Yang",
      "Qianqian Xu",
      "Cong Hua",
      "Peisong Wen",
      "Qingming Huang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06859v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06859v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.07003v1",
    "title": "Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs",
    "summary": "Large language models have significantly advanced Multilingual Machine Translation (MMT), yet the broad language coverage, consistent translation quality, and English-centric bias remain open challenges. To address these challenges, we introduce \\textbf{LMT}, a suite of \\textbf{L}arge-scale \\textbf{M}ultilingual \\textbf{T}ranslation models centered on both Chinese and English, covering 60 languages and 234 translation directions. During development, we identify a previously overlooked phenomenon of \\textbf{directional degeneration}, where symmetric multi-way fine-tuning data overemphasize reverse directions (X $\\to$ En/Zh), leading to excessive many-to-one mappings and degraded translation quality. We propose \\textbf{Strategic Downsampling}, a simple yet effective method to mitigate this degeneration. In addition, we design \\textbf{Parallel Multilingual Prompting (PMP)}, which leverages typologically related auxiliary languages to enhance cross-lingual transfer. Through rigorous data curation and refined adaptation strategies, LMT achieves SOTA performance among models of comparable language coverage, with our 4B model (LMT-60-4B) surpassing the much larger Aya-101-13B and NLLB-54B models by a substantial margin. We release LMT in four sizes (0.6B/1.7B/4B/8B) to catalyze future research and provide strong baselines for inclusive, scalable, and high-quality MMT \\footnote{\\href{https://github.com/NiuTrans/LMT}{https://github.com/NiuTrans/LMT}}.",
    "authors": [
      "Yingfeng Luo",
      "Ziqiang Xu",
      "Yuxuan Ouyang",
      "Murun Yang",
      "Dingyang Lin",
      "Kaiyan Chang",
      "Tong Zheng",
      "Bei Li",
      "Peinan Feng",
      "Quan Du",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07003v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07003v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.07166v1",
    "title": "AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and Dual-Channel Reasoning",
    "summary": "We propose AdaRec, a few-shot in-context learning framework that leverages large language models for an adaptive personalized recommendation. AdaRec introduces narrative profiling, transforming user-item interactions into natural language representations to enable unified task handling and enhance human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a dual-channel architecture that integrates horizontal behavioral alignment, discovering peer-driven patterns, with vertical causal attribution, highlighting decisive factors behind user preferences. Unlike existing LLM-based approaches, AdaRec eliminates manual feature engineering through semantic representations and supports rapid cross-task adaptation with minimal supervision. Experiments on real ecommerce datasets demonstrate that AdaRec outperforms both machine learning models and LLM-based baselines by up to eight percent in few-shot settings. In zero-shot scenarios, it achieves up to a nineteen percent improvement over expert-crafted profiling, showing effectiveness for long-tail personalization with minimal interaction data. Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec matches the performance of fully fine-tuned models, highlighting its efficiency and generalization across diverse tasks.",
    "authors": [
      "Meiyun Wang",
      "Charin Polpanumas"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07166v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07166v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06852v1",
    "title": "Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment",
    "summary": "Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.",
    "authors": [
      "Peng Zhang",
      "peijie sun"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06852v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06852v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06817v1",
    "title": "TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning",
    "summary": "Stereo matching in minimally invasive surgery (MIS) is essential for next-generation navigation and augmented reality. Yet, dense disparity supervision is nearly impossible due to anatomical constraints, typically limiting annotations to only a few image-level labels acquired before the endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a promising solution by leveraging a teacher trained on sparse labels to generate pseudo labels and associated confidence maps from abundant unlabeled surgical videos. However, existing TSL methods are confined to image-level supervision, providing only spatial confidence and lacking temporal consistency estimation. This absence of spatio-temporal reliability results in unstable disparity predictions and severe flickering artifacts across video frames. To overcome these challenges, we propose TiS-TSL, a novel time-switchable teacher-student learning framework for video stereo matching under minimal supervision. At its core is a unified model that operates in three distinct modes: Image-Prediction (IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP), enabling flexible temporal modeling within a single architecture. Enabled by this unified model, TiS-TSL adopts a two-stage learning strategy. The Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal disparity predictions by comparing forward and backward predictions to calculate bidirectional spatio-temporal consistency. This consistency identifies unreliable regions across frames, filters noisy video-level pseudo labels, and enforces temporal coherence. Experimental results on two public datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts by improving TEPE and EPE by at least 2.11% and 4.54%, respectively..",
    "authors": [
      "Rui Wang",
      "Ying Zhou",
      "Hao Wang",
      "Wenwei Zhang",
      "Qiang Li",
      "Zhiwei Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06817v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06817v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06678v1",
    "title": "Flexible Concept Bottleneck Model",
    "summary": "Concept bottleneck models (CBMs) improve neural network interpretability by introducing an intermediate layer that maps human-understandable concepts to predictions. Recent work has explored the use of vision-language models (VLMs) to automate concept selection and annotation. However, existing VLM-based CBMs typically require full model retraining when new concepts are involved, which limits their adaptability and flexibility in real-world scenarios, especially considering the rapid evolution of vision-language foundation models. To address these issues, we propose Flexible Concept Bottleneck Model (FCBM), which supports dynamic concept adaptation, including complete replacement of the original concept set. Specifically, we design a hypernetwork that generates prediction weights based on concept embeddings, allowing seamless integration of new concepts without retraining the entire model. In addition, we introduce a modified sparsemax module with a learnable temperature parameter that dynamically selects the most relevant concepts, enabling the model to focus on the most informative features. Extensive experiments on five public benchmarks demonstrate that our method achieves accuracy comparable to state-of-the-art baselines with a similar number of effective concepts. Moreover, the model generalizes well to unseen concepts with just a single epoch of fine-tuning, demonstrating its strong adaptability and flexibility.",
    "authors": [
      "Xingbo Du",
      "Qiantong Dou",
      "Lei Fan",
      "Rui Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06678v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06678v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07103v1",
    "title": "GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for Hyperspectral Image Super-resolution",
    "summary": "Improving the quality of hyperspectral images (HSIs), such as through super-resolution, is a crucial research area. However, generative modeling for HSIs presents several challenges. Due to their high spectral dimensionality, HSIs are too memory-intensive for direct input into conventional diffusion models. Furthermore, general generative models lack an understanding of the topological and geometric structures of ground objects in remote sensing imagery. In addition, most diffusion models optimize loss functions at the noise level, leading to a non-intuitive convergence behavior and suboptimal generation quality for complex data. To address these challenges, we propose a Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework for reconstructing hyperspectral images at 4-times super-resolution. A wavelet-based encoder-decoder is introduced that efficiently compresses HSIs into a latent space while preserving spectral-spatial information. To avoid distortion during generation, we incorporate a geometry-enhanced diffusion process that preserves the geometric features. Furthermore, a multi-level loss function was designed to guide the diffusion process, promoting stable convergence and improved reconstruction fidelity. Our model demonstrated state-of-the-art results across multiple dimensions, including fidelity, spectral accuracy, visual realism, and clarity.",
    "authors": [
      "Sirui Wang",
      "Jiang He",
      "Nat\u00e0lia Blasco Andreo",
      "Xiao Xiang Zhu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07103v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07103v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07156v1",
    "title": "Conditional Diffusion as Latent Constraints for Controllable Symbolic Music Generation",
    "summary": "Recent advances in latent diffusion models have demonstrated state-of-the-art performance in high-dimensional time-series data synthesis while providing flexible control through conditioning and guidance. However, existing methodologies primarily rely on musical context or natural language as the main modality of interacting with the generative process, which may not be ideal for expert users who seek precise fader-like control over specific musical attributes. In this work, we explore the application of denoising diffusion processes as plug-and-play latent constraints for unconditional symbolic music generation models. We focus on a framework that leverages a library of small conditional diffusion models operating as implicit probabilistic priors on the latents of a frozen unconditional backbone. While previous studies have explored domain-specific use cases, this work, to the best of our knowledge, is the first to demonstrate the versatility of such an approach across a diverse array of musical attributes, such as note density, pitch range, contour, and rhythm complexity. Our experiments show that diffusion-driven constraints outperform traditional attribute regularization and other latent constraints architectures, achieving significantly stronger correlations between target and generated attributes while maintaining high perceptual quality and diversity.",
    "authors": [
      "Matteo Petten\u00f3",
      "Alessandro Ilic Mezza",
      "Alberto Bernardini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07156v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07156v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07296v1",
    "title": "Who Is the Story About? Protagonist Entity Recognition in News",
    "summary": "News articles often reference numerous organizations, but traditional Named Entity Recognition (NER) treats all mentions equally, obscuring which entities genuinely drive the narrative. This limits downstream tasks that rely on understanding event salience, influence, or narrative focus. We introduce Protagonist Entity Recognition (PER), a task that identifies the organizations that anchor a news story and shape its main developments. To validate PER, we compare he predictions of Large Language Models (LLMs) against annotations from four expert annotators over a gold corpus, establishing both inter-annotator consistency and human-LLM agreement. Leveraging these findings, we use state-of-the-art LLMs to automatically label large-scale news collections through NER-guided prompting, generating scalable, high-quality supervision. We then evaluate whether other LLMs, given reduced context and without explicit candidate guidance, can still infer the correct protagonists. Our results demonstrate that PER is a feasible and meaningful extension to narrative-centered information extraction, and that guided LLMs can approximate human judgments of narrative importance at scale.",
    "authors": [
      "Jorge Gab\u00edn",
      "M. Eduardo Ares",
      "Javier Parapar"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07296v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07296v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07318v1",
    "title": "When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs",
    "summary": "Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.",
    "authors": [
      "Shaowen Wang",
      "Yiqi Dong",
      "Ruinian Chang",
      "Tansheng Zhu",
      "Yuebo Sun",
      "Kaifeng Lyu",
      "Jian Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07318v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07318v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07362v1",
    "title": "Inference-Time Scaling of Diffusion Models for Infrared Data Generation",
    "summary": "Infrared imagery enables temperature-based scene understanding using passive sensors, particularly under conditions of low visibility where traditional RGB imaging fails. Yet, developing downstream vision models for infrared applications is hindered by the scarcity of high-quality annotated data, due to the specialized expertise required for infrared annotation. While synthetic infrared image generation has the potential to accelerate model development by providing large-scale, diverse training data, training foundation-level generative diffusion models in the infrared domain has remained elusive due to limited datasets. In light of such data constraints, we explore an inference-time scaling approach using a domain-adapted CLIP-based verifier for enhanced infrared image generation quality. We adapt FLUX.1-dev, a state-of-the-art text-to-image diffusion model, to the infrared domain by finetuning it on a small sample of infrared images using parameter-efficient techniques. The trained verifier is then employed during inference to guide the diffusion sampling process toward higher quality infrared generations that better align with input text prompts. Empirically, we find that our approach leads to consistent improvements in generation quality, reducing FID scores on the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared to unguided baseline samples. Our results suggest that inference-time guidance offers a promising direction for bridging the domain gap in low-data infrared settings.",
    "authors": [
      "Kai A. Horstmann",
      "Maxim Clouser",
      "Kia Khezeli"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07362v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07362v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06854v1",
    "title": "Beyond Observations: Reconstruction Error-Guided Irregularly Sampled Time Series Representation Learning",
    "summary": "Irregularly sampled time series (ISTS), characterized by non-uniform time intervals with natural missingness, are prevalent in real-world applications. Existing approaches for ISTS modeling primarily rely on observed values to impute unobserved ones or infer latent dynamics. However, these methods overlook a critical source of learning signal: the reconstruction error inherently produced during model training. Such error implicitly reflects how well a model captures the underlying data structure and can serve as an informative proxy for unobserved values. To exploit this insight, we propose iTimER, a simple yet effective self-supervised pre-training framework for ISTS representation learning. iTimER models the distribution of reconstruction errors over observed values and generates pseudo-observations for unobserved timestamps through a mixup strategy between sampled errors and the last available observations. This transforms unobserved timestamps into noise-aware training targets, enabling meaningful reconstruction signals. A Wasserstein metric aligns reconstruction error distributions between observed and pseudo-observed regions, while a contrastive learning objective enhances the discriminability of learned representations. Extensive experiments on classification, interpolation, and forecasting tasks demonstrate that iTimER consistently outperforms state-of-the-art methods under the ISTS setting.",
    "authors": [
      "Jiexi Liu",
      "Meng Cao",
      "Songcan Chen"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06854v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06854v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06634v1",
    "title": "CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy Prediction",
    "summary": "Cross-domain HVAC energy prediction is essential for scalable building energy management, particularly because collecting extensive labeled data for every new building is both costly and impractical. Yet, this task remains highly challenging due to the scarcity and heterogeneity of data across different buildings, climate zones, and seasonal patterns. In particular, buildings situated in distinct climatic regions introduce variability that often leads existing methods to overfit to spurious correlations, rely heavily on expert intervention, or compromise on data diversity. To address these limitations, we propose CaberNet, a causal and interpretable deep sequence model that learns invariant (Markov blanket) representations for robust cross-domain prediction. In a purely data-driven fashion and without requiring any prior knowledge, CaberNet integrates i) a global feature gate trained with a self-supervised Bernoulli regularization to distinguish superior causal features from inferior ones, and ii) a domain-wise training scheme that balances domain contributions, minimizes cross-domain loss variance, and promotes latent factor independence. We evaluate CaberNet on real-world datasets collected from three buildings located in three climatically diverse cities, and it consistently outperforms all baselines, achieving a 22.9\\% reduction in normalized mean squared error (NMSE) compared to the best benchmark. Our code is available at https://github.com/rickzky1001/CaberNet-CRL.",
    "authors": [
      "Kaiyuan Zhai",
      "Jiacheng Cui",
      "Zhehao Zhang",
      "Junyu Xue",
      "Yang Deng",
      "Kui Wu",
      "Guoming Tang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06634v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06634v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06715v1",
    "title": "Sensor Calibration Model Balancing Accuracy, Real-time, and Efficiency",
    "summary": "Most on-device sensor calibration studies benchmark models only against three macroscopic requirements (i.e., accuracy, real-time, and resource efficiency), thereby hiding deployment bottlenecks such as instantaneous error and worst-case latency. We therefore decompose this triad into eight microscopic requirements and introduce Scare (Sensor Calibration model balancing Accuracy, Real-time, and Efficiency), an ultra-compressed transformer that fulfills them all. SCARE comprises three core components: (1) Sequence Lens Projector (SLP) that logarithmically compresses time-series data while preserving boundary information across bins, (2) Efficient Bitwise Attention (EBA) module that replaces costly multiplications with bitwise operations via binary hash codes, and (3) Hash optimization strategy that ensures stable training without auxiliary loss terms. Together, these components minimize computational overhead while maintaining high accuracy and compatibility with microcontroller units (MCUs). Extensive experiments on large-scale air-quality datasets and real microcontroller deployments demonstrate that Scare outperforms existing linear, hybrid, and deep-learning baselines, making Scare, to the best of our knowledge, the first model to meet all eight microscopic requirements simultaneously.",
    "authors": [
      "Jinyong Yun",
      "Hyungjin Kim",
      "Seokho Ahn",
      "Euijong Lee",
      "Young-Duk Seo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06715v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06715v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07092v1",
    "title": "Sample-efficient quantum error mitigation via classical learning surrogates",
    "summary": "The pursuit of practical quantum utility on near-term quantum processors is critically challenged by their inherent noise. Quantum error mitigation (QEM) techniques are leading solutions to improve computation fidelity with relatively low qubit-overhead, while full-scale quantum error correction remains a distant goal. However, QEM techniques incur substantial measurement overheads, especially when applied to families of quantum circuits parameterized by classical inputs. Focusing on zero-noise extrapolation (ZNE), a widely adopted QEM technique, here we devise the surrogate-enabled ZNE (S-ZNE), which leverages classical learning surrogates to perform ZNE entirely on the classical side. Unlike conventional ZNE, whose measurement cost scales linearly with the number of circuits, S-ZNE requires only constant measurement overhead for an entire family of quantum circuits, offering superior scalability. Theoretical analysis indicates that S-ZNE achieves accuracy comparable to conventional ZNE in many practical scenarios, and numerical experiments on up to 100-qubit ground-state energy and quantum metrology tasks confirm its effectiveness. Our approach provides a template that can be effectively extended to other quantum error mitigation protocols, opening a promising path toward scalable error mitigation.",
    "authors": [
      "Wei-You Liao",
      "Ge Yan",
      "Yujin Song",
      "Tian-Ci Tian",
      "Wei-Ming Zhu",
      "De-Tao Jiang",
      "Yuxuan Du",
      "He-Liang Huang"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07092v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07092v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06946v1",
    "title": "Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning",
    "summary": "Transformers have shown strong ability to model long-term dependencies and are increasingly adopted as world models in model-based reinforcement learning (RL) under partial observability. However, unlike natural language corpora, RL trajectories are sparse and reward-driven, making standard self-attention inefficient because it distributes weight uniformly across all past tokens rather than emphasizing the few transitions critical for control. To address this, we introduce structured inductive priors into the self-attention mechanism of the dynamics head: (i) per-head memory-length priors that constrain attention to task-specific windows, and (ii) distributional priors that learn smooth Gaussian weightings over past state-action pairs. We integrate these mechanisms into UniZero, a model-based RL agent with a Transformer-based world model that supports planning under partial observability. Experiments on the Atari 100k benchmark show that most efficiency gains arise from the Gaussian prior, which smoothly allocates attention to informative transitions, while memory-length priors often truncate useful signals with overly restrictive cut-offs. In particular, Gaussian Attention achieves a 77% relative improvement in mean human-normalized scores over UniZero. These findings suggest that in partially observable RL domains with non-stationary temporal dependencies, discrete memory windows are difficult to learn reliably, whereas smooth distributional priors flexibly adapt across horizons and yield more robust data efficiency. Overall, our results demonstrate that encoding structured temporal priors directly into self-attention improves the prioritization of informative histories for dynamics modeling under partial observability.",
    "authors": [
      "Daniel De Dios Allegue",
      "Jinke He",
      "Frans A. Oliehoek"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06946v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06946v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06721v1",
    "title": "AvatarTex: High-Fidelity Facial Texture Reconstruction from Single-Image Stylized Avatars",
    "summary": "We present AvatarTex, a high-fidelity facial texture reconstruction framework capable of generating both stylized and photorealistic textures from a single image. Existing methods struggle with stylized avatars due to the lack of diverse multi-style datasets and challenges in maintaining geometric consistency in non-standard textures. To address these limitations, AvatarTex introduces a novel three-stage diffusion-to-GAN pipeline. Our key insight is that while diffusion models excel at generating diversified textures, they lack explicit UV constraints, whereas GANs provide a well-structured latent space that ensures style and topology consistency. By integrating these strengths, AvatarTex achieves high-quality topology-aligned texture synthesis with both artistic and geometric coherence. Specifically, our three-stage pipeline first completes missing texture regions via diffusion-based inpainting, refines style and structure consistency using GAN-based latent optimization, and enhances fine details through diffusion-based repainting. To address the need for a stylized texture dataset, we introduce TexHub, a high-resolution collection of 20,000 multi-style UV textures with precise UV-aligned layouts. By leveraging TexHub and our structured diffusion-to-GAN pipeline, AvatarTex establishes a new state-of-the-art in multi-style facial texture reconstruction. TexHub will be released upon publication to facilitate future research in this field.",
    "authors": [
      "Yuda Qiu",
      "Zitong Xiao",
      "Yiwei Zuo",
      "Zisheng Ye",
      "Weikai Chen",
      "Xiaoguang Han"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06721v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06721v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07062v1",
    "title": "Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision",
    "summary": "Region representation learning plays a pivotal role in urban computing by extracting meaningful features from unlabeled urban data. Analogous to how perceived facial age reflects an individual's health, the visual appearance of a city serves as its ``portrait\", encapsulating latent socio-economic and environmental characteristics. Recent studies have explored leveraging Large Language Models (LLMs) to incorporate textual knowledge into imagery-based urban region representation learning. However, two major challenges remain: i)~difficulty in aligning fine-grained visual features with long captions, and ii) suboptimal knowledge incorporation due to noise in LLM-generated captions. To address these issues, we propose a novel pre-training framework called UrbanLN that improves Urban region representation learning through Long-text awareness and Noise suppression. Specifically, we introduce an information-preserved stretching interpolation strategy that aligns long captions with fine-grained visual semantics in complex urban scenes. To effectively mine knowledge from LLM-generated captions and filter out noise, we propose a dual-level optimization strategy. At the data level, a multi-model collaboration pipeline automatically generates diverse and reliable captions without human intervention. At the model level, we employ a momentum-based self-distillation mechanism to generate stable pseudo-targets, facilitating robust cross-modal learning under noisy conditions. Extensive experiments across four real-world cities and various downstream tasks demonstrate the superior performance of our UrbanLN.",
    "authors": [
      "Yimei Zhang",
      "Guojiang Shen",
      "Kaili Ning",
      "Tongwei Ren",
      "Xuebo Qiu",
      "Mengmeng Wang",
      "Xiangjie Kong"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07062v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07062v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06606v1",
    "title": "SPUR: A Plug-and-Play Framework for Integrating Spatial Audio Understanding and Reasoning into Large Audio-Language Models",
    "summary": "Spatial perception is central to auditory intelligence, enabling accurate understanding of real-world acoustic scenes and advancing human-level perception of the world around us. While recent large audio-language models (LALMs) show strong reasoning over complex audios, most operate on monaural inputs and lack the ability to capture spatial cues such as direction, elevation, and distance. We introduce SPUR, a lightweight, plug-in approach that equips LALMs with spatial perception through minimal architectural changes. SPUR consists of: (i) a First-Order Ambisonics (FOA) encoder that maps (W, X, Y, Z) channels to rotation-aware, listener-centric spatial features, integrated into target LALMs via a multimodal adapter; and (ii) SPUR-Set, a spatial QA dataset combining open-source FOA recordings with controlled simulations, emphasizing relative direction, elevation, distance, and overlap for supervised spatial reasoning. Fine-tuning our model on the SPUR-Set consistently improves spatial QA and multi-speaker attribution while preserving general audio understanding. SPUR provides a simple recipe that transforms monaural LALMs into spatially aware models. Extensive ablations validate the effectiveness of our approach.",
    "authors": [
      "S Sakshi",
      "Vaibhavi Lokegaonkar",
      "Neil Zhang",
      "Ramani Duraiswami",
      "Sreyan Ghosh",
      "Dinesh Manocha",
      "Lie Lu"
    ],
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06606v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06606v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06853v1",
    "title": "Deep learning EPI-TIRF cross-modality enables background subtraction and axial super-resolution for widefield fluorescence microscopy",
    "summary": "The resolving ability of wide-field fluorescence microscopy is fundamentally limited by out-of-focus background owing to its low axial resolution, particularly for densely labeled biological samples. To address this, we developed ET2dNet, a deep learning-based EPI-TIRF cross-modality network that achieves TIRF-comparable background subtraction and axial super-resolution from a single wide-field image without requiring hardware modifications. The model employs a physics-informed hybrid architecture, synergizing supervised learning with registered EPI-TIRF image pairs and self-supervised physical modeling via convolution with the point spread function. This framework ensures exceptional generalization across microscope objectives, enabling few-shot adaptation to new imaging setups. Rigorous validation on cellular and tissue samples confirms ET2dNet's superiority in background suppression and axial resolution enhancement, while maintaining compatibility with deconvolution techniques for lateral resolution improvement. Furthermore, by extending this paradigm through knowledge distillation, we developed ET3dNet, a dedicated three-dimensional reconstruction network that produces artifact-reduced volumetric results. ET3dNet effectively removes out-of-focus background signals even when the input image stack lacks the source of background. This framework makes axial super-resolution imaging more accessible by providing an easy-to-deploy algorithm that avoids additional hardware costs and complexity, showing great potential for live cell studies and clinical histopathology.",
    "authors": [
      "Qiushi Li",
      "Celi Lou",
      "Yanfang Cheng",
      "Bilang Gong",
      "Xinlin Chen",
      "Hao Chen",
      "Baowan Li",
      "Jieli Wang",
      "Yulin Wang",
      "Sipeng Yang",
      "Yunqing Tang",
      "Luru Dai"
    ],
    "categories": [
      "physics.optics",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06853v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06853v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07099v1",
    "title": "E2E-VGuard: Adversarial Prevention for Production LLM-based End-To-End Speech Synthesis",
    "summary": "Recent advancements in speech synthesis technology have enriched our daily lives, with high-quality and human-like audio widely adopted across real-world applications. However, malicious exploitation like voice-cloning fraud poses severe security risks. Existing defense techniques struggle to address the production large language model (LLM)-based speech synthesis. While previous studies have considered the protection for fine-tuning synthesizers, they assume manually annotated transcripts. Given the labor intensity of manual annotation, end-to-end (E2E) systems leveraging automatic speech recognition (ASR) to generate transcripts are becoming increasingly prevalent, e.g., voice cloning via commercial APIs. Therefore, this E2E speech synthesis also requires new security mechanisms. To tackle these challenges, we propose E2E-VGuard, a proactive defense framework for two emerging threats: (1) production LLM-based speech synthesis, and (2) the novel attack arising from ASR-driven E2E scenarios. Specifically, we employ the encoder ensemble with a feature extractor to protect timbre, while ASR-targeted adversarial examples disrupt pronunciation. Moreover, we incorporate the psychoacoustic model to ensure perturbative imperceptibility. For a comprehensive evaluation, we test 16 open-source synthesizers and 3 commercial APIs across Chinese and English datasets, confirming E2E-VGuard's effectiveness in timbre and pronunciation protection. Real-world deployment validation is also conducted. Our code and demo page are available at https://wxzyd123.github.io/e2e-vguard/.",
    "authors": [
      "Zhisheng Zhang",
      "Derui Wang",
      "Yifan Mi",
      "Zhiyong Wu",
      "Jie Gao",
      "Yuxin Cao",
      "Kai Ye",
      "Minhui Xue",
      "Jie Hao"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07099v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07099v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07332v1",
    "title": "Grounding Computer Use Agents on Human Demonstrations",
    "summary": "Building reliable computer-use agents requires grounding: accurately connecting natural language instructions to the correct on-screen elements. While large datasets exist for web and mobile interactions, high-quality resources for desktop environments are limited. To address this gap, we introduce GroundCUA, a large-scale desktop grounding dataset built from expert human demonstrations. It covers 87 applications across 12 categories and includes 56K screenshots, with every on-screen element carefully annotated for a total of over 3.56M human-verified annotations. From these demonstrations, we generate diverse instructions that capture a wide range of real-world tasks, providing high-quality data for model training. Using GroundCUA, we develop the GroundNext family of models that map instructions to their target UI elements. At both 3B and 7B scales, GroundNext achieves state-of-the-art results across five benchmarks using supervised fine-tuning, while requiring less than one-tenth the training data of prior work. Reinforcement learning post-training further improves performance, and when evaluated in an agentic setting on the OSWorld benchmark using o3 as planner, GroundNext attains comparable or superior results to models trained with substantially more data,. These results demonstrate the critical role of high-quality, expert-driven datasets in advancing general-purpose computer-use agents.",
    "authors": [
      "Aarash Feizi",
      "Shravan Nayak",
      "Xiangru Jian",
      "Kevin Qinghong Lin",
      "Kaixin Li",
      "Rabiul Awal",
      "Xing Han L\u00f9",
      "Johan Obando-Ceron",
      "Juan A. Rodriguez",
      "Nicolas Chapados",
      "David Vazquez",
      "Adriana Romero-Soriano",
      "Reihaneh Rabbany",
      "Perouz Taslakian",
      "Christopher Pal",
      "Spandana Gella",
      "Sai Rajeswar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07332v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07332v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.06778v1",
    "title": "SAFENLIDB: A Privacy-Preserving Safety Alignment Framework for LLM-based Natural Language Database Interfaces",
    "summary": "The rapid advancement of Large Language Models (LLMs) has driven significant progress in Natural Language Interface to Database (NLIDB). However, the widespread adoption of LLMs has raised critical privacy and security concerns. During interactions, LLMs may unintentionally expose confidential database contents or be manipulated by attackers to exfiltrate data through seemingly benign queries. While current efforts typically rely on rule-based heuristics or LLM agents to mitigate this leakage risk, these methods still struggle with complex inference-based attacks, suffer from high false positive rates, and often compromise the reliability of SQL queries. To address these challenges, we propose \\textsc{SafeNlidb}, a novel privacy-security alignment framework for LLM-based NLIDB. The framework features an automated pipeline that generates hybrid chain-of-thought interaction data from scratch, seamlessly combining implicit security reasoning with SQL generation. Additionally, we introduce reasoning warm-up and alternating preference optimization to overcome the multi-preference oscillations of Direct Preference Optimization (DPO), enabling LLMs to produce security-aware SQL through fine-grained reasoning without the need for human-annotated preference data. Extensive experiments demonstrate that our method outperforms both larger-scale LLMs and ideal-setting baselines, achieving significant security improvements while preserving high utility.WARNING: This work may contain content that is offensive and harmful!",
    "authors": [
      "Ruiheng Liu",
      "XiaoBing Chen",
      "Jinyu Zhang",
      "Qiongwen Zhang",
      "Yu Zhang",
      "Bailong Yang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06778v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06778v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.06645v1",
    "title": "Adaptive Testing for Segmenting Watermarked Texts From Language Models",
    "summary": "The rapid adoption of large language models (LLMs), such as GPT-4 and Claude 3.5, underscores the need to distinguish LLM-generated text from human-written content to mitigate the spread of misinformation and misuse in education. One promising approach to address this issue is the watermark technique, which embeds subtle statistical signals into LLM-generated text to enable reliable identification. In this paper, we first generalize the likelihood-based LLM detection method of a previous study by introducing a flexible weighted formulation, and further adapt this approach to the inverse transform sampling method. Moving beyond watermark detection, we extend this adaptive detection strategy to tackle the more challenging problem of segmenting a given text into watermarked and non-watermarked substrings. In contrast to the approach in a previous study, which relies on accurate estimation of next-token probabilities that are highly sensitive to prompt estimation, our proposed framework removes the need for precise prompt estimation. Extensive numerical experiments demonstrate that the proposed methodology is both effective and robust in accurately segmenting texts containing a mixture of watermarked and non-watermarked content.",
    "authors": [
      "Xingchi Li",
      "Xiaochi Liu",
      "Guanxun Li"
    ],
    "categories": [
      "stat.ML",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06645v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06645v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07364v1",
    "title": "Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence Estimation for Failure Detection",
    "summary": "Reliability and failure detection of large language models (LLMs) is critical for their deployment in high-stakes, multi-step reasoning tasks. Prior work explores confidence estimation for self-evaluating LLM-scorer systems, with confidence scorers estimating the likelihood of errors in LLM responses. However, most methods focus on single-step outputs and overlook the challenges of multi-step reasoning. In this work, we extend self-evaluation techniques to multi-step tasks, testing two intuitive approaches: holistic scoring and step-by-step scoring. Using two multi-step benchmark datasets, we show that stepwise evaluation generally outperforms holistic scoring in detecting potential errors, with up to 15% relative increase in AUC-ROC. Our findings demonstrate that self-evaluating LLM systems provide meaningful confidence estimates in complex reasoning, improving their trustworthiness and providing a practical framework for failure detection.",
    "authors": [
      "Vaibhav Mavi",
      "Shubh Jaroria",
      "Weiqi Sun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07364v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07364v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06826v1",
    "title": "Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection",
    "summary": "Detecting Alzheimer's disease (AD) from narrative transcripts challenges large language models (LLMs): pre-training rarely covers this out-of-distribution task, and all transcript demos describe the same scene, producing highly homogeneous contexts. These factors cripple both the model's built-in task knowledge (\\textbf{task cognition}) and its ability to surface subtle, class-discriminative cues (\\textbf{contextual perception}). Because cognition is fixed after pre-training, improving in-context learning (ICL) for AD detection hinges on enriching perception through better demonstration (demo) sets. We demonstrate that standard ICL quickly saturates, its demos lack diversity (context width) and fail to convey fine-grained signals (context depth), and that recent task vector (TV) approaches improve broad task adaptation by injecting TV into the LLMs' hidden states (HSs), they are ill-suited for AD detection due to the mismatch of injection granularity, strength and position. To address these bottlenecks, we introduce \\textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands context width via \\emph{\\textbf{Diverse and Contrastive Retrieval}} (DCR) and deepens each demo's signal via \\emph{\\textbf{Projected Vector Anchoring}} (PVA) at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large, stable gains over both ICL and TV baselines, charting a new paradigm for fine-grained, OOD and low-resource LLM adaptation.",
    "authors": [
      "Puzhen Su",
      "Haoran Yin",
      "Yongzhu Miao",
      "Jintao Tang",
      "Shasha Li",
      "Ting Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06826v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06826v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07032v1",
    "title": "Fair Bayesian Data Selection via Generalized Discrepancy Measures",
    "summary": "Fairness concerns are increasingly critical as machine learning models are deployed in high-stakes applications. While existing fairness-aware methods typically intervene at the model level, they often suffer from high computational costs, limited scalability, and poor generalization. To address these challenges, we propose a Bayesian data selection framework that ensures fairness by aligning group-specific posterior distributions of model parameters and sample weights with a shared central distribution. Our framework supports flexible alignment via various distributional discrepancy measures, including Wasserstein distance, maximum mean discrepancy, and $f$-divergence, allowing geometry-aware control without imposing explicit fairness constraints. This data-centric approach mitigates group-specific biases in training data and improves fairness in downstream tasks, with theoretical guarantees. Experiments on benchmark datasets show that our method consistently outperforms existing data selection and model-based fairness methods in both fairness and accuracy.",
    "authors": [
      "Yixuan Zhang",
      "Jiabin Luo",
      "Zhenggang Wang",
      "Feng Zhou",
      "Quyu Kong"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07032v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07032v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07210v1",
    "title": "Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with Generative Trigger Optimization",
    "summary": "Clean-image backdoor attacks, which use only label manipulation in training datasets to compromise deep neural networks, pose a significant threat to security-critical applications. A critical flaw in existing methods is that the poison rate required for a successful attack induces a proportional, and thus noticeable, drop in Clean Accuracy (CA), undermining their stealthiness. This paper presents a new paradigm for clean-image attacks that minimizes this accuracy degradation by optimizing the trigger itself. We introduce Generative Clean-Image Backdoors (GCB), a framework that uses a conditional InfoGAN to identify naturally occurring image features that can serve as potent and stealthy triggers. By ensuring these triggers are easily separable from benign task-related features, GCB enables a victim model to learn the backdoor from an extremely small set of poisoned examples, resulting in a CA drop of less than 1%. Our experiments demonstrate GCB's remarkable versatility, successfully adapting to six datasets, five architectures, and four tasks, including the first demonstration of clean-image backdoors in regression and segmentation. GCB also exhibits resilience against most of the existing backdoor defenses.",
    "authors": [
      "Binyan Xu",
      "Fan Yang",
      "Di Tang",
      "Xilin Dai",
      "Kehuan Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07210v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07210v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07286v1",
    "title": "Glioma C6: A Novel Dataset for Training and Benchmarking Cell Segmentation",
    "summary": "We present Glioma C6, a new open dataset for instance segmentation of glioma C6 cells, designed as both a benchmark and a training resource for deep learning models. The dataset comprises 75 high-resolution phase-contrast microscopy images with over 12,000 annotated cells, providing a realistic testbed for biomedical image analysis. It includes soma annotations and morphological cell categorization provided by biologists. Additional categorization of cells, based on morphology, aims to enhance the utilization of image data for cancer cell research. Glioma C6 consists of two parts: the first is curated with controlled parameters for benchmarking, while the second supports generalization testing under varying conditions. We evaluate the performance of several generalist segmentation models, highlighting their limitations on our dataset. Our experiments demonstrate that training on Glioma C6 significantly enhances segmentation performance, reinforcing its value for developing robust and generalizable models. The dataset is publicly available for researchers.",
    "authors": [
      "Roman Malashin",
      "Svetlana Pashkevich",
      "Daniil Ilyukhin",
      "Arseniy Volkov",
      "Valeria Yachnaya",
      "Andrey Denisov",
      "Maria Mikhalkova"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07286v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07286v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06739v1",
    "title": "Rank-1 LoRAs Encode Interpretable Reasoning Signals",
    "summary": "Reasoning models leverage inference-time compute to significantly enhance the performance of language models on difficult logical tasks, and have become a dominating paradigm in frontier LLMs. Despite their wide adoption, the mechanisms underpinning the enhanced performance of these reasoning models are not well understood. In this work, we show that the majority of new capabilities in reasoning models can be elicited by small, single-rank changes to base model parameters, with many of these changes being interpretable. Specifically, we use a rank-1 LoRA to create a minimal parameter adapter for Qwen-2.5-32B-Instruct which recovers 73-90% of reasoning-benchmark performance compared to a full parameter finetune. We find that the activations of this LoRA are as interpretable as MLP neurons, and fire for reasoning-specific behaviors. Finally, we train a sparse autoencoder on the entire activation state of this LoRA and identify fine-grained and monosemantic features. Our findings highlight that reasoning performance can arise largely from minimal changes to base model parameters, and explore what these changes affect. More broadly, our work shows that parameter-efficient training methods can be used as a targeted lens for uncovering fundamental insights about language model behavior and dynamics.",
    "authors": [
      "Jake Ward",
      "Paul Riechers",
      "Adam Shai"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06739v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06739v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06662v1",
    "title": "Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug Interactions",
    "summary": "Drug-drug interactions (DDIs) remain a major source of preventable harm, and many clinically important mechanisms are still unknown. Existing models either rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on electronic health records (EHRs), which are noisy, temporal, and site-dependent. We introduce, to our knowledge, the first system that conditions KG relation scoring on patient-level EHR context and distills that reasoning into an EHR-only model for zero-shot inference. A fusion \"Teacher\" learns mechanism-specific relations for drug pairs represented in both sources, while a distilled \"Student\" generalizes to new or rarely used drugs without KG access at inference. Both operate under a shared ontology (set) of pharmacologic mechanisms (drug relations) to produce interpretable, auditable alerts rather than opaque risk scores. Trained on a multi-institution EHR corpus paired with a curated DrugBank DDI graph, and evaluated using a clinically aligned, decision-focused protocol with leakage-safe negatives that avoid artificially easy pairs, the system maintains precision across multi-institutuion test data, produces mechanism-specific, clinically consistent predictions, reduces false alerts (higher precision) at comparable overall detection performance (F1), and misses fewer true interactions compared to prior methods. Case studies further show zero-shot identification of clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs absent from the KG, supporting real-world use in clinical decision support and pharmacovigilance.",
    "authors": [
      "Franklin Lee",
      "Tengfei Ma"
    ],
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06662v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06662v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06633v1",
    "title": "Dual-branch Spatial-Temporal Self-supervised Representation for Enhanced Road Network Learning",
    "summary": "Road network representation learning (RNRL) has attracted increasing attention from both researchers and practitioners as various spatiotemporal tasks are emerging. Recent advanced methods leverage Graph Neural Networks (GNNs) and contrastive learning to characterize the spatial structure of road segments in a self-supervised paradigm. However, spatial heterogeneity and temporal dynamics of road networks raise severe challenges to the neighborhood smoothing mechanism of self-supervised GNNs. To address these issues, we propose a $\\textbf{D}$ual-branch $\\textbf{S}$patial-$\\textbf{T}$emporal self-supervised representation framework for enhanced road representations, termed as DST. On one hand, DST designs a mix-hop transition matrix for graph convolution to incorporate dynamic relations of roads from trajectories. Besides, DST contrasts road representations of the vanilla road network against that of the hypergraph in a spatial self-supervised way. The hypergraph is newly built based on three types of hyperedges to capture long-range relations. On the other hand, DST performs next token prediction as the temporal self-supervised task on the sequences of traffic dynamics based on a causal Transformer, which is further regularized by differentiating traffic modes of weekdays from those of weekends. Extensive experiments against state-of-the-art methods verify the superiority of our proposed framework. Moreover, the comprehensive spatiotemporal modeling facilitates DST to excel in zero-shot learning scenarios.",
    "authors": [
      "Qinghong Guo",
      "Yu Wang",
      "Ji Cao",
      "Tongya Zheng",
      "Junshu Dai",
      "Bingde Hu",
      "Shunyu Liu",
      "Canghong Jin"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06633v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06633v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07367v1",
    "title": "Machine-Learning Accelerated Calculations of Reduced Density Matrices",
    "summary": "$n$-particle reduced density matrices ($n$-RDMs) play a central role in understanding correlated phases of matter. Yet the calculation of $n$-RDMs is often computationally inefficient for strongly-correlated states, particularly when the system sizes are large. In this work, we propose to use neural network (NN) architectures to accelerate the calculation of, and even predict, the $n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs are often smooth functions over the Brillouin zone (BZ) (certainly true for gapped states) and are thus interpolable, allowing NNs trained on small-size $n$-RDMs to predict large-size ones. Building on this intuition, we devise two NNs: (i) a self-attention NN that maps random RDMs to physical ones, and (ii) a Sinusoidal Representation Network (SIREN) that directly maps momentum-space coordinates to RDM values. We test the NNs in three 2D models: the pair-pair correlation functions of the Richardson model of superconductivity, the translationally-invariant 1-RDM in a four-band model with short-range repulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model. We find that a SIREN trained on a $6\\times 6$ momentum mesh can predict the $18\\times 18$ pair-pair correlation function with a relative accuracy of $0.839$. The NNs trained on $6\\times 6 \\sim 8\\times 8$ meshes can provide high-quality initial guesses for $50\\times 50$ translation-invariant Hartree-Fock (HF) and $30\\times 30$ fully translation-breaking-allowed HF, reducing the number of iterations required for convergence by up to $91.63\\%$ and $92.78\\%$, respectively, compared to random initializations. Our results illustrate the potential of using NN-based methods for interpolable $n$-RDMs, which might open a new avenue for future research on strongly correlated phases.",
    "authors": [
      "Awwab A. Azam",
      "Lexu Zhao",
      "Jiabin Yu"
    ],
    "categories": [
      "cond-mat.str-el",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07367v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07367v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06842v1",
    "title": "MI-to-Mid Distilled Compression (M2M-DC): An Hybrid-Information-Guided-Block Pruning with Progressive Inner Slicing Approach to Model Compression",
    "summary": "We introduce MI-to-Mid Distilled Compression (M2M-DC), a two-scale, shape-safe compression framework that interleaves information-guided block pruning with progressive inner slicing and staged knowledge distillation (KD). First, M2M-DC ranks residual (or inverted-residual) blocks by a label-aware mutual information (MI) signal and removes the least informative units (structured prune-after-training). It then alternates short KD phases with stage-coherent, residual-safe channel slicing: (i) stage \"planes\" (co-slicing conv2 out-channels with the downsample path and next-stage inputs), and (ii) an optional mid-channel trim (conv1 out / bn1 / conv2 in). This targets complementary redundancy, whole computational motifs and within-stage width while preserving residual shape invariants. On CIFAR-100, M2M-DC yields a clean accuracy-compute frontier. For ResNet-18, we obtain 85.46% Top-1 with 3.09M parameters and 0.0139 GMacs (72% params, 63% GMacs vs. teacher; mean final 85.29% over three seeds). For ResNet-34, we reach 85.02% Top-1 with 5.46M params and 0.0195 GMacs (74% / 74% vs. teacher; mean final 84.62%). Extending to inverted-residuals, MobileNetV2 achieves a mean final 68.54% Top-1 at 1.71M params (27%) and 0.0186 conv GMacs (24%), improving over the teacher's 66.03% by +2.5 points across three seeds. Because M2M-DC exposes only a thin, architecture-aware interface (blocks, stages, and down sample/skip wiring), it generalizes across residual CNNs and extends to inverted-residual families with minor legalization rules. The result is a compact, practical recipe for deployment-ready models that match or surpass teacher accuracy at a fraction of the compute.",
    "authors": [
      "Lionel Levine",
      "Sajjad Ghiasvand",
      "Haniyeh Ehsani Oskouie",
      "Majid Sarrafzadeh"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06842v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06842v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07047v1",
    "title": "Anatomy-Aware Lymphoma Lesion Detection in Whole-Body PET/CT",
    "summary": "Early cancer detection is crucial for improving patient outcomes, and 18F FDG PET/CT imaging plays a vital role by combining metabolic and anatomical information. Accurate lesion detection remains challenging due to the need to identify multiple lesions of varying sizes. In this study, we investigate the effect of adding anatomy prior information to deep learning-based lesion detection models. In particular, we add organ segmentation masks from the TotalSegmentator tool as auxiliary inputs to provide anatomical context to nnDetection, which is the state-of-the-art for lesion detection, and Swin Transformer. The latter is trained in two stages that combine self-supervised pre-training and supervised fine-tuning. The method is tested in the AutoPET and Karolinska lymphoma datasets. The results indicate that the inclusion of anatomical priors substantially improves the detection performance within the nnDetection framework, while it has almost no impact on the performance of the vision transformer. Moreover, we observe that Swin Transformer does not offer clear advantages over conventional convolutional neural network (CNN) encoders used in nnDetection. These findings highlight the critical role of the anatomical context in cancer lesion detection, especially in CNN-based models.",
    "authors": [
      "Simone Bendazzoli",
      "Antonios Tzortzakakis",
      "Andreas Abrahamsson",
      "Bj\u00f6rn Engelbrekt Wahlin",
      "\u00d6rjan Smedby",
      "Maria Holstensson",
      "Rodrigo Moreno"
    ],
    "categories": [
      "eess.IV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07047v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07047v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07417v1",
    "title": "Language Generation with Infinite Contamination",
    "summary": "We study language generation in the limit, where an algorithm observes an adversarial enumeration of strings from an unknown target language $K$ and must eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan [KM24] proved that generation is achievable in surprisingly general settings. But their generator suffers from ``mode collapse,'' producing from an ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25] require the generator's output to be ``dense'' in the target language. They showed that generation with density, surprisingly, remains achievable at the same generality.   Both results assume perfect data: no noisy insertions and no omissions. This raises a central question: how much contamination can generation tolerate? Recent works made partial progress on this question by studying (non-dense) generation with either finite amounts of noise (but no omissions) or omissions (but no noise).   We characterize robustness under contaminated enumerations: 1. Generation under Contamination: Language generation in the limit is achievable for all countable collections iff the fraction of contaminated examples converges to zero. When this fails, we characterize which collections are generable. 2. Dense Generation under Contamination: Dense generation is strictly less robust to contamination than generation. As a byproduct, we resolve an open question of Raman and Raman [ICML25] by showing that generation is possible with only membership oracle access under finitely many contaminated examples.   Finally, we introduce a beyond-worst-case model inspired by curriculum learning and prove that dense generation is achievable even with infinite contamination provided the fraction of contaminated examples converges to zero. This suggests curriculum learning may be crucial for learning from noisy web data.",
    "authors": [
      "Anay Mehrotra",
      "Grigoris Velegkas",
      "Xifan Yu",
      "Felix Zhou"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.DS",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07417v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07417v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07129v1",
    "title": "LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging",
    "summary": "Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for fine-tuning large language models.However, conventional LoRA adapters are typically trained for a single task, limiting their applicability in real-world settings where inputs may span diverse and unpredictable domains. At inference time, existing approaches combine multiple LoRAs for improving performance on diverse tasks, while usually requiring labeled data or additional task-specific training, which is expensive at scale. In this work, we introduce LoRA on the Go (LoGo), a training-free framework that dynamically selects and merges adapters at the instance level without any additional requirements. LoGo leverages signals extracted from a single forward pass through LoRA adapters, to identify the most relevant adapters and determine their contributions on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo outperforms training-based baselines on some tasks upto a margin of 3.6% while remaining competitive on other tasks and maintaining inference throughput, highlighting its effectiveness and practicality.",
    "authors": [
      "Seungeon Lee",
      "Soumi Das",
      "Manish Gupta",
      "Krishna P. Gummadi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07129v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07129v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07124v1",
    "title": "Think Consistently, Reason Efficiently: Energy-Based Calibration for Implicit Chain-of-Thought",
    "summary": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities through \\emph{Chain-of-Thought} (CoT) prompting, which enables step-by-step intermediate reasoning. However, explicit CoT methods rely on discrete token-level reasoning processes that are prone to error propagation and limited by vocabulary expressiveness, often resulting in rigid and inconsistent reasoning trajectories. Recent research has explored implicit or continuous reasoning in latent spaces, allowing models to perform internal reasoning before generating explicit output. Although such approaches alleviate some limitations of discrete CoT, they generally lack explicit mechanisms to enforce consistency among reasoning steps, leading to divergent reasoning paths and unstable outcomes. To address this issue, we propose EBM-CoT, an Energy-Based Chain-of-Thought Calibration framework that refines latent thought representations through an energy-based model (EBM). Our method dynamically adjusts latent reasoning trajectories toward lower-energy, high-consistency regions in the embedding space, improving both reasoning accuracy and consistency without modifying the base language model. Extensive experiments across mathematical, commonsense, and symbolic reasoning benchmarks demonstrate that the proposed framework significantly enhances the consistency and efficiency of multi-step reasoning in LLMs.",
    "authors": [
      "Zhikang Chen",
      "Sen Cui",
      "Deheng Ye",
      "Yu Zhang",
      "Yatao Bian",
      "Tingting Zhu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07124v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07124v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07084v1",
    "title": "Pandar128 dataset for lane line detection",
    "summary": "We present Pandar128, the largest public dataset for lane line detection using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR scans, captured in diverse real-world conditions in Germany. The dataset includes full sensor calibration (intrinsics, extrinsics) and synchronized odometry, supporting tasks such as projection, fusion, and temporal modeling.   To complement the dataset, we also introduce SimpleLidarLane, a light-weight baseline method for lane line reconstruction that combines BEV segmentation, clustering, and polyline fitting. Despite its simplicity, our method achieves strong performance under challenging various conditions (e.g., rain, sparse returns), showing that modular pipelines paired with high-quality data and principled evaluation can compete with more complex approaches.   Furthermore, to address the lack of standardized evaluation, we propose a novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that employs interpolation-aware lateral matching in BEV space.   All data and code are publicly released to support reproducibility in LiDAR-based lane detection.",
    "authors": [
      "Filip Ber\u00e1nek",
      "V\u00e1clav Divi\u0161",
      "Ivan Gruber"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07084v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07084v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07250v1",
    "title": "MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs",
    "summary": "The advent of Multimodal Large Language Models (MLLMs) has expanded AI capabilities to visual modalities, yet existing evaluation benchmarks remain limited to single-video understanding, overlooking the critical need for multi-video understanding in real-world scenarios (e.g., sports analytics and autonomous driving). To address this significant gap, we introduce MVU-Eval, the first comprehensive benchmark for evaluating Multi-Video Understanding for MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies through 1,824 meticulously curated question-answer pairs spanning 4,959 videos from diverse domains, addressing both fundamental perception tasks and high-order reasoning tasks. These capabilities are rigorously aligned with real-world applications such as multi-sensor synthesis in autonomous systems and cross-angle sports analytics. Through extensive evaluation of state-of-the-art open-source and closed-source models, we reveal significant performance discrepancies and limitations in current MLLMs' ability to perform understanding across multiple videos. The benchmark will be made publicly available to foster future research.",
    "authors": [
      "Tianhao Peng",
      "Haochen Wang",
      "Yuanxing Zhang",
      "Zekun Wang",
      "Zili Wang",
      "Ge Zhang",
      "Jian Yang",
      "Shihao Li",
      "Yanghai Wang",
      "Xintao Wang",
      "Houyi Li",
      "Wei Ji",
      "Pengfei Wan",
      "Wenhao Huang",
      "Zhaoxiang Zhang",
      "Jiaheng Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07250v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07250v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06793v1",
    "title": "Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models",
    "summary": "Multimodal Large Language Models (MLLMs) extend foundation models to real-world applications by integrating inputs such as text and vision. However, their broad knowledge capacity raises growing concerns about privacy leakage, toxicity mitigation, and intellectual property violations. Machine Unlearning (MU) offers a practical solution by selectively forgetting targeted knowledge while preserving overall model utility. When applied to MLLMs, existing neuron-editing-based MU approaches face two fundamental challenges: (1) forgetting becomes inconsistent across modalities because existing point-wise attribution methods fail to capture the structured, layer-by-layer information flow that connects different modalities; and (2) general knowledge performance declines when sensitive neurons that also support important reasoning paths are pruned, as this disrupts the model's ability to generalize. To alleviate these limitations, we propose a multimodal influential neuron path editor (MIP-Editor) for MU. Our approach introduces modality-specific attribution scores to identify influential neuron paths responsible for encoding forget-set knowledge and applies influential-path-aware neuron-editing via representation misdirection. This strategy also enables effective and coordinated forgetting across modalities while preserving the model's general capabilities. Experimental results demonstrate that MIP-Editor achieves a superior unlearning performance on multimodal tasks, with a maximum forgetting rate of 87.75% and up to 54.26% improvement in general knowledge retention. On textual tasks, MIP-Editor achieves up to 80.65% forgetting and preserves 77.9% of general performance. Codes are available at https://github.com/PreckLi/MIP-Editor.",
    "authors": [
      "Kunhao Li",
      "Wenhao Li",
      "Di Wu",
      "Lei Yang",
      "Jun Bai",
      "Ju Jia",
      "Jason Xue"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06793v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06793v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06947v1",
    "title": "FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection",
    "summary": "The well-aligned attribute of CLIP-based models enables its effective application like CLIPscore as a widely adopted image quality assessment metric. However, such a CLIP-based metric is vulnerable for its delicate multimodal alignment. In this work, we propose \\textbf{FoCLIP}, a feature-space misalignment framework for fooling CLIP-based image quality metric. Based on the stochastic gradient descent technique, FoCLIP integrates three key components to construct fooling examples: feature alignment as the core module to reduce image-text modality gaps, the score distribution balance module and pixel-guard regularization, which collectively optimize multimodal output equilibrium between CLIPscore performance and image quality. Such a design can be engineered to maximize the CLIPscore predictions across diverse input prompts, despite exhibiting either visual unrecognizability or semantic incongruence with the corresponding adversarial prompts from human perceptual perspectives. Experiments on ten artistic masterpiece prompts and ImageNet subsets demonstrate that optimized images can achieve significant improvement in CLIPscore while preserving high visual fidelity. In addition, we found that grayscale conversion induces significant feature degradation in fooling images, exhibiting noticeable CLIPscore reduction while preserving statistical consistency with original images. Inspired by this phenomenon, we propose a color channel sensitivity-driven tampering detection mechanism that achieves 91% accuracy on standard benchmarks. In conclusion, this work establishes a practical pathway for feature misalignment in CLIP-based multimodal systems and the corresponding defense method.",
    "authors": [
      "Yulin Chen",
      "Zeyuan Wang",
      "Tianyuan Yu",
      "Yingmei Wei",
      "Liang Bai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06947v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06947v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06608v1",
    "title": "Beyond Fixed Depth: Adaptive Graph Neural Networks for Node Classification Under Varying Homophily",
    "summary": "Graph Neural Networks (GNNs) have achieved significant success in addressing node classification tasks. However, the effectiveness of traditional GNNs degrades on heterophilic graphs, where connected nodes often belong to different labels or properties. While recent work has introduced mechanisms to improve GNN performance under heterophily, certain key limitations still exist. Most existing models apply a fixed aggregation depth across all nodes, overlooking the fact that nodes may require different propagation depths based on their local homophily levels and neighborhood structures. Moreover, many methods are tailored to either homophilic or heterophilic settings, lacking the flexibility to generalize across both regimes. To address these challenges, we develop a theoretical framework that links local structural and label characteristics to information propagation dynamics at the node level. Our analysis shows that optimal aggregation depth varies across nodes and is critical for preserving class-discriminative information. Guided by this insight, we propose a novel adaptive-depth GNN architecture that dynamically selects node-specific aggregation depths using theoretically grounded metrics. Our method seamlessly adapts to both homophilic and heterophilic patterns within a unified model. Extensive experiments demonstrate that our approach consistently enhances the performance of standard GNN backbones across diverse benchmarks.",
    "authors": [
      "Asela Hevapathige",
      "Asiri Wijesinghe",
      "Ahad N. Zehmakan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06608v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06608v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07107v1",
    "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks",
    "summary": "Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment.",
    "authors": [
      "Liang Shan",
      "Kaicheng Shen",
      "Wen Wu",
      "Zhenyu Ying",
      "Chaochao Lu",
      "Guangze Ye",
      "Liang He"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07107v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07107v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07010v1",
    "title": "A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided Judge-Corrector System for Multimodal Machine Translation",
    "summary": "In this paper, we describe our system under the team name BLEU Monday for the English-to-Indic Multimodal Translation Task at WAT 2025. We participate in the text-only translation tasks for English-Hindi, English-Bengali, English-Malayalam, and English-Odia language pairs. We present a two-stage approach that addresses quality issues in the training data through automated error detection and correction, followed by parameter-efficient model fine-tuning.   Our methodology introduces a vision-augmented judge-corrector pipeline that leverages multimodal language models to systematically identify and correct translation errors in the training data. The judge component classifies translations into three categories: correct, visually ambiguous (requiring image context), or mistranslated (poor translation quality). Identified errors are routed to specialized correctors: GPT-4o-mini regenerates captions requiring visual disambiguation, while IndicTrans2 retranslates cases with pure translation quality issues. This automated pipeline processes 28,928 training examples across four languages, correcting an average of 17.1% of captions per language.   We then apply Low-Rank Adaptation (LoRA) to fine-tune the IndicTrans2 en-indic 200M distilled model on both original and corrected datasets. Training on corrected data yields consistent improvements, with BLEU score gains of +1.30 for English-Bengali on the evaluation set (42.00 -> 43.30) and +0.70 on the challenge set (44.90 -> 45.60), +0.60 for English-Odia on the evaluation set (41.00 -> 41.60), and +0.10 for English-Hindi on the challenge set (53.90 -> 54.00).",
    "authors": [
      "Siddharth Betala",
      "Kushan Raj",
      "Vipul Betala",
      "Rohan Saswade"
    ],
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07010v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07010v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06937v1",
    "title": "Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization",
    "summary": "Diffusion models recently emerged as a powerful paradigm for recommender systems, offering state-of-the-art performance by modeling the generative process of user-item interactions. However, training such models from scratch is both computationally expensive and yields diminishing returns once convergence is reached. To remedy these challenges, we propose ReFiT, a new framework that integrates Reinforcement learning (RL)-based Fine-Tuning into diffusion-based recommender systems. In contrast to prior RL approaches for diffusion models depending on external reward models, ReFiT adopts a task-aligned design: it formulates the denoising trajectory as a Markov decision process (MDP) and incorporates a collaborative signal-aware reward function that directly reflects recommendation quality. By tightly coupling the MDP structure with this reward signal, ReFiT empowers the RL agent to exploit high-order connectivity for fine-grained optimization, while avoiding the noisy or uninformative feedback common in naive reward designs. Leveraging policy gradient optimization, ReFiT maximizes exact log-likelihood of observed interactions, thereby enabling effective post hoc fine-tuning of diffusion recommenders. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed ReFiT framework (a) exhibits substantial performance gains over strong competitors (up to 36.3% on sequential recommendation), (b) demonstrates strong efficiency with linear complexity in the number of users or items, and (c) generalizes well across multiple diffusion-based recommendation scenarios. The source code and datasets are publicly available at https://anonymous.4open.science/r/ReFiT-4C60.",
    "authors": [
      "Yu Hou",
      "Hua Li",
      "Ha Young Kim",
      "Won-Yong Shin"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "cs.SI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06937v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06937v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07057v1",
    "title": "TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight Segmentation",
    "summary": "Deploying lightweight medical image segmentation models on edge devices presents two major challenges: 1) efficiently handling the stark contrast between lesion boundaries and background regions, and 2) the sharp drop in accuracy that occurs when pursuing extremely lightweight designs (e.g., <0.5M parameters). To address these problems, this paper proposes TauFlow, a novel lightweight segmentation model. The core of TauFlow is a dynamic feature response strategy inspired by brain-like mechanisms. This is achieved through two key innovations: the Convolutional Long-Time Constant Cell (ConvLTC), which dynamically regulates the feature update rate to \"slowly\" process low-frequency backgrounds and \"quickly\" respond to high-frequency boundaries; and the STDP Self-Organizing Module, which significantly mitigates feature conflicts between the encoder and decoder, reducing the conflict rate from approximately 35%-40% to 8%-10%.",
    "authors": [
      "Zidong Chen",
      "Fadratul Hafinaz Hassan"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07057v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07057v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07260v1",
    "title": "PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork",
    "summary": "Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly.",
    "authors": [
      "Hohei Chan",
      "Xinzhi Zhang",
      "Antao Xiang",
      "Weinan Zhang",
      "Mengchen Zhao"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07260v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07260v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07237v1",
    "title": "The Few Govern the Many:Unveiling Few-Layer Dominance for Time Series Models",
    "summary": "Large-scale models are at the forefront of time series (TS) forecasting, dominated by two paradigms: fine-tuning text-based Large Language Models (LLM4TS) and training Time Series Foundation Models (TSFMs) from scratch. Both approaches share a foundational assumption that scaling up model capacity and data volume leads to improved performance. However, we observe a \\textit{\\textbf{scaling paradox}} in TS models, revealing a puzzling phenomenon that larger models do \\emph{NOT} achieve better performance. Through extensive experiments on two model families across four scales (100M to 1.7B parameters) and diverse data (up to 6B observations), we rigorously confirm that the scaling paradox is a pervasive issue. We then diagnose its root cause by analyzing internal representations, identifying a phenomenon we call \\textit{few-layer dominance}: only a small subset of layers are functionally important, while the majority are redundant, under-utilized, and can even distract training. Based on this discovery, we propose a practical method to automatically identify and retain only these dominant layers. In our models, retaining only 21\\% of the parameters achieves up to a 12\\% accuracy improvement and a 2.7$\\times$ inference speedup. We validate the universality of our method on 8 prominent SOTA models (LLM4TS and TSFMs, 90M to 6B), showing that retaining less than 30\\% of layers achieves comparable or superior accuracy in over 95\\% of tasks.",
    "authors": [
      "Xin Qiu",
      "Junlong Tong",
      "Yirong Sun",
      "Yunpu Ma",
      "Xiaoyu Shen"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07237v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07237v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06831v1",
    "title": "DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design",
    "summary": "Monte Carlo random walk methods are widely used in capacitance extraction for their mesh-free formulation and inherent parallelism. However, modern semiconductor technologies with densely packed structures present significant challenges in unbiasedly sampling transition domains in walk steps with multiple high-contrast dielectric materials. We present DeepRWCap, a machine learning-guided random walk solver that predicts the transition quantities required to guide each step of the walk. These include Poisson kernels, gradient kernels, signs and magnitudes of weights. DeepRWCap employs a two-stage neural architecture that decomposes structured outputs into face-wise distributions and spatial kernels on cube faces. It uses 3D convolutional networks to capture volumetric dielectric interactions and 2D depthwise separable convolutions to model localized kernel behavior. The design incorporates grid-based positional encodings and structural design choices informed by cube symmetries to reduce learning redundancy and improve generalization. Trained on 100,000 procedurally generated dielectric configurations, DeepRWCap achieves a mean relative error of $1.24\\pm0.53$\\% when benchmarked against the commercial Raphael solver on the self-capacitance estimation of 10 industrial designs spanning 12 to 55 nm nodes. Compared to the state-of-the-art stochastic difference method Microwalk, DeepRWCap achieves an average 23\\% speedup. On complex designs with runtimes over 10 s, it reaches an average 49\\% acceleration.",
    "authors": [
      "Hector R. Rodriguez",
      "Jiechen Huang",
      "Wenjian Yu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06831v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06831v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07274v1",
    "title": "Multi-modal Dynamic Proxy Learning for Personalized Multiple Clustering",
    "summary": "Multiple clustering aims to discover diverse latent structures from different perspectives, yet existing methods generate exhaustive clusterings without discerning user interest, necessitating laborious manual screening. Current multi-modal solutions suffer from static semantic rigidity: predefined candidate words fail to adapt to dataset-specific concepts, and fixed fusion strategies ignore evolving feature interactions. To overcome these limitations, we propose Multi-DProxy, a novel multi-modal dynamic proxy learning framework that leverages cross-modal alignment through learnable textual proxies. Multi-DProxy introduces 1) gated cross-modal fusion that synthesizes discriminative joint representations by adaptively modeling feature interactions. 2) dual-constraint proxy optimization where user interest constraints enforce semantic consistency with domain concepts while concept constraints employ hard example mining to enhance cluster discrimination. 3) dynamic candidate management that refines textual proxies through iterative clustering feedback. Therefore, Multi-DProxy not only effectively captures a user's interest through proxies but also enables the identification of relevant clusterings with greater precision. Extensive experiments demonstrate state-of-the-art performance with significant improvements over existing methods across a broad set of multi-clustering benchmarks.",
    "authors": [
      "Jinfeng Xu",
      "Zheyu Chen",
      "Shuo Yang",
      "Jinze Li",
      "Ziyue Peng",
      "Zewei Liu",
      "Hewei Wang",
      "Jiayi Zhang",
      "Edith C. H. Ngai"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07274v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07274v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06805v1",
    "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning",
    "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}.",
    "authors": [
      "Jinhao Chen",
      "Zhen Yang",
      "Jianxin Shi",
      "Tianyu Wo",
      "Jie Tang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06805v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06805v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.06899v1",
    "title": "RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation",
    "summary": "Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have shown impressive performance on various multimodal benchmarks. However, most of these benchmarks evaluate models primarily through multiple-choice or short-answer formats, which do not take the reasoning process into account. Although some benchmarks assess the reasoning process, their methods are often overly simplistic and only examine reasoning when answers are incorrect. This approach overlooks scenarios where flawed reasoning leads to correct answers. In addition, these benchmarks do not consider the impact of intermodal relationships on reasoning. To address this issue, we propose the Reasoning Process Tree Score (RPTS), a tree structure-based metric to assess reasoning processes. Specifically, we organize the reasoning steps into a reasoning tree and leverage its hierarchical information to assign weighted faithfulness scores to each reasoning step. By dynamically adjusting these weights, RPTS not only evaluates the overall correctness of the reasoning, but also pinpoints where the model fails in the reasoning. To validate RPTS in real-world multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374 images and 390 reasoning instances. Each instance includes reliable visual-textual clues that serve as leaf nodes of the reasoning tree. Furthermore, we define three types of intermodal relationships to investigate how intermodal interactions influence the reasoning process. We evaluated representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in multimodal reasoning and highlighting the differences between open-source and closed-source commercial LVLMs. We believe that this benchmark will contribute to the advancement of research in the field of multimodal reasoning.",
    "authors": [
      "Haofeng Wang",
      "Yu Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06899v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06899v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.07403v1",
    "title": "SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards",
    "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language tasks, but they continue to struggle with spatial understanding. Existing spatial MLLMs often rely on explicit 3D inputs or architecture-specific modifications, and remain constrained by large-scale datasets or sparse supervision. To address these limitations, we introduce SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial grounding with multi-step reasoning. The model simulates human-like spatial perception by constructing a scene graph of task-relevant objects and spatial relations, and reasoning towards an answer via dense spatial rewards. SpatialThinker consists of two key contributions: (1) a data synthesis pipeline that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL with a multi-objective dense spatial reward enforcing spatial grounding. SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline on spatial understanding and real-world VQA benchmarks, nearly doubling the base-model gain compared to sparse RL, and surpassing GPT-4o. These results showcase the effectiveness of combining spatial supervision with reward-aligned reasoning in enabling robust 3D spatial understanding with limited data and advancing MLLMs towards human-level visual reasoning.",
    "authors": [
      "Hunar Batra",
      "Haoqin Tu",
      "Hardy Chen",
      "Yuanze Lin",
      "Cihang Xie",
      "Ronald Clark"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07403v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07403v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07007v1",
    "title": "TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding",
    "summary": "3D semantic scene understanding remains a long-standing challenge in the 3D computer vision community. One of the key issues pertains to limited real-world annotated data to facilitate generalizable models. The common practice to tackle this issue is to simulate new data. Although synthetic datasets offer scalability and perfect labels, their designer-crafted scenes fail to capture real-world complexity and sensor noise, resulting in a synthetic-to-real domain gap. Moreover, no benchmark provides synchronized real and simulated point clouds for segmentation-oriented domain shift analysis. We introduce TrueCity, the first urban semantic segmentation benchmark with cm-accurate annotated real-world point clouds, semantic 3D city models, and annotated simulated point clouds representing the same city. TrueCity proposes segmentation classes aligned with international 3D city modeling standards, enabling consistent evaluation of synthetic-to-real gap. Our extensive experiments on common baselines quantify domain shift and highlight strategies for exploiting synthetic data to enhance real-world 3D scene understanding. We are convinced that the TrueCity dataset will foster further development of sim-to-real gap quantification and enable generalizable data-driven models. The data, code, and 3D models are available online: https://tum-gis.github.io/TrueCity/",
    "authors": [
      "Duc Nguyen",
      "Yan-Ling Lai",
      "Qilin Zhang",
      "Prabin Gyawali",
      "Benedikt Schwab",
      "Olaf Wysocki",
      "Thomas H. Kolbe"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07007v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07007v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06803v1",
    "title": "Learning to Fast Unrank in Collaborative Filtering Recommendation",
    "summary": "Modern data-driven recommendation systems risk memorizing sensitive user behavioral patterns, raising privacy concerns. Existing recommendation unlearning methods, while capable of removing target data influence, suffer from inefficient unlearning speed and degraded performance, failing to meet real-time unlearning demands. Considering the ranking-oriented nature of recommendation systems, we present unranking, the process of reducing the ranking positions of target items while ensuring the formal guarantees of recommendation unlearning. To achieve efficient unranking, we propose Learning to Fast Unrank in Collaborative Filtering Recommendation (L2UnRank), which operates through three key stages: (a) identifying the influenced scope via interaction-based p-hop propagation, (b) computing structural and semantic influences for entities within this scope, and (c) performing efficient, ranking-aware parameter updates guided by influence information. Extensive experiments across multiple datasets and backbone models demonstrate L2UnRank's model-agnostic nature, achieving state-of-the-art unranking effectiveness and maintaining recommendation quality comparable to retraining, while also delivering a 50x speedup over existing methods. Codes are available at https://github.com/Juniper42/L2UnRank.",
    "authors": [
      "Junpeng Zhao",
      "Lin Li",
      "Ming Li",
      "Amran Bhuiyan",
      "Jimmy Huang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06803v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06803v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06818v1",
    "title": "Learning to Focus: Focal Attention for Selective and Scalable Transformers",
    "summary": "Attention is a core component of transformer architecture, whether encoder-only, decoder-only, or encoder-decoder model. However, the standard softmax attention often produces noisy probability distribution, which can impair effective feature selection at every layer of these models, particularly for long contexts. We propose Focal Attention, a simple yet effective modification that sharpens the attention distribution by controlling the softmax temperature, either as a fixed hyperparameter or as a learnable parameter during training. This sharpening enables the model to concentrate on the most relevant tokens while suppressing irrelevant ones. Empirically, Focal Attention scales more favorably than standard transformer with respect to model size, training data, and context length. Across diverse benchmarks, it achieves the same accuracy with up to 42% fewer parameters or 33% less training data. On long-context tasks, it delivers substantial relative improvements ranging from 17% to 82%, demonstrating its effectiveness in real world applications.",
    "authors": [
      "Dhananjay Ram",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06818v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06818v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07416v1",
    "title": "Robot Learning from a Physical World Model",
    "summary": "We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \\href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details.",
    "authors": [
      "Jiageng Mao",
      "Sicheng He",
      "Hao-Ning Wu",
      "Yang You",
      "Shuyang Sun",
      "Zhicheng Wang",
      "Yanan Bao",
      "Huizhong Chen",
      "Leonidas Guibas",
      "Vitor Guizilini",
      "Howard Zhou",
      "Yue Wang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07416v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07416v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06745v1",
    "title": "Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning",
    "summary": "Self-supervised goal-conditioned reinforcement learning enables robots to autonomously acquire diverse skills without human supervision. However, a central challenge is the goal setting problem: robots must propose feasible and diverse goals that are achievable in their current environment. Existing methods like RIG (Visual Reinforcement Learning with Imagined Goals) use variational autoencoder (VAE) to generate goals in a learned latent space but have the limitation of producing physically implausible goals that hinder learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates physical constraints directly into the VAE training process through a novel Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling the generation of physically consistent and achievable goals. Our key innovation is the explicit separation of the latent space into physics variables governing object dynamics and environmental factors capturing visual appearance, while enforcing physical consistency through differential equation constraints and conservation laws. This enables the generation of physically consistent and achievable goals that respect fundamental physical principles such as object permanence, collision constraints, and dynamic feasibility. Through extensive experiments, we demonstrate that this physics-informed goal generation significantly improves the quality of proposed goals, leading to more effective exploration and better skill acquisition in visual robotic manipulation tasks including reaching, pushing, and pick-and-place scenarios.",
    "authors": [
      "Lan Thi Ha Nguyen",
      "Kien Ton Manh",
      "Anh Do Duc",
      "Nam Pham Hai"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06745v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06745v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07014v1",
    "title": "Diffolio: A Diffusion Model for Multivariate Probabilistic Financial Time-Series Forecasting and Portfolio Construction",
    "summary": "Probabilistic forecasting is crucial in multivariate financial time-series for constructing efficient portfolios that account for complex cross-sectional dependencies. In this paper, we propose Diffolio, a diffusion model designed for multivariate financial time-series forecasting and portfolio construction. Diffolio employs a denoising network with a hierarchical attention architecture, comprising both asset-level and market-level layers. Furthermore, to better reflect cross-sectional correlations, we introduce a correlation-guided regularizer informed by a stable estimate of the target correlation matrix. This structure effectively extracts salient features not only from historical returns but also from asset-specific and systematic covariates, significantly enhancing the performance of forecasts and portfolios. Experimental results on the daily excess returns of 12 industry portfolios show that Diffolio outperforms various probabilistic forecasting baselines in multivariate forecasting accuracy and portfolio performance. Moreover, in portfolio experiments, portfolios constructed from Diffolio's forecasts show consistently robust performance, thereby outperforming those from benchmarks by achieving higher Sharpe ratios for the mean-variance tangency portfolio and higher certainty equivalents for the growth-optimal portfolio. These results demonstrate the superiority of our proposed Diffolio in terms of not only statistical accuracy but also economic significance.",
    "authors": [
      "So-Yoon Cho",
      "Jin-Young Kim",
      "Kayoung Ban",
      "Hyeng Keun Koo",
      "Hyun-Gyoon Kim"
    ],
    "categories": [
      "cs.CE",
      "cs.AI",
      "econ.EM",
      "q-fin.PM"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07014v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07014v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06802v1",
    "title": "Neural-Initialized Newton: Accelerating Nonlinear Finite Elements via Operator Learning",
    "summary": "We propose a Newton-based scheme, initialized by neural operator predictions, to accelerate the parametric solution of nonlinear problems in computational solid mechanics. First, a physics informed conditional neural field is trained to approximate the nonlinear parametric solutionof the governing equations. This establishes a continuous mapping between the parameter and solution spaces, which can then be evaluated for a given parameter at any spatial resolution. Second, since the neural approximation may not be exact, it is subsequently refined using a Newton-based correction initialized by the neural output. To evaluate the effectiveness of this hybrid approach, we compare three solution strategies: (i) the standard Newton-Raphson solver used in NFEM, which is robust and accurate but computationally demanding; (ii) physics-informed neural operators, which provide rapid inference but may lose accuracy outside the training distribution and resolution; and (iii) the neural-initialized Newton (NiN) strategy, which combines the efficiency of neural operators with the robustness of NFEM. The results demonstrate that the proposed hybrid approach reduces computational cost while preserving accuracy, highlighting its potential to accelerate large-scale nonlinear simulations.",
    "authors": [
      "Kianoosh Taghikhani",
      "Yusuke Yamazaki",
      "Jerry Paul Varghese",
      "Markus Apel",
      "Reza Najian Asl",
      "Shahed Rezaei"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06802v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06802v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06618v1",
    "title": "GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization",
    "summary": "Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering.",
    "authors": [
      "Moriya Dechtiar",
      "Daniel Martin Katz",
      "Mari Sundaresan",
      "Sylvain Jaume",
      "Hongming Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06618v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06618v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06761v1",
    "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding",
    "summary": "Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. Moreover, unlike the prevalent ``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune'' approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our analysis further reveals a benchmark bias, outlines a path for a more holistic evaluation, and demonstrates SRNN's white-box utility for precise error diagnosis. Our work confirms the viability of translating biological intelligence into engineered systems for intuitive physics understanding.",
    "authors": [
      "Fei Yang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06761v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06761v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07317v1",
    "title": "RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments",
    "summary": "We introduce Reinforcement Learning (RL) with Adaptive Verifiable Environments (RLVE), an approach using verifiable environments that procedurally generate problems and provide algorithmically verifiable rewards, to scale up RL for language models (LMs). RLVE enables each verifiable environment to dynamically adapt its problem difficulty distribution to the policy model's capabilities as training progresses. In contrast, static data distributions often lead to vanishing learning signals when problems are either too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a large-scale suite of 400 verifiable environments carefully developed through manual environment engineering. Using RLVE-Gym, we show that environment scaling, i.e., expanding the collection of training environments, consistently improves generalizable reasoning capabilities. RLVE with joint training across all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement across six reasoning benchmarks, starting from one of the strongest 1.5B reasoning LMs. By comparison, continuing this LM's original RL training yields only a 0.49% average absolute gain despite using over 3x more compute. We release our code publicly.",
    "authors": [
      "Zhiyuan Zeng",
      "Hamish Ivison",
      "Yiping Wang",
      "Lifan Yuan",
      "Shuyue Stella Li",
      "Zhuorui Ye",
      "Siting Li",
      "Jacqueline He",
      "Runlong Zhou",
      "Tong Chen",
      "Chenyang Zhao",
      "Yulia Tsvetkov",
      "Simon Shaolei Du",
      "Natasha Jaques",
      "Hao Peng",
      "Pang Wei Koh",
      "Hannaneh Hajishirzi"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07317v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07317v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06973v1",
    "title": "Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery",
    "summary": "Traditional methods for identifying structurally similar spreadsheets fail to capture the spatial layouts and type patterns defining templates. To quantify spreadsheet similarity, we introduce a hybrid distance metric that combines semantic embeddings, data type information, and spatial positioning. In order to calculate spreadsheet similarity, our method converts spreadsheets into cell-level embeddings and then uses aggregation techniques like Chamfer and Hausdorff distances. Experiments across template families demonstrate superior unsupervised clustering performance compared to the graph-based Mondrian baseline, achieving perfect template reconstruction (Adjusted Rand Index of 1.00 versus 0.90) on the FUSTE dataset. Our approach facilitates large-scale automated template discovery, which in turn enables downstream applications such as retrieval-augmented generation over tabular collections, model training, and bulk data cleaning.",
    "authors": [
      "Ananad Krishnakumar",
      "Vengadesh Ravikumaran"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06973v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06973v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06894v1",
    "title": "COGNOS: Universal Enhancement for Time Series Anomaly Detection via Constrained Gaussian-Noise Optimization and Smoothing",
    "summary": "Reconstruction-based methods are a dominant paradigm in time series anomaly detection (TSAD), however, their near-universal reliance on Mean Squared Error (MSE) loss results in statistically flawed reconstruction residuals. This fundamental weakness leads to noisy, unstable anomaly scores with a poor signal-to-noise ratio, hindering reliable detection. To address this, we propose Constrained Gaussian-Noise Optimization and Smoothing (COGNOS), a universal, model-agnostic enhancement framework that tackles this issue at its source. COGNOS introduces a novel Gaussian-White Noise Regularization strategy during training, which directly constrains the model's output residuals to conform to a Gaussian white noise distribution. This engineered statistical property creates the ideal precondition for our second contribution: a Kalman Smoothing Post-processor that provably operates as a statistically optimal estimator to denoise the raw anomaly scores. The synergy between these two components allows COGNOS to robustly separate the true anomaly signal from random fluctuations. Extensive experiments demonstrate that COGNOS is highly effective, delivering an average F-score uplift of 57.9% when applied to 12 diverse backbone models across multiple real-world benchmark datasets. Our work reveals that directly regularizing output statistics is a powerful and generalizable strategy for significantly improving anomaly detection systems.",
    "authors": [
      "Wenlong Shang",
      "Peng Chang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06894v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06894v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07065v1",
    "title": "Aligning Attention with Human Rationales for Self-Explaining Hate Speech Detection",
    "summary": "The opaque nature of deep learning models presents significant challenges for the ethical deployment of hate speech detection systems. To address this limitation, we introduce Supervised Rational Attention (SRA), a framework that explicitly aligns model attention with human rationales, improving both interpretability and fairness in hate speech classification. SRA integrates a supervised attention mechanism into transformer-based classifiers, optimizing a joint objective that combines standard classification loss with an alignment loss term that minimizes the discrepancy between attention weights and human-annotated rationales. We evaluated SRA on hate speech benchmarks in English (HateXplain) and Portuguese (HateBRXplain) with rationale annotations. Empirically, SRA achieves 2.4x better explainability compared to current baselines, and produces token-level explanations that are more faithful and human-aligned. In terms of fairness, SRA achieves competitive fairness across all measures, with second-best performance in detecting toxic posts targeting identity groups, while maintaining comparable results on other metrics. These findings demonstrate that incorporating human rationales into attention mechanisms can enhance interpretability and faithfulness without compromising fairness.",
    "authors": [
      "Brage Eilertsen",
      "R\u00f8skva Bj\u00f8rgfinsd\u00f3ttir",
      "Francielle Vargas",
      "Ali Ramezani-Kebrya"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07065v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07065v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06653v1",
    "title": "HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in Vision-Language Alignment",
    "summary": "Contrastive vision-language models like CLIP have achieved impressive results in image-text retrieval by aligning image and text representations in a shared embedding space. However, these models often treat text as flat sequences, limiting their ability to handle complex, compositional, and long-form descriptions. In particular, they fail to capture two essential properties of language: semantic hierarchy, which reflects the multi-level compositional structure of text, and semantic monotonicity, where richer descriptions should result in stronger alignment with visual content.To address these limitations, we propose HiMo-CLIP, a representation-level framework that enhances CLIP-style models without modifying the encoder architecture. HiMo-CLIP introduces two key components: a hierarchical decomposition (HiDe) module that extracts latent semantic components from long-form text via in-batch PCA, enabling flexible, batch-aware alignment across different semantic granularities, and a monotonicity-aware contrastive loss (MoLo) that jointly aligns global and component-level representations, encouraging the model to internalize semantic ordering and alignment strength as a function of textual completeness.These components work in concert to produce structured, cognitively-aligned cross-modal representations. Experiments on multiple image-text retrieval benchmarks show that HiMo-CLIP consistently outperforms strong baselines, particularly under long or compositional descriptions. The code is available at https://github.com/UnicomAI/HiMo-CLIP.",
    "authors": [
      "Ruijia Wu",
      "Ping Chen",
      "Fei Shen",
      "Shaoan Zhao",
      "Qiang Hui",
      "Huanlin Gao",
      "Ting Lu",
      "Zhaoxiang Liu",
      "Fang Zhao",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06653v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06653v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06848v1",
    "title": "Distillation Dynamics: Towards Understanding Feature-Based Distillation in Vision Transformers",
    "summary": "While feature-based knowledge distillation has proven highly effective for compressing CNNs, these techniques unexpectedly fail when applied to Vision Transformers (ViTs), often performing worse than simple logit-based distillation. We provide the first comprehensive analysis of this phenomenon through a novel analytical framework termed as ``distillation dynamics\", combining frequency spectrum analysis, information entropy metrics, and activation magnitude tracking. Our investigation reveals that ViTs exhibit a distinctive U-shaped information processing pattern: initial compression followed by expansion. We identify the root cause of negative transfer in feature distillation: a fundamental representational paradigm mismatch between teacher and student models. Through frequency-domain analysis, we show that teacher models employ distributed, high-dimensional encoding strategies in later layers that smaller student models cannot replicate due to limited channel capacity. This mismatch causes late-layer feature alignment to actively harm student performance. Our findings reveal that successful knowledge transfer in ViTs requires moving beyond naive feature mimicry to methods that respect these fundamental representational constraints, providing essential theoretical guidance for designing effective ViTs compression strategies. All source code and experimental logs are provided in the supplementary material.",
    "authors": [
      "Huiyuan Tian",
      "Bonan Xu Shijian Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06848v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06848v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07137v1",
    "title": "MPJudge: Towards Perceptual Assessment of Music-Induced Paintings",
    "summary": "Music induced painting is a unique artistic practice, where visual artworks are created under the influence of music. Evaluating whether a painting faithfully reflects the music that inspired it poses a challenging perceptual assessment task. Existing methods primarily rely on emotion recognition models to assess the similarity between music and painting, but such models introduce considerable noise and overlook broader perceptual cues beyond emotion. To address these limitations, we propose a novel framework for music induced painting assessment that directly models perceptual coherence between music and visual art. We introduce MPD, the first large scale dataset of music painting pairs annotated by domain experts based on perceptual coherence. To better handle ambiguous cases, we further collect pairwise preference annotations. Building on this dataset, we present MPJudge, a model that integrates music features into a visual encoder via a modulation based fusion mechanism. To effectively learn from ambiguous cases, we adopt Direct Preference Optimization for training. Extensive experiments demonstrate that our method outperforms existing approaches. Qualitative results further show that our model more accurately identifies music relevant regions in paintings.",
    "authors": [
      "Shiqi Jiang",
      "Tianyi Liang",
      "Changbo Wang",
      "Chenhui Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07137v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07137v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06722v1",
    "title": "Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View",
    "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have spurred significant progress in Chain-of-Thought (CoT) reasoning. Building on the success of Deepseek-R1, researchers extended multimodal reasoning to post-training paradigms based on reinforcement learning (RL), focusing predominantly on mathematical datasets. However, existing post-training paradigms tend to neglect two critical aspects: (1) The lack of quantifiable difficulty metrics capable of strategically screening samples for post-training optimization. (2) Suboptimal post-training paradigms that fail to jointly optimize perception and reasoning capabilities. To address this gap, we propose two novel difficulty-aware sampling strategies: Progressive Image Semantic Masking (PISM) quantifies sample hardness through systematic image degradation, while Cross-Modality Attention Balance (CMAB) assesses cross-modal interaction complexity via attention distribution analysis. Leveraging these metrics, we design a hierarchical training framework that incorporates both GRPO-only and SFT+GRPO hybrid training paradigms, and evaluate them across six benchmark datasets. Experiments demonstrate consistent superiority of GRPO applied to difficulty-stratified samples compared to conventional SFT+GRPO pipelines, indicating that strategic data sampling can obviate the need for supervised fine-tuning while improving model accuracy. Our code will be released at https://github.com/qijianyu277/DifficultySampling.",
    "authors": [
      "Jianyu Qi",
      "Ding Zou",
      "Wenrui Yan",
      "Rui Ma",
      "Jiaxu Li",
      "Zhijie Zheng",
      "Zhiguo Yang",
      "Rongchang Zhao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06722v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06722v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07288v1",
    "title": "Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization",
    "summary": "Learning complex policies with Reinforcement Learning (RL) is often hindered by instability and slow convergence, a problem exacerbated by the difficulty of reward engineering. Imitation Learning (IL) from expert demonstrations bypasses this reliance on rewards. However, state-of-the-art IL methods, exemplified by Generative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severe sample inefficiency. This is a direct consequence of their foundational on-policy algorithms, such as TRPO Schulman et.al. In this work, we introduce an adversarial imitation learning algorithm that incorporates off-policy learning to improve sample efficiency. By combining an off-policy framework with auxiliary techniques specifically, double Q network based stabilization and value learning without reward function inference we demonstrate a reduction in the samples required to robustly match expert behavior.",
    "authors": [
      "Sayambhu Sen",
      "Shalabh Bhatnagar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07288v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07288v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07091v1",
    "title": "How Bias Binds: Measuring Hidden Associations for Bias Control in Text-to-Image Compositions",
    "summary": "Text-to-image generative models often exhibit bias related to sensitive attributes. However, current research tends to focus narrowly on single-object prompts with limited contextual diversity. In reality, each object or attribute within a prompt can contribute to bias. For example, the prompt \"an assistant wearing a pink hat\" may reflect female-inclined biases associated with a pink hat. The neglected joint effects of the semantic binding in the prompts cause significant failures in current debiasing approaches. This work initiates a preliminary investigation on how bias manifests under semantic binding, where contextual associations between objects and attributes influence generative outcomes. We demonstrate that the underlying bias distribution can be amplified based on these associations. Therefore, we introduce a bias adherence score that quantifies how specific object-attribute bindings activate bias. To delve deeper, we develop a training-free context-bias control framework to explore how token decoupling can facilitate the debiasing of semantic bindings. This framework achieves over 10% debiasing improvement in compositional generation tasks. Our analysis of bias scores across various attribute-object bindings and token decorrelation highlights a fundamental challenge: reducing bias without disrupting essential semantic relationships. These findings expose critical limitations in current debiasing approaches when applied to semantically bound contexts, underscoring the need to reassess prevailing bias mitigation strategies.",
    "authors": [
      "Jeng-Lin Li",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07091v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07091v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06961v1",
    "title": "Hybrid Autoencoders for Tabular Data: Leveraging Model-Based Augmentation in Low-Label Settings",
    "summary": "Deep neural networks often under-perform on tabular data due to their sensitivity to irrelevant features and a spectral bias toward smooth, low-frequency functions. These limitations hinder their ability to capture the sharp, high-frequency signals that often define tabular structure, especially under limited labeled samples. While self-supervised learning (SSL) offers promise in such settings, it remains challenging in tabular domains due to the lack of effective data augmentations. We propose a hybrid autoencoder that combines a neural encoder with an oblivious soft decision tree (OSDT) encoder, each guided by its own stochastic gating network that performs sample-specific feature selection. Together, these structurally different encoders and model-specific gating networks implement model-based augmentation, producing complementary input views tailored to each architecture. The two encoders, trained with a shared decoder and cross-reconstruction loss, learn distinct yet aligned representations that reflect their respective inductive biases. During training, the OSDT encoder (robust to noise and effective at modeling localized, high-frequency structure) guides the neural encoder toward representations more aligned with tabular data. At inference, only the neural encoder is used, preserving flexibility and SSL compatibility. Spectral analysis highlights the distinct inductive biases of each encoder. Our method achieves consistent gains in low-label classification and regression across diverse tabular datasets, outperforming deep and tree-based supervised baselines.",
    "authors": [
      "Erel Naor",
      "Ofir Lindenbaum"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06961v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06961v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06694v1",
    "title": "ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware",
    "summary": "Machine learning inference occurs at a massive scale, yet its environmental impact remains poorly quantified, especially on low-resource hardware. We present ML-EcoLyzer, a cross-framework tool for measuring the carbon, energy, thermal, and water costs of inference across CPUs, consumer GPUs, and datacenter accelerators. The tool supports both classical and modern models, applying adaptive monitoring and hardware-aware evaluation.   We introduce the Environmental Sustainability Score (ESS), which quantifies the number of effective parameters served per gram of CO$_2$ emitted. Our evaluation covers over 1,900 inference configurations, spanning diverse model architectures, task modalities (text, vision, audio, tabular), hardware types, and precision levels. These rigorous and reliable measurements demonstrate that quantization enhances ESS, huge accelerators can be inefficient for lightweight applications, and even small models may incur significant costs when implemented suboptimally. ML-EcoLyzer sets a standard for sustainability-conscious model selection and offers an extensive empirical evaluation of environmental costs during inference.",
    "authors": [
      "Jose Marie Antonio Minoza",
      "Rex Gregor Laylo",
      "Christian F Villarin",
      "Sebastian C. Ibanez"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06694v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06694v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07165v1",
    "title": "Fuzzy Label: From Concept to Its Application in Label Learning",
    "summary": "Label learning is a fundamental task in machine learning that aims to construct intelligent models using labeled data, encompassing traditional single-label and multi-label classification models. Traditional methods typically rely on logical labels, such as binary indicators (e.g., \"yes/no\") that specify whether an instance belongs to a given category. However, in practical applications, label annotations often involve significant uncertainty due to factors such as data noise, inherent ambiguity in the observed entities, and the subjectivity of human annotators. Therefore, representing labels using simplistic binary logic can obscure valuable information and limit the expressiveness of label learning models. To overcome this limitation, this paper introduces the concept of fuzzy labels, grounded in fuzzy set theory, to better capture and represent label uncertainty. We further propose an efficient fuzzy labeling method that mines and generates fuzzy labels from the original data, thereby enriching the label space with more informative and nuanced representations. Based on this foundation, we present fuzzy-label-enhanced algorithms for both single-label and multi-label learning, using the classical K-Nearest Neighbors (KNN) and multi-label KNN algorithms as illustrative examples. Experimental results indicate that fuzzy labels can more effectively characterize the real-world labeling information and significantly enhance the performance of label learning models.",
    "authors": [
      "Chenxi Luoa",
      "Zhuangzhuang Zhaoa",
      "Zhaohong Denga",
      "Te Zhangb"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07165v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07165v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07398v1",
    "title": "Solving bilevel optimization via sequential minimax optimization",
    "summary": "In this paper we propose a sequential minimax optimization (SMO) method for solving a class of constrained bilevel optimization problems in which the lower-level part is a possibly nonsmooth convex optimization problem, while the upper-level part is a possibly nonconvex optimization problem. Specifically, SMO applies a first-order method to solve a sequence of minimax subproblems, which are obtained by employing a hybrid of modified augmented Lagrangian and penalty schemes on the bilevel optimization problems. Under suitable assumptions, we establish an operation complexity of $O(\\varepsilon^{-7}\\log\\varepsilon^{-1})$ and $O(\\varepsilon^{-6}\\log\\varepsilon^{-1})$, measured in terms of fundamental operations, for SMO in finding an $\\varepsilon$-KKT solution of the bilevel optimization problems with merely convex and strongly convex lower-level objective functions, respectively. The latter result improves the previous best-known operation complexity by a factor of $\\varepsilon^{-1}$. Preliminary numerical results demonstrate significantly superior computational performance compared to the recently developed first-order penalty method.",
    "authors": [
      "Zhaosong Lu",
      "Sanyou Mei"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "math.NA",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07398v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07398v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07295v1",
    "title": "Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender Systems via Large Language Models",
    "summary": "Implicit feedback, employed in training recommender systems, unavoidably confronts noise due to factors such as misclicks and position bias. Previous studies have attempted to identify noisy samples through their diverged data patterns, such as higher loss values, and mitigate their influence through sample dropping or reweighting. However, we observed that noisy samples and hard samples display similar patterns, leading to hard-noisy confusion issue. Such confusion is problematic as hard samples are vital for modeling user preferences. To solve this problem, we propose LLMHNI framework, leveraging two auxiliary user-item relevance signals generated by Large Language Models (LLMs) to differentiate hard and noisy samples. LLMHNI obtains user-item semantic relevance from LLM-encoded embeddings, which is used in negative sampling to select hard negatives while filtering out noisy false negatives. An objective alignment strategy is proposed to project LLM-encoded embeddings, originally for general language tasks, into a representation space optimized for user-item relevance modeling. LLMHNI also exploits LLM-inferred logical relevance within user-item interactions to identify hard and noisy samples. These LLM-inferred interactions are integrated into the interaction graph and guide denoising with cross-graph contrastive alignment. To eliminate the impact of unreliable interactions induced by LLM hallucination, we propose a graph contrastive learning strategy that aligns representations from randomly edge-dropped views to suppress unreliable edges. Empirical results demonstrate that LLMHNI significantly improves denoising and recommendation performance.",
    "authors": [
      "Tianrui Song",
      "Wen-Shuo Chao",
      "Hao Liu"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07295v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07295v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07253v1",
    "title": "Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large Language Models",
    "summary": "Large language models (LLMs) have recently achieved impressive results in speech recognition across multiple modalities, including Auditory Speech Recognition (ASR), Visual Speech Recognition (VSR), and Audio-Visual Speech Recognition (AVSR). Despite this progress, current LLM-based approaches typically address each task independently, training separate models that raise computational and deployment resource use while missing potential cross-task synergies. They also rely on fixed-rate token compression, which restricts flexibility in balancing accuracy with efficiency. These limitations highlight the need for a unified framework that can support ASR, VSR, and AVSR while enabling elastic inference. To this end, we present Omni-AVSR, a unified audio-visual LLM that combines efficient multi-granularity training with parameter-efficient adaptation. Specifically, we adapt the matryoshka representation learning paradigm to efficiently train across multiple audio and visual granularities, reducing its inherent training resource use. Furthermore, we explore three LoRA-based strategies for adapting the backbone LLM, balancing shared and task-specific specialization. Experiments on LRS2 and LRS3 show that Omni-AVSR achieves comparable or superior accuracy to state-of-the-art baselines while training a single model at substantially lower training and deployment resource use. The model also remains robust under acoustic noise, and we analyze its scaling behavior as LLM size increases, providing insights into the trade-off between performance and efficiency.",
    "authors": [
      "Umberto Cappellazzo",
      "Xubo Liu",
      "Pingchuan Ma",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "categories": [
      "eess.AS",
      "cs.CV",
      "cs.SD"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07253v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07253v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06976v1",
    "title": "Rethinking Crystal Symmetry Prediction: A Decoupled Perspective",
    "summary": "Efficiently and accurately determining the symmetry is a crucial step in the structural analysis of crystalline materials. Existing methods usually mindlessly apply deep learning models while ignoring the underlying chemical rules. More importantly, experiments show that they face a serious sub-property confusion SPC problem. To address the above challenges, from a decoupled perspective, we introduce the XRDecoupler framework, a problem-solving arsenal specifically designed to tackle the SPC problem. Imitating the thinking process of chemists, we innovatively incorporate multidimensional crystal symmetry information as superclass guidance to ensure that the model's prediction process aligns with chemical intuition. We further design a hierarchical PXRD pattern learning model and a multi-objective optimization approach to achieve high-quality representation and balanced optimization. Comprehensive evaluations on three mainstream databases (e.g., CCDC, CoREMOF, and InorganicData) demonstrate that XRDecoupler excels in performance, interpretability, and generalization.",
    "authors": [
      "Liheng Yu",
      "Zhe Zhao",
      "Xucong Wang",
      "Di Wu",
      "Pengkun Wang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06976v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06976v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06720v1",
    "title": "Relative Energy Learning for LiDAR Out-of-Distribution Detection",
    "summary": "Out-of-distribution (OOD) detection is a critical requirement for reliable autonomous driving, where safety depends on recognizing road obstacles and unexpected objects beyond the training distribution. Despite extensive research on OOD detection in 2D images, direct transfer to 3D LiDAR point clouds has been proven ineffective. Current LiDAR OOD methods struggle to distinguish rare anomalies from common classes, leading to high false-positive rates and overconfident errors in safety-critical settings. We propose Relative Energy Learning (REL), a simple yet effective framework for OOD detection in LiDAR point clouds. REL leverages the energy gap between positive (in-distribution) and negative logits as a relative scoring function, mitigating calibration issues in raw energy values and improving robustness across various scenes. To address the absence of OOD samples during training, we propose a lightweight data synthesis strategy called Point Raise, which perturbs existing point clouds to generate auxiliary anomalies without altering the inlier semantics. Evaluated on SemanticKITTI and the Spotting the Unexpected (STU) benchmark, REL consistently outperforms existing methods by a large margin. Our results highlight that modeling relative energy, combined with simple synthetic outliers, provides a principled and scalable solution for reliable OOD detection in open-world autonomous driving.",
    "authors": [
      "Zizhao Li",
      "Zhengkang Xiang",
      "Jiayang Ao",
      "Joseph West",
      "Kourosh Khoshelham"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06720v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06720v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07142v1",
    "title": "ProcGen3D: Learning Neural Procedural Graph Representations for Image-to-3D Reconstruction",
    "summary": "We introduce ProcGen3D, a new approach for 3D content creation by generating procedural graph abstractions of 3D objects, which can then be decoded into rich, complex 3D assets. Inspired by the prevalent use of procedural generators in production 3D applications, we propose a sequentialized, graph-based procedural graph representation for 3D assets. We use this to learn to approximate the landscape of a procedural generator for image-based 3D reconstruction. We employ edge-based tokenization to encode the procedural graphs, and train a transformer prior to predict the next token conditioned on an input RGB image. Crucially, to enable better alignment of our generated outputs to an input image, we incorporate Monte Carlo Tree Search (MCTS) guided sampling into our generation process, steering output procedural graphs towards more image-faithful reconstructions. Our approach is applicable across a variety of objects that can be synthesized with procedural generators. Extensive experiments on cacti, trees, and bridges show that our neural procedural graph generation outperforms both state-of-the-art generative 3D methods and domain-specific modeling techniques. Furthermore, this enables improved generalization on real-world input images, despite training only on synthetic data.",
    "authors": [
      "Xinyi Zhang",
      "Daoyi Gao",
      "Naiqi Li",
      "Angela Dai"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07142v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07142v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06948v1",
    "title": "PADM: A Physics-aware Diffusion Model for Attenuation Correction",
    "summary": "Attenuation artifacts remain a significant challenge in cardiac Myocardial Perfusion Imaging (MPI) using Single-Photon Emission Computed Tomography (SPECT), often compromising diagnostic accuracy and reducing clinical interpretability. While hybrid SPECT/CT systems mitigate these artifacts through CT-derived attenuation maps, their high cost, limited accessibility, and added radiation exposure hinder widespread clinical adoption. In this study, we propose a novel CT-free solution to attenuation correction in cardiac SPECT. Specifically, we introduce Physics-aware Attenuation Correction Diffusion Model (PADM), a diffusion-based generative method that incorporates explicit physics priors via a teacher--student distillation mechanism. This approach enables attenuation artifact correction using only Non-Attenuation-Corrected (NAC) input, while still benefiting from physics-informed supervision during training. To support this work, we also introduce CardiAC, a comprehensive dataset comprising 424 patient studies with paired NAC and Attenuation-Corrected (AC) reconstructions, alongside high-resolution CT-based attenuation maps. Extensive experiments demonstrate that PADM outperforms state-of-the-art generative models, delivering superior reconstruction fidelity across both quantitative metrics and visual assessment.",
    "authors": [
      "Trung Kien Pham",
      "Hoang Minh Vu",
      "Anh Duc Chu",
      "Dac Thai Nguyen",
      "Trung Thanh Nguyen",
      "Thao Nguyen Truong",
      "Mai Hong Son",
      "Thanh Trung Nguyen",
      "Phi Le Nguyen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06948v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06948v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06582v1",
    "title": "TabRAG: Tabular Document Retrieval via Structured Language Representations",
    "summary": "Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.",
    "authors": [
      "Jacob Si",
      "Mike Qu",
      "Michelle Lee",
      "Yingzhen Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06582v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06582v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06790v1",
    "title": "Robust Causal Discovery under Imperfect Structural Constraints",
    "summary": "Robust causal discovery from observational data under imperfect prior knowledge remains a significant and largely unresolved challenge. Existing methods typically presuppose perfect priors or can only handle specific, pre-identified error types. And their performance degrades substantially when confronted with flawed constraints of unknown location and type. This decline arises because most of them rely on inflexible and biased thresholding strategies that may conflict with the data distribution. To overcome these limitations, we propose to harmonizes knowledge and data through prior alignment and conflict resolution. First, we assess the credibility of imperfect structural constraints through a surrogate model, which then guides a sparse penalization term measuring the loss between the learned and constrained adjacency matrices. We theoretically prove that, under ideal assumption, the knowledge-driven objective aligns with the data-driven objective. Furthermore, to resolve conflicts when this assumption is violated, we introduce a multi-task learning framework optimized via multi-gradient descent, jointly minimizing both objectives. Our proposed method is robust to both linear and nonlinear settings. Extensive experiments, conducted under diverse noise conditions and structural equation model types, demonstrate the effectiveness and efficiency of our method under imperfect structural constraints.",
    "authors": [
      "Zidong Wang",
      "Xi Lin",
      "Chuchao He",
      "Xiaoguang Gao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06790v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06790v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07109v1",
    "title": "A Provably-Correct and Robust Convex Model for Smooth Separable NMF",
    "summary": "Nonnegative matrix factorization (NMF) is a linear dimensionality reduction technique for nonnegative data, with applications such as hyperspectral unmixing and topic modeling. NMF is a difficult problem in general (NP-hard), and its solutions are typically not unique. To address these two issues, additional constraints or assumptions are often used. In particular, separability assumes that the basis vectors in the NMF are equal to some columns of the input matrix. In that case, the problem is referred to as separable NMF (SNMF) and can be solved in polynomial-time with robustness guarantees, while identifying a unique solution. However, in real-world scenarios, due to noise or variability, multiple data points may lie near the basis vectors, which SNMF does not leverage. In this work, we rely on the smooth separability assumption, which assumes that each basis vector is close to multiple data points. We explore the properties of the corresponding problem, referred to as smooth SNMF (SSNMF), and examine how it relates to SNMF and orthogonal NMF. We then propose a convex model for SSNMF and show that it provably recovers the sought-after factors, even in the presence of noise. We finally adapt an existing fast gradient method to solve this convex model for SSNMF, and show that it compares favorably with state-of-the-art methods on both synthetic and hyperspectral datasets.",
    "authors": [
      "Junjun Pan",
      "Valentin Leplat",
      "Michael Ng",
      "Nicolas Gillis"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "eess.SP",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07109v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07109v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06781v1",
    "title": "On the Mechanisms of Collaborative Learning in VAE Recommenders",
    "summary": "Variational Autoencoders (VAEs) are a powerful alternative to matrix factorization for recommendation. A common technique in VAE-based collaborative filtering (CF) consists in applying binary input masking to user interaction vectors, which improves performance but remains underexplored theoretically. In this work, we analyze how collaboration arises in VAE-based CF and show it is governed by latent proximity: we derive a latent sharing radius that informs when an SGD update on one user strictly reduces the loss on another user, with influence decaying as the latent Wasserstein distance increases. We further study the induced geometry: with clean inputs, VAE-based CF primarily exploits \\emph{local} collaboration between input-similar users and under-utilizes global collaboration between far-but-related users. We compare two mechanisms that encourage \\emph{global} mixing and characterize their trade-offs: (1) $\u03b2$-KL regularization directly tightens the information bottleneck, promoting posterior overlap but risking representational collapse if too large; (2) input masking induces stochastic geometric contractions and expansions, which can bring distant users onto the same latent neighborhood but also introduce neighborhood drift. To preserve user identity while enabling global consistency, we propose an anchor regularizer that aligns user posteriors with item embeddings, stabilizing users under masking and facilitating signal sharing across related items. Our analyses are validated on the Netflix, MovieLens-20M, and Million Song datasets. We also successfully deployed our proposed algorithm on an Amazon streaming platform following a successful online experiment.",
    "authors": [
      "Tung-Long Vuong",
      "Julien Monteil",
      "Hien Dang",
      "Volodymyr Vaskovych",
      "Trung Le",
      "Vu Nguyen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06781v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06781v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06886v1",
    "title": "Inclusion of Role into Named Entity Recognition and Ranking",
    "summary": "Most of the Natural Language Processing systems are involved in entity-based processing for several tasks like Information Extraction, Question-Answering, Text-Summarization and so on. A new challenge comes when entities play roles according to their act or attributes in certain context. Entity Role Detection is the task of assigning such roles to the entities. Usually real-world entities are of types: person, location and organization etc. Roles could be considered as domain-dependent subtypes of these types. In the cases, where retrieving a subset of entities based on their roles is needed, poses the problem of defining the role and entities having those roles. This paper presents the study of study of solving Entity Role Detection problem by modeling it as Named Entity Recognition (NER) and Entity Retrieval/Ranking task. In NER, these roles could be considered as mutually exclusive classes and standard NER methods like sequence tagging could be used. For Entity Retrieval, Roles could be formulated as Query and entities as Collection on which the query needs to be executed. The aspect of Entity Retrieval task, which is different than document retrieval task is that the entities and roles against which they need to be retrieved are indirectly described. We have formulated automated ways of learning representative words and phrases and building representations of roles and entities using them. We have also explored different contexts like sentence and document. Since the roles depend upon context, so it is not always possible to have large domain-specific dataset or knowledge bases for learning purposes, so we have tried to exploit the information from small dataset in domain-agnostic way.",
    "authors": [
      "Neelesh Kumar Shukla",
      "Sanasam Ranbir Singh"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06886v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06886v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07392v1",
    "title": "Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction",
    "summary": "In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in the procedure, making it difficult to access and manipulate multimodal patient data without interruption. We propose a voice-directed Surgical Agent Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework, consisting of an orchestration agent and three task-specific agents driven by Large Language Models (LLMs). These LLM-based agents autonomously plan, refine, validate, and reason to map voice commands into specific tasks such as retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models on the surgical video. We also introduce a Multi-level Orchestration Evaluation Metric (MOEM) to comprehensively assess the performance and robustness from command-level and category-level perspectives. The SAOP achieves high accuracy and success rates across 240 voice commands, while LLM-based agents improve robustness against speech recognition errors and diverse or ambiguous free-form commands, demonstrating strong potential to support minimally invasive da Vinci robotic surgery.",
    "authors": [
      "Hyeryun Park",
      "Byung Mo Gu",
      "Jun Hee Lee",
      "Byeong Hyeon Choi",
      "Sekeun Kim",
      "Hyun Koo Kim",
      "Kyungsang Kim"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07392v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07392v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07230v1",
    "title": "Discourse Graph Guided Document Translation with Large Language Models",
    "summary": "Adapting large language models to full document translation remains challenging due to the difficulty of capturing long-range dependencies and preserving discourse coherence throughout extended texts. While recent agentic machine translation systems mitigate context window constraints through multi-agent orchestration and persistent memory, they require substantial computational resources and are sensitive to memory retrieval strategies. We introduce TransGraph, a discourse-guided framework that explicitly models inter-chunk relationships through structured discourse graphs and selectively conditions each translation segment on relevant graph neighbourhoods rather than relying on sequential or exhaustive context. Across three document-level MT benchmarks spanning six languages and diverse domains, TransGraph consistently surpasses strong baselines in translation quality and terminology consistency while incurring significantly lower token overhead.",
    "authors": [
      "Viet-Thanh Pham",
      "Minghan Wang",
      "Hao-Han Liao",
      "Thuy-Trang Vu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07230v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07230v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07197v1",
    "title": "Simulation-based Methods for Optimal Sampling Design in Systems Biology",
    "summary": "In many areas of systems biology, including virology, pharmacokinetics, and population biology, dynamical systems are commonly used to describe biological processes. These systems can be characterized by estimating their parameters from sampled data. The key problem is how to optimally select sampling points to achieve accurate parameter estimation. Classical approaches often rely on Fisher information matrix-based criteria such as A-, D-, and E-optimality, which require an initial parameter estimate and may yield suboptimal results when the estimate is inaccurate. This study proposes two simulation-based methods for optimal sampling design that do not depend on initial parameter estimates. The first method, E-optimal-ranking (EOR), employs the E-optimal criterion, while the second utilizes a Long Short-Term Memory (LSTM) neural network. Simulation studies based on the Lotka-Volterra and three-compartment models demonstrate that the proposed methods outperform both random selection and classical E-optimal design.",
    "authors": [
      "Tuan Minh Ha",
      "Binh Thanh Nguyen",
      "Lam Si Tung Ho"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07197v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07197v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07080v1",
    "title": "Wasm: A Pipeline for Constructing Structured Arabic Interleaved Multimodal Corpora",
    "summary": "The performance of large language models (LLMs) and large multimodal models (LMMs) depends heavily on the quality and scale of their pre-training datasets. Recent research shows that large multimodal models trained on natural documents where images and text are interleaved outperform those trained only on image-text pairs across a wide range of benchmarks, leveraging advanced pre-trained models to enforce semantic alignment, image-sequence consistency, and textual coherence. For Arabic, however, the lack of high-quality multimodal datasets that preserve document structure has limited progress. In this paper, we present our pipeline Wasm for processing the Common Crawl dataset to create a new Arabic multimodal dataset that uniquely provides markdown output. Unlike existing Arabic corpora that focus solely on text extraction, our approach preserves the structural integrity of web content while maintaining flexibility for both text-only and multimodal pre-training scenarios. We provide a comprehensive comparative analysis of our data processing pipeline against those used for major existing datasets, highlighting the convergences in filtering strategies and justifying our specific design choices. To support future research, we publicly release a representative dataset dump along with the multimodal processing pipeline for Arabic.",
    "authors": [
      "Khalil Hennara",
      "Ahmad Bastati",
      "Muhammad Hreden",
      "Mohamed Motasim Hamed",
      "Zeina Aldallal",
      "Sara Chrouf",
      "Safwan AlModhayan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07080v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07080v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06632v1",
    "title": "DIAL-GS: Dynamic Instance Aware Reconstruction for Label-free Street Scenes with 4D Gaussian Splatting",
    "summary": "Urban scene reconstruction is critical for autonomous driving, enabling structured 3D representations for data synthesis and closed-loop testing. Supervised approaches rely on costly human annotations and lack scalability, while current self-supervised methods often confuse static and dynamic elements and fail to distinguish individual dynamic objects, limiting fine-grained editing. We propose DIAL-GS, a novel dynamic instance-aware reconstruction method for label-free street scenes with 4D Gaussian Splatting. We first accurately identify dynamic instances by exploiting appearance-position inconsistency between warped rendering and actual observation. Guided by instance-level dynamic perception, we employ instance-aware 4D Gaussians as the unified volumetric representation, realizing dynamic-adaptive and instance-aware reconstruction. Furthermore, we introduce a reciprocal mechanism through which identity and dynamics reinforce each other, enhancing both integrity and consistency. Experiments on urban driving scenarios show that DIAL-GS surpasses existing self-supervised baselines in reconstruction quality and instance-level editing, offering a concise yet powerful solution for urban scene modeling.",
    "authors": [
      "Chenpeng Su",
      "Wenhua Wu",
      "Chensheng Peng",
      "Tianchen Deng",
      "Zhe Liu",
      "Hesheng Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06632v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06632v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06592v1",
    "title": "MedVoiceBias: A Controlled Study of Audio LLM Behavior in Clinical Decision-Making",
    "summary": "As large language models transition from text-based interfaces to audio interactions in clinical settings, they might introduce new vulnerabilities through paralinguistic cues in audio. We evaluated these models on 170 clinical cases, each synthesized into speech from 36 distinct voice profiles spanning variations in age, gender, and emotion. Our findings reveal a severe modality bias: surgical recommendations for audio inputs varied by as much as 35% compared to identical text-based inputs, with one model providing 80% fewer recommendations. Further analysis uncovered age disparities of up to 12% between young and elderly voices, which persisted in most models despite chain-of-thought prompting. While explicit reasoning successfully eliminated gender bias, the impact of emotion was not detected due to poor recognition performance. These results demonstrate that audio LLMs are susceptible to making clinical decisions based on a patient's voice characteristics rather than medical evidence, a flaw that risks perpetuating healthcare disparities. We conclude that bias-aware architectures are essential and urgently needed before the clinical deployment of these models.",
    "authors": [
      "Zhi Rui Tam",
      "Yun-Nung Chen"
    ],
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06592v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06592v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07406v1",
    "title": "Entangled Schr\u00f6dinger Bridge Matching",
    "summary": "Simulating trajectories of multi-particle systems on complex energy landscapes is a central task in molecular dynamics (MD) and drug discovery, but remains challenging at scale due to computationally expensive and long simulations. Previous approaches leverage techniques such as flow or Schr\u00f6dinger bridge matching to implicitly learn joint trajectories through data snapshots. However, many systems, including biomolecular systems and heterogeneous cell populations, undergo dynamic interactions that evolve over their trajectory and cannot be captured through static snapshots. To close this gap, we introduce Entangled Schr\u00f6dinger Bridge Matching (EntangledSBM), a framework that learns the first- and second-order stochastic dynamics of interacting, multi-particle systems where the direction and magnitude of each particle's path depend dynamically on the paths of the other particles. We define the Entangled Schr\u00f6dinger Bridge (EntangledSB) problem as solving a coupled system of bias forces that entangle particle velocities. We show that our framework accurately simulates heterogeneous cell populations under perturbations and rare transitions in high-dimensional biomolecular systems.",
    "authors": [
      "Sophia Tang",
      "Yinuo Zhang",
      "Pranam Chatterjee"
    ],
    "categories": [
      "cs.LG",
      "q-bio.BM"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07406v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07406v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07276v1",
    "title": "RobustA: Robust Anomaly Detection in Multimodal Data",
    "summary": "In recent years, multimodal anomaly detection methods have demonstrated remarkable performance improvements over video-only models. However, real-world multimodal data is often corrupted due to unforeseen environmental distortions. In this paper, we present the first-of-its-kind work that comprehensively investigates the adverse effects of corrupted modalities on multimodal anomaly detection task. To streamline this work, we propose RobustA, a carefully curated evaluation dataset to systematically observe the impacts of audio and visual corruptions on the overall effectiveness of anomaly detection systems. Furthermore, we propose a multimodal anomaly detection method, which shows notable resilience against corrupted modalities. The proposed method learns a shared representation space for different modalities and employs a dynamic weighting scheme during inference based on the estimated level of corruption. Our work represents a significant step forward in enabling the real-world application of multimodal anomaly detection, addressing situations where the likely events of modality corruptions occur. The proposed evaluation dataset with corrupted modalities and respective extracted features will be made publicly available.",
    "authors": [
      "Salem AlMarri",
      "Muhammad Irzam Liaqat",
      "Muhammad Zaigham Zaheer",
      "Shah Nawaz",
      "Karthik Nandakumar",
      "Markus Schedl"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07276v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07276v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07222v1",
    "title": "Omni-View: Unlocking How Generation Facilitates Understanding in Unified 3D Model based on Multiview images",
    "summary": "This paper presents Omni-View, which extends the unified multimodal understanding and generation to 3D scenes based on multiview images, exploring the principle that \"generation facilitates understanding\". Consisting of understanding model, texture module, and geometry module, Omni-View jointly models scene understanding, novel view synthesis, and geometry estimation, enabling synergistic interaction between 3D scene understanding and generation tasks. By design, it leverages the spatiotemporal modeling capabilities of its texture module responsible for appearance synthesis, alongside the explicit geometric constraints provided by its dedicated geometry module, thereby enriching the model's holistic understanding of 3D scenes. Trained with a two-stage strategy, Omni-View achieves a state-of-the-art score of 55.4 on the VSI-Bench benchmark, outperforming existing specialized 3D understanding models, while simultaneously delivering strong performance in both novel view synthesis and 3D scene generation.",
    "authors": [
      "JiaKui Hu",
      "Shanshan Zhao",
      "Qing-Guo Chen",
      "Xuerui Qiu",
      "Jialun Liu",
      "Zhao Xu",
      "Weihua Luo",
      "Kaifu Zhang",
      "Yanye Lu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07222v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07222v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06876v1",
    "title": "Generating an Image From 1,000 Words: Enhancing Text-to-Image With Structured Captions",
    "summary": "Text-to-image models have rapidly evolved from casual creative tools to professional-grade systems, achieving unprecedented levels of image quality and realism. Yet, most models are trained to map short prompts into detailed images, creating a gap between sparse textual input and rich visual outputs. This mismatch reduces controllability, as models often fill in missing details arbitrarily, biasing toward average user preferences and limiting precision for professional use. We address this limitation by training the first open-source text-to-image model on long structured captions, where every training sample is annotated with the same set of fine-grained attributes. This design maximizes expressive coverage and enables disentangled control over visual factors. To process long captions efficiently, we propose DimFusion, a fusion mechanism that integrates intermediate tokens from a lightweight LLM without increasing token length. We also introduce the Text-as-a-Bottleneck Reconstruction (TaBR) evaluation protocol. By assessing how well real images can be reconstructed through a captioning-generation loop, TaBR directly measures controllability and expressiveness, even for very long captions where existing evaluation methods fail. Finally, we demonstrate our contributions by training the large-scale model FIBO, achieving state-of-the-art prompt alignment among open-source models. Model weights are publicly available at https://huggingface.co/briaai/FIBO",
    "authors": [
      "Eyal Gutflaish",
      "Eliran Kachlon",
      "Hezi Zisman",
      "Tal Hacham",
      "Nimrod Sarid",
      "Alexander Visheratin",
      "Saar Huberman",
      "Gal Davidi",
      "Guy Bukchin",
      "Kfir Goldberg",
      "Ron Mokady"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06876v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06876v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06797v1",
    "title": "FedNET: Federated Learning for Proactive Traffic Management and Network Capacity Planning",
    "summary": "We propose FedNET, a proactive and privacy-preserving framework for early identification of high-risk links in large-scale communication networks, that leverages a distributed multi-step traffic forecasting method. FedNET employs Federated Learning (FL) to model the temporal evolution of node-level traffic in a distributed manner, enabling accurate multi-step-ahead predictions (e.g., several hours to days) without exposing sensitive network data. Using these node-level forecasts and known routing information, FedNET estimates the future link-level utilization by aggregating traffic contributions across all source-destination pairs. The links are then ranked according to the predicted load intensity and temporal variability, providing an early warning signal for potential high-risk links. We compare the federated traffic prediction of FedNET against a centralized multi-step learning baseline and then systematically analyze the impact of history and prediction window sizes on forecast accuracy using the $R^2$ score. Results indicate that FL achieves accuracy close to centralized training, with shorter prediction horizons consistently yielding the highest accuracy ($R^2 >0.92$), while longer horizons providing meaningful forecasts ($R^2 \\approx 0.45\\text{--}0.55$). We further validate the efficacy of the FedNET framework in predicting network utilization on a realistic network topology and demonstrate that it consistently identifies high-risk links well in advance (i.e., three days ahead) of the critical stress states emerging, making it a practical tool for anticipatory traffic engineering and capacity planning.",
    "authors": [
      "Saroj Kumar Panda",
      "Basabdatta Palit",
      "Sadananda Behera"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06797v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06797v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06897v1",
    "title": "Adaptive Morph-Patch Transformer for Arotic Vessel Segmentation",
    "summary": "Accurate segmentation of aortic vascular structures is critical for diagnosing and treating cardiovascular diseases.Traditional Transformer-based models have shown promise in this domain by capturing long-range dependencies between vascular features. However, their reliance on fixed-size rectangular patches often influences the integrity of complex vascular structures, leading to suboptimal segmentation accuracy. To address this challenge, we propose the adaptive Morph Patch Transformer (MPT), a novel architecture specifically designed for aortic vascular segmentation. Specifically, MPT introduces an adaptive patch partitioning strategy that dynamically generates morphology-aware patches aligned with complex vascular structures. This strategy can preserve semantic integrity of complex vascular structures within individual patches. Moreover, a Semantic Clustering Attention (SCA) method is proposed to dynamically aggregate features from various patches with similar semantic characteristics. This method enhances the model's capability to segment vessels of varying sizes, preserving the integrity of vascular structures. Extensive experiments on three open-source dataset(AVT, AortaSeg24 and TBAD) demonstrate that MPT achieves state-of-the-art performance, with improvements in segmenting intricate vascular structures.",
    "authors": [
      "Zhenxi Zhang",
      "Fuchen Zheng",
      "Adnan Iltaf",
      "Yifei Han",
      "Zhenyu Cheng",
      "Yue Du",
      "Bin Li",
      "Tianyong Liu",
      "Shoujun Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06897v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06897v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07378v1",
    "title": "Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization",
    "summary": "The ability to reason lies at the core of artificial intelligence (AI), and challenging problems usually call for deeper and longer reasoning to tackle. A crucial question about AI reasoning is whether models can extrapolate learned reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In this work, we present a theoretical analysis of transformers learning on synthetic state-tracking tasks with gradient descent. We mathematically prove how the algebraic structure of state-tracking problems governs the degree of extrapolation of the learned CoT. Specifically, our theory characterizes the length generalization of transformers through the mechanism of attention concentration, linking the retrieval robustness of the attention layer to the state-tracking task structure of long-context reasoning. Moreover, for transformers with limited reasoning length, we prove that a recursive self-training scheme can progressively extend the range of solvable problem lengths. To our knowledge, we provide the first optimization guarantee that constant-depth transformers provably learn $\\mathsf{NC}^1$-complete problems with CoT, significantly going beyond prior art confined in $\\mathsf{TC}^0$, unless the widely held conjecture $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$ fails. Finally, we present a broad set of experiments supporting our theoretical results, confirming the length generalization behaviors and the mechanism of attention concentration.",
    "authors": [
      "Yu Huang",
      "Zixin Wen",
      "Aarti Singh",
      "Yuejie Chi",
      "Yuxin Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07378v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07378v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07368v1",
    "title": "Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning",
    "summary": "Foundation models exhibit broad knowledge but limited task-specific reasoning, motivating post-training strategies such as RLVR and inference scaling with outcome or process reward models (ORM/PRM). While recent work highlights the role of exploration and entropy stability in improving pass@K, empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce existing tree-like reasoning paths rather than expanding the reasoning scope, raising the question of why exploration helps at all if no new patterns emerge.   To reconcile this paradox, we adopt the perspective of Kim et al. (2025), viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a symmetry) reasoning steps as low- versus high-probability Markov transitions, and formalize post-training dynamics through Multi-task Tree-structured Markov Chains (TMC). In this tractable model, pretraining corresponds to tree expansion, while post-training corresponds to chain-of-thought reweighting. We show that several phenomena recently observed in empirical studies arise naturally in this setting: (1) RLVR induces a squeezing effect, reducing reasoning entropy and forgetting some correct paths; (2) population rewards of ORM/PRM encourage consistency rather than accuracy, thereby favoring common patterns; and (3) certain rare, high-uncertainty reasoning paths by the base model are responsible for solving hard problem instances.   Together, these explain why exploration -- even when confined to the base model's reasoning scope -- remains essential: it preserves access to rare but crucial reasoning traces needed for difficult cases, which are squeezed out by RLVR or unfavored by inference scaling. Building on this, we further show that exploration strategies such as rejecting easy instances and KL regularization help preserve rare reasoning traces. Empirical simulations corroborate our theoretical results.",
    "authors": [
      "Dake Bu",
      "Wei Huang",
      "Andi Han",
      "Atsushi Nitanda",
      "Bo Xue",
      "Qingfu Zhang",
      "Hau-San Wong",
      "Taiji Suzuki"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07368v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07368v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07322v1",
    "title": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation",
    "summary": "While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.",
    "authors": [
      "Song Jin",
      "Shuqi Li",
      "Shukun Zhang",
      "Rui Yan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07322v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07322v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07070v1",
    "title": "RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social Networking Services",
    "summary": "As a key medium for human interaction and information exchange, social networking services (SNS) pose unique challenges for large language models (LLMs): heterogeneous workloads, fast-shifting norms and slang, and multilingual, culturally diverse corpora that induce sharp distribution shift. Supervised fine-tuning (SFT) can specialize models but often triggers a ``seesaw'' between in-distribution gains and out-of-distribution robustness, especially for smaller models. To address these challenges, we introduce RedOne 2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized post-training paradigm designed for rapid and stable adaptation. The pipeline consist in three stages: (1) Exploratory Learning on curated SNS corpora to establish initial alignment and identify systematic weaknesses; (2) Targeted Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a small fraction of general data to mitigate forgetting; and (3) Refinement Learning that re-applies RL with SNS-centric signals to consolidate improvements and harmonize trade-offs across tasks. Across various tasks spanning three categories, our 4B scale model delivers an average improvements about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves average performance lift about 8.74 from the base model with less than half the data required by SFT-centric method RedOne, evidencing superior data efficiency and stability at compact scales. Overall, RedOne 2.0 establishes a competitive, cost-effective baseline for domain-specific LLMs in SNS scenario, advancing capability without sacrificing robustness.",
    "authors": [
      "Fei Zhao",
      "Chonggang Lu",
      "Haofu Qian",
      "Fangcheng Shi",
      "Zijie Meng",
      "Jianzhao Huang",
      "Xu Tang",
      "Zheyong Xie",
      "Zheyu Ye",
      "Zhe Xu",
      "Yao Hu",
      "Shaosheng Cao"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07070v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07070v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06663v1",
    "title": "GNN-Enabled Robust Hybrid Beamforming with Score-Based CSI Generation and Denoising",
    "summary": "Accurate Channel State Information (CSI) is critical for Hybrid Beamforming (HBF) tasks. However, obtaining high-resolution CSI remains challenging in practical wireless communication systems. To address this issue, we propose to utilize Graph Neural Networks (GNNs) and score-based generative models to enable robust HBF under imperfect CSI conditions. Firstly, we develop the Hybrid Message Graph Attention Network (HMGAT) which updates both node and edge features through node-level and edge-level message passing. Secondly, we design a Bidirectional Encoder Representations from Transformers (BERT)-based Noise Conditional Score Network (NCSN) to learn the distribution of high-resolution CSI, facilitating CSI generation and data augmentation to further improve HMGAT's performance. Finally, we present a Denoising Score Network (DSN) framework and its instantiation, termed DeBERT, which can denoise imperfect CSI under arbitrary channel error levels, thereby facilitating robust HBF. Experiments on DeepMIMO urban datasets demonstrate the proposed models' superior generalization, scalability, and robustness across various HBF tasks with perfect and imperfect CSI.",
    "authors": [
      "Yuhang Li",
      "Yang Lu",
      "Bo Ai",
      "Zhiguo Ding",
      "Dusit Niyato",
      "Arumugam Nallanathan"
    ],
    "categories": [
      "eess.SY",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06663v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06663v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06798v1",
    "title": "Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward Reflective Intelligence",
    "summary": "This study introduces the Fast-Weights Homeostatic Reentry Layer (FH-RL), a neural mechanism that integrates fast-weight associative memory, homeostatic regularization, and learned reentrant feedback to approximate self-referential computation in neural networks. Unlike standard transformer architectures that operate in a purely feedforward manner during inference, FH-RL enables internal recurrence without external looping, allowing prior latent states to be dynamically re-entered into the ongoing computation stream. We conduct controlled experiments sweeping the reentry gain $\u03b3$ and evaluate emergent internal dynamics using three novel metrics: the Information Reentry Ratio (IRR), Eigen-Spectrum Recursion Index (ESRI), and Representational Drift Periodicity (RDP). Results show that reentry quantity increases proportionally with~$\u03b3$, while the learned feedback matrix $W_r$ remains bounded and becomes more structured at moderate gains. Critically, a stable reflective band emerges around $\u03b3\\approx 0.10-0.20$, where internal feedback is maximally expressive yet spectrally stable: IRR rises smoothly, ESRI remains near zero, and RDP exhibits consistent low-frequency cycles. These findings provide quantitative evidence that reflective, thought-like internal processing can arise from a principled balance between feedback amplification and homeostatic regulation, linking modern fast-weight architectures to theories of cortical reentry and recursive cognition.",
    "authors": [
      "B. G. Chae"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06798v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06798v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07118v1",
    "title": "On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation",
    "summary": "Explicit latent variable models provide a flexible yet powerful framework for data synthesis, enabling controlled manipulation of generative factors. With latent variables drawn from a tractable probability density function that can be further constrained, these models enable continuous and semantically rich exploration of the output space by navigating their latent spaces. Structured latent representations are typically obtained through the joint minimization of regularization loss functions. In variational information bottleneck models, reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly combined with an auxiliary Attribute-Regularization (AR) loss. However, balancing KLD and AR turns out to be a very delicate matter. When KLD dominates over AR, generative models tend to lack controllability; when AR dominates over KLD, the stochastic encoder is encouraged to violate the standard normal prior. We explore this trade-off in the context of symbolic music generation with explicit control over continuous musical attributes. We show that existing approaches struggle to jointly minimize both regularization objectives, whereas suitable attribute transformations can help achieve both controllability and regularization of the target latent dimensions.",
    "authors": [
      "Matteo Petten\u00f3",
      "Alessandro Ilic Mezza",
      "Alberto Bernardini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07118v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07118v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07208v1",
    "title": "SMiLE: Provably Enforcing Global Relational Properties in Neural Networks",
    "summary": "Artificial Intelligence systems are increasingly deployed in settings where ensuring robustness, fairness, or domain-specific properties is essential for regulation compliance and alignment with human values. However, especially on Neural Networks, property enforcement is very challenging, and existing methods are limited to specific constraints or local properties (defined around datapoints), or fail to provide full guarantees. We tackle these limitations by extending SMiLE, a recently proposed enforcement framework for NNs, to support global relational properties (defined over the entire input space). The proposed approach scales well with model complexity, accommodates general properties and backbones, and provides full satisfaction guarantees. We evaluate SMiLE on monotonicity, global robustness, and individual fairness, on synthetic and real data, for regression and classification tasks. Our approach is competitive with property-specific baselines in terms of accuracy and runtime, and strictly superior in terms of generality and level of guarantees. Overall, our results emphasize the potential of the SMiLE framework as a platform for future research and applications.",
    "authors": [
      "Matteo Francobaldi",
      "Michele Lombardi",
      "Andrea Lodi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07208v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07208v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06913v1",
    "title": "Sampling and Loss Weights in Multi-Domain Training",
    "summary": "In the training of large deep neural networks, there is a need for vast amounts of training data. To meet this need, data is collected from multiple domains, such as Wikipedia and GitHub. These domains are heterogeneous in both data quality and the diversity of information they provide. This raises the question of how much we should rely on each domain. Several methods have attempted to address this issue by assigning sampling weights to each data domain using heuristics or approximations. As a first step toward a deeper understanding of the role of data mixing, this work revisits the problem by studying two kinds of weights: sampling weights, which control how much each domain contributes in a batch, and loss weights, which scale the loss from each domain during training. Through a rigorous study of linear regression, we show that these two weights play complementary roles. First, they can reduce the variance of gradient estimates in iterative methods such as stochastic gradient descent (SGD). Second, they can improve generalization performance by reducing the generalization gap. We provide both theoretical and empirical support for these claims. We further study the joint dynamics of sampling weights and loss weights, examining how they can be combined to capture both contributions.",
    "authors": [
      "Mahdi Salmani",
      "Pratik Worah",
      "Meisam Razaviyayn",
      "Vahab Mirrokni"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06913v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06913v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06816v1",
    "title": "Controllable Flow Matching for Online Reinforcement Learning",
    "summary": "Model-based reinforcement learning (MBRL) typically relies on modeling environment dynamics for data efficiency. However, due to the accumulation of model errors over long-horizon rollouts, such methods often face challenges in maintaining modeling stability. To address this, we propose CtrlFlow, a trajectory-level synthetic method using conditional flow matching (CFM), which directly modeling the distribution of trajectories from initial states to high-return terminal states without explicitly modeling the environment transition function. Our method ensures optimal trajectory sampling by minimizing the control energy governed by the non-linear Controllability Gramian Matrix, while the generated diverse trajectory data significantly enhances the robustness and cross-task generalization of policy learning. In online settings, CtrlFlow demonstrates the better performance on common MuJoCo benchmark tasks than dynamics models and achieves superior sample efficiency compared to standard MBRL methods.",
    "authors": [
      "Bin Wang",
      "Boxiang Tao",
      "Haifeng Jing",
      "Hongbo Dou",
      "Zijian Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06816v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06816v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07112v1",
    "title": "More Agents Helps but Adversarial Robustness Gap Persists",
    "summary": "When LLM agents work together, they seem to be more powerful than a single LLM in mathematical question answering. However, are they also more robust to adversarial inputs? We investigate this question using adversarially perturbed math questions. These perturbations include punctuation noise with three intensities (10, 30, and 50 percent), plus real-world and human-like typos (WikiTypo, R2ATA). Using a unified sampling-and-voting framework (Agent Forest), we evaluate six open-source models (Qwen3-4B/14B, Llama3.1-8B, Mistral-7B, Gemma3-4B/12B) across four benchmarks (GSM8K, MATH, MMLU-Math, MultiArith), with various numbers of agents n from one to 25 (1, 2, 5, 10, 15, 20, 25). Our findings show that (1) Noise type matters: punctuation noise harm scales with its severity, and the human typos remain the dominant bottleneck, yielding the largest gaps to Clean accuracy and the highest ASR even with a large number of agents. And (2) Collaboration reliably improves accuracy as the number of agents, n, increases, with the largest gains from one to five agents and diminishing returns beyond 10 agents. However, the adversarial robustness gap persists regardless of the agent count.",
    "authors": [
      "Khashayar Alavi",
      "Zhastay Yeltay",
      "Lucie Flek",
      "Akbar Karimi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07112v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07112v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07055v1",
    "title": "When Sufficient is not Enough: Utilizing the Rashomon Effect for Complete Evidence Extraction",
    "summary": "Feature attribution methods typically provide minimal sufficient evidence justifying a model decision. However, in many applications this is inadequate. For compliance and cataloging, the full set of contributing features must be identified - complete evidence. We perform a case study on a medical dataset which contains human-annotated complete evidence. We show that individual models typically recover only subsets of complete evidence and that aggregating evidence from several models improves evidence recall from $\\sim$0.60 (single best model) to $\\sim$0.86 (ensemble). We analyze the recall-precision trade-off, the role of training with evidence, dynamic ensembles with certainty thresholds, and discuss implications.",
    "authors": [
      "Katharina Beckh",
      "Stefan R\u00fcping"
    ],
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07055v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07055v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06731v1",
    "title": "Diagnosing and Breaking Amplitude Suppression in Seismic Phase Picking Through Adversarial Shape Learning",
    "summary": "Deep learning has revolutionized seismic phase picking, yet a paradox persists: high signal-to-noise S-wave predictions consistently fail to cross detection thresholds, oscillating at suppressed amplitudes. We identify this previously unexplained phenomenon as amplitude suppression, which we diagnose through analyzing training histories and loss landscapes. Three interacting factors emerge: S-wave onsets exhibit high temporal uncertainty relative to high-amplitude boundaries; CNN's bias toward sharp amplitude changes anchors predictions to these boundaries rather than subtle onsets; and point-wise Binary Cross-Entropy (BCE) loss lacks lateral corrective forces, providing only vertical gradients that suppress amplitude while temporal gaps persist. This geometric trap points to a shape-then-align solution where stable geometric templates must precede temporal alignment. We implement this through a conditional GAN framework by augmenting conventional BCE training with a discriminator that enforces shape constraints. Training for 10,000 steps, this achieves a 64% increase in effective S-phase detections. Our framework autonomously discovers target geometry without a priori assumptions, offering a generalizable solution for segmentation tasks requiring precise alignment of subtle features near dominant structures.",
    "authors": [
      "Chun-Ming Huang",
      "Li-Heng Chang",
      "I-Hsin Chang",
      "An-Sheng Lee",
      "Hao Kuo-Chen"
    ],
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06731v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06731v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07049v1",
    "title": "From Pretrain to Pain: Adversarial Vulnerability of Video Foundation Models Without Task Knowledge",
    "summary": "Large-scale Video Foundation Models (VFMs) has significantly advanced various video-related tasks, either through task-specific models or Multi-modal Large Language Models (MLLMs). However, the open accessibility of VFMs also introduces critical security risks, as adversaries can exploit full knowledge of the VFMs to launch potent attacks. This paper investigates a novel and practical adversarial threat scenario: attacking downstream models or MLLMs fine-tuned from open-source VFMs, without requiring access to the victim task, training data, model query, and architecture. In contrast to conventional transfer-based attacks that rely on task-aligned surrogate models, we demonstrate that adversarial vulnerabilities can be exploited directly from the VFMs. To this end, we propose the Transferable Video Attack (TVA), a temporal-aware adversarial attack method that leverages the temporal representation dynamics of VFMs to craft effective perturbations. TVA integrates a bidirectional contrastive learning mechanism to maximize the discrepancy between the clean and adversarial features, and introduces a temporal consistency loss that exploits motion cues to enhance the sequential impact of perturbations. TVA avoids the need to train expensive surrogate models or access to domain-specific data, thereby offering a more practical and efficient attack strategy. Extensive experiments across 24 video-related tasks demonstrate the efficacy of TVA against downstream models and MLLMs, revealing a previously underexplored security vulnerability in the deployment of video models.",
    "authors": [
      "Hui Lu",
      "Yi Yu",
      "Song Xia",
      "Yiming Yang",
      "Deepu Rajan",
      "Boon Poh Ng",
      "Alex Kot",
      "Xudong Jiang"
    ],
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07049v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07049v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07029v1",
    "title": "Certified L2-Norm Robustness of 3D Point Cloud Recognition in the Frequency Domain",
    "summary": "3D point cloud classification is a fundamental task in safety-critical applications such as autonomous driving, robotics, and augmented reality. However, recent studies reveal that point cloud classifiers are vulnerable to structured adversarial perturbations and geometric corruptions, posing risks to their deployment in safety-critical scenarios. Existing certified defenses limit point-wise perturbations but overlook subtle geometric distortions that preserve individual points yet alter the overall structure, potentially leading to misclassification. In this work, we propose FreqCert, a novel certification framework that departs from conventional spatial domain defenses by shifting robustness analysis to the frequency domain, enabling structured certification against global L2-bounded perturbations. FreqCert first transforms the input point cloud via the graph Fourier transform (GFT), then applies structured frequency-aware subsampling to generate multiple sub-point clouds. Each sub-cloud is independently classified by a standard model, and the final prediction is obtained through majority voting, where sub-clouds are constructed based on spectral similarity rather than spatial proximity, making the partitioning more stable under L2 perturbations and better aligned with the object's intrinsic structure. We derive a closed-form lower bound on the certified L2 robustness radius and prove its tightness under minimal and interpretable assumptions, establishing a theoretical foundation for frequency domain certification. Extensive experiments on the ModelNet40 and ScanObjectNN datasets demonstrate that FreqCert consistently achieves higher certified accuracy and empirical accuracy under strong perturbations. Our results suggest that spectral representations provide an effective pathway toward certifiable robustness in 3D point cloud recognition.",
    "authors": [
      "Liang Zhou",
      "Qiming Wang",
      "Tianze Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07029v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07029v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06700v1",
    "title": "Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries",
    "summary": "How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts.",
    "authors": [
      "Damian Curran",
      "Vanessa Sporne",
      "Lea Frermann",
      "Jeannie Paterson"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06700v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06700v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06698v1",
    "title": "Lassoed Forests: Random Forests with Adaptive Lasso Post-selection",
    "summary": "Random forests are a statistical learning technique that use bootstrap aggregation to average high-variance and low-bias trees. Improvements to random forests, such as applying Lasso regression to the tree predictions, have been proposed in order to reduce model bias. However, these changes can sometimes degrade performance (e.g., an increase in mean squared error). In this paper, we show in theory that the relative performance of these two methods, standard and Lasso-weighted random forests, depends on the signal-to-noise ratio. We further propose a unified framework to combine random forests and Lasso selection by applying adaptive weighting and show mathematically that it can strictly outperform the other two methods. We compare the three methods through simulation, including bias-variance decomposition, error estimates evaluation, and variable importance analysis. We also show the versatility of our method by applications to a variety of real-world datasets.",
    "authors": [
      "Jing Shang",
      "James Bannon",
      "Benjamin Haibe-Kains",
      "Robert Tibshirani"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06698v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06698v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.07011v1",
    "title": "Multilingual Lexical Feature Analysis of Spoken Language for Predicting Major Depression Symptom Severity",
    "summary": "Background: Captured between clinical appointments using mobile devices, spoken language has potential for objective, more regular assessment of symptom severity and earlier detection of relapse in major depressive disorder. However, research to date has largely been in non-clinical cross-sectional samples of written language using complex machine learning (ML) approaches with limited interpretability.   Methods: We describe an initial exploratory analysis of longitudinal speech data and PHQ-8 assessments from 5,836 recordings of 586 participants in the UK, Netherlands, and Spain, collected in the RADAR-MDD study. We sought to identify interpretable lexical features associated with MDD symptom severity with linear mixed-effects modelling. Interpretable features and high-dimensional vector embeddings were also used to test the prediction performance of four regressor ML models.   Results: In English data, MDD symptom severity was associated with 7 features including lexical diversity measures and absolutist language. In Dutch, associations were observed with words per sentence and positive word frequency; no associations were observed in recordings collected in Spain. The predictive power of lexical features and vector embeddings was near chance level across all languages.   Limitations: Smaller samples in non-English speech and methodological choices, such as the elicitation prompt, may have also limited the effect sizes observable. A lack of NLP tools in languages other than English restricted our feature choice.   Conclusion: To understand the value of lexical markers in clinical research and practice, further research is needed in larger samples across several languages using improved protocols, and ML models that account for within- and between-individual variations in language.",
    "authors": [
      "Anastasiia Tokareva",
      "Judith Dineley",
      "Zoe Firth",
      "Pauline Conde",
      "Faith Matcham",
      "Sara Siddi",
      "Femke Lamers",
      "Ewan Carr",
      "Carolin Oetzmann",
      "Daniel Leightley",
      "Yuezhou Zhang",
      "Amos A. Folarin",
      "Josep Maria Haro",
      "Brenda W. J. H. Penninx",
      "Raquel Bailon",
      "Srinivasan Vairavan",
      "Til Wykes",
      "Richard J. B. Dobson",
      "Vaibhav A. Narayan",
      "Matthew Hotopf",
      "Nicholas Cummins",
      "The RADAR-CNS Consortium"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07011v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07011v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06740v1",
    "title": "SinSEMI: A One-Shot Image Generation Model and Data-Efficient Evaluation Framework for Semiconductor Inspection Equipment",
    "summary": "In the early stages of semiconductor equipment development, obtaining large quantities of raw optical images poses a significant challenge. This data scarcity hinder the advancement of AI-powered solutions in semiconductor manufacturing. To address this challenge, we introduce SinSEMI, a novel one-shot learning approach that generates diverse and highly realistic images from single optical image. SinSEMI employs a multi-scale flow-based model enhanced with LPIPS (Learned Perceptual Image Patch Similarity) energy guidance during sampling, ensuring both perceptual realism and output variety. We also introduce a comprehensive evaluation framework tailored for this application, which enables a thorough assessment using just two reference images. Through the evaluation against multiple one-shot generation techniques, we demonstrate SinSEMI's superior performance in visual quality, quantitative measures, and downstream tasks. Our experimental results demonstrate that SinSEMI-generated images achieve both high fidelity and meaningful diversity, making them suitable as training data for semiconductor AI applications.",
    "authors": [
      "ChunLiang Wu",
      "Xiaochun Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06740v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06740v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.07304v1",
    "title": "Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task Learning Approach for Bangla Hate Speech Identification",
    "summary": "This paper addresses the problem of Bangla hate speech identification, a socially impactful yet linguistically challenging task. As part of the \"Bangla Multi-task Hate Speech Identification\" shared task at the BLP Workshop, IJCNLP-AACL 2025, our team \"Retriv\" participated in all three subtasks: (1A) hate type classification, (1B) target group identification, and (1C) joint detection of type, severity, and target. For subtasks 1A and 1B, we employed a soft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2). For subtask 1C, we trained three multitask variants and aggregated their predictions through a weighted voting ensemble. Our systems achieved micro-f1 scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62% (1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7th positions, respectively. These results highlight the promise of transformer ensembles and weighted multitask frameworks for advancing Bangla hate speech detection in low-resource contexts. We made experimental scripts publicly available for the community.",
    "authors": [
      "Sourav Saha",
      "K M Nafi Asib",
      "Mohammed Moshiul Hoque"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07304v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07304v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06668v1",
    "title": "When Evidence Contradicts: Toward Safer Retrieval-Augmented Generation in Healthcare",
    "summary": "In high-stakes information domains such as healthcare, where large language models (LLMs) can produce hallucinations or misinformation, retrieval-augmented generation (RAG) has been proposed as a mitigation strategy, grounding model outputs in external, domain-specific documents. Yet, this approach can introduce errors when source documents contain outdated or contradictory information. This work investigates the performance of five LLMs in generating RAG-based responses to medicine-related queries. Our contributions are three-fold: i) the creation of a benchmark dataset using consumer medicine information documents from the Australian Therapeutic Goods Administration (TGA), where headings are repurposed as natural language questions, ii) the retrieval of PubMed abstracts using TGA headings, stratified across multiple publication years, to enable controlled temporal evaluation of outdated evidence, and iii) a comparative analysis of the frequency and impact of outdated or contradictory content on model-generated responses, assessing how LLMs integrate and reconcile temporally inconsistent information. Our findings show that contradictions between highly similar abstracts do, in fact, degrade performance, leading to inconsistencies and reduced factual accuracy in model answers. These results highlight that retrieval similarity alone is insufficient for reliable medical RAG and underscore the need for contradiction-aware filtering strategies to ensure trustworthy responses in high-stakes domains.",
    "authors": [
      "Saeedeh Javadi",
      "Sara Mirabi",
      "Manan Gangar",
      "Bahadorreza Ofoghi"
    ],
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06668v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06668v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06837v1",
    "title": "Minimum Width of Deep Narrow Networks for Universal Approximation",
    "summary": "Determining the minimum width of fully connected neural networks has become a fundamental problem in recent theoretical studies of deep neural networks. In this paper, we study the lower bounds and upper bounds of the minimum width required for fully connected neural networks in order to have universal approximation capability, which is important in network design and training. We show that $w_{min}\\leq\\max(2d_x+1, d_y)$ for networks with ELU, SELU, and the upper bound of this inequality is attained when $d_y=2d_x$, where $d_x$, $d_y$ denote the input and output dimensions, respectively. Besides, we show that $d_x+1\\leq w_{min}\\leq d_x+d_y$ for networks with LeakyReLU, ELU, CELU, SELU, Softplus, by proving that ReLU can be approximated by these activation functions. In addition, in the case that the activation function is injective or can be uniformly approximated by a sequence of injective functions (e.g., ReLU), we present a new proof of the inequality $w_{min}\\ge d_y+\\mathbf{1}_{d_x<d_y\\leq2d_x}$ by constructing a more intuitive example via a new geometric approach based on Poincar$\\acute{\\text{e}}$-Miranda Theorem.",
    "authors": [
      "Xiao-Song Yang",
      "Qi Zhou",
      "Xuan Zhou"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06837v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06837v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06641v1",
    "title": "Neyman-Pearson Classification under Both Null and Alternative Distributions Shift",
    "summary": "We consider the problem of transfer learning in Neyman-Pearson classification, where the objective is to minimize the error w.r.t. a distribution $\u03bc_1$, subject to the constraint that the error w.r.t. a distribution $\u03bc_0$ remains below a prescribed threshold. While transfer learning has been extensively studied in traditional classification, transfer learning in imbalanced classification such as Neyman-Pearson classification has received much less attention. This setting poses unique challenges, as both types of errors must be simultaneously controlled. Existing works address only the case of distribution shift in $\u03bc_1$, whereas in many practical scenarios shifts may occur in both $\u03bc_0$ and $\u03bc_1$. We derive an adaptive procedure that not only guarantees improved Type-I and Type-II errors when the source is informative, but also automatically adapt to situations where the source is uninformative, thereby avoiding negative transfer. In addition to such statistical guarantees, the procedures is efficient, as shown via complementary computational guarantees.",
    "authors": [
      "Mohammadreza M. Kalan",
      "Yuyang Deng",
      "Eitan J. Neugut",
      "Samory Kpotufe"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06641v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06641v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.07325v1",
    "title": "Garbage Vulnerable Point Monitoring using IoT and Computer Vision",
    "summary": "This paper proposes a smart way to manage municipal solid waste by using the Internet of Things (IoT) and computer vision (CV) to monitor illegal waste dumping at garbage vulnerable points (GVPs) in urban areas. The system can quickly detect and monitor dumped waste using a street-level camera and object detection algorithm. Data was collected from the Sangareddy district in Telangana, India. A series of comprehensive experiments was carried out using the proposed dataset to assess the accuracy and overall performance of various object detection models. Specifically, we performed an in-depth evaluation of YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models, YOLO11m achieved the highest accuracy of 92.39\\% in waste detection, demonstrating its effectiveness in detecting waste. Additionally, it attains an mAP@50 of 0.91, highlighting its high precision. These findings confirm that the object detection model is well-suited for monitoring and tracking waste dumping events at GVP locations. Furthermore, the system effectively captures waste disposal patterns, including hourly, daily, and weekly dumping trends, ensuring comprehensive daily and nightly monitoring.",
    "authors": [
      "R. Kumar",
      "A. Lall",
      "S. Chaudhari",
      "M. Kale",
      "A. Vattem"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07325v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07325v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.07086v1",
    "title": "LLM Driven Processes to Foster Explainable AI",
    "summary": "We present a modular, explainable LLM-agent pipeline for decision support that externalizes reasoning into auditable artifacts. The system instantiates three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix, systemic roles, feedback loops); normal-form games (strategies, payoff matrix, equilibria); and sequential games (role-conditioned agents, tree construction, backward induction), with swappable modules at every step. LLM components (default: GPT-5) are paired with deterministic analyzers for equilibria and matrix-based role classification, yielding traceable intermediates rather than opaque outputs. In a real-world logistics case (100 runs), mean factor alignment with a human baseline was 55.5\\% over 26 factors and 62.9\\% on the transport-core subset; role agreement over matches was 57\\%. An LLM judge using an eight-criterion rubric (max 100) scored runs on par with a reconstructed human baseline. Configurable LLM pipelines can thus mimic expert workflows with transparent, inspectable steps.",
    "authors": [
      "Marcel Pehlke",
      "Marc Jansen"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07086v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07086v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.06895v1",
    "title": "On The Presence of Double-Descent in Deep Reinforcement Learning",
    "summary": "The double descent (DD) paradox, where over-parameterized models see generalization improve past the interpolation point, remains largely unexplored in the non-stationary domain of Deep Reinforcement Learning (DRL). We present preliminary evidence that DD exists in model-free DRL, investigating it systematically across varying model capacity using the Actor-Critic framework. We rely on an information-theoretic metric, Policy Entropy, to measure policy uncertainty throughout training. Preliminary results show a clear epoch-wise DD curve; the policy's entrance into the second descent region correlates with a sustained, significant reduction in Policy Entropy. This entropic decay suggests that over-parameterization acts as an implicit regularizer, guiding the policy towards robust, flatter minima in the loss landscape. These findings establish DD as a factor in DRL and provide an information-based mechanism for designing agents that are more general, transferable, and robust.",
    "authors": [
      "Viktor Vesel\u00fd",
      "Aleksandar Todorov",
      "Matthia Sabatelli"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06895v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06895v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07270v1",
    "title": "High-Dimensional Asymptotics of Differentially Private PCA",
    "summary": "In differential privacy, statistics of a sensitive dataset are privatized by introducing random noise. Most privacy analyses provide privacy bounds specifying a noise level sufficient to achieve a target privacy guarantee. Sometimes, these bounds are pessimistic and suggest adding excessive noise, which overwhelms the meaningful signal. It remains unclear if such high noise levels are truly necessary or a limitation of the proof techniques. This paper explores whether we can obtain sharp privacy characterizations that identify the smallest noise level required to achieve a target privacy level for a given mechanism. We study this problem in the context of differentially private principal component analysis, where the goal is to privatize the leading principal components (PCs) of a dataset with n samples and p features. We analyze the exponential mechanism for this problem in a model-free setting and provide sharp utility and privacy characterizations in the high-dimensional limit ($p\\rightarrow\\infty$). Our privacy result shows that, in high dimensions, detecting the presence of a target individual in the dataset using the privatized PCs is exactly as hard as distinguishing two Gaussians with slightly different means, where the mean difference depends on certain spectral properties of the dataset. Our privacy analysis combines the hypothesis-testing formulation of privacy guarantees proposed by Dong, Roth, and Su (2022) with classical contiguity arguments due to Le Cam to obtain sharp high-dimensional privacy characterizations.",
    "authors": [
      "Youngjoo Yun",
      "Rishabh Dudeja"
    ],
    "categories": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.PR",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07270v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07270v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06585v1",
    "title": "Learning Biomolecular Motion: The Physics-Informed Machine Learning Paradigm",
    "summary": "The convergence of statistical learning and molecular physics is transforming our approach to modeling biomolecular systems. Physics-informed machine learning (PIML) offers a systematic framework that integrates data-driven inference with physical constraints, resulting in models that are accurate, mechanistic, generalizable, and able to extrapolate beyond observed domains. This review surveys recent advances in physics-informed neural networks and operator learning, differentiable molecular simulation, and hybrid physics-ML potentials, with emphasis on long-timescale kinetics, rare events, and free-energy estimation. We frame these approaches as solutions to the \"biomolecular closure problem\", recovering unresolved interactions beyond classical force fields while preserving thermodynamic consistency and mechanistic interpretability. We examine theoretical foundations, tools and frameworks, computational trade-offs, and unresolved issues, including model expressiveness and stability. We outline prospective research avenues at the intersection of machine learning, statistical physics, and computational chemistry, contending that future advancements will depend on mechanistic inductive biases, and integrated differentiable physical learning frameworks for biomolecular simulation and discovery.",
    "authors": [
      "Aaryesh Deshpande"
    ],
    "categories": [
      "q-bio.BM",
      "cs.LG",
      "physics.comp-ph",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06585v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06585v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06906v1",
    "title": "Counterfactual Explanation for Multivariate Time Series Forecasting with Exogenous Variables",
    "summary": "Currently, machine learning is widely used across various domains, including time series data analysis. However, some machine learning models function as black boxes, making interpretability a critical concern. One approach to address this issue is counterfactual explanation (CE), which aims to provide insights into model predictions. This study focuses on the relatively underexplored problem of generating counterfactual explanations for time series forecasting. We propose a method for extracting CEs in time series forecasting using exogenous variables, which are frequently encountered in fields such as business and marketing. In addition, we present methods for analyzing the influence of each variable over an entire time series, generating CEs by altering only specific variables, and evaluating the quality of the resulting CEs. We validate the proposed method through theoretical analysis and empirical experiments, showcasing its accuracy and practical applicability. These contributions are expected to support real-world decision-making based on time series data analysis.",
    "authors": [
      "Keita Kinjo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06906v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06906v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06780v1",
    "title": "OntoTune: Ontology-Driven Learning for Query Optimization with Convolutional Models",
    "summary": "Query optimization has been studied using machine learning, reinforcement learning, and, more recently, graph-based convolutional networks. Ontology, as a structured, information-rich knowledge representation, can provide context, particularly in learning problems. This paper presents OntoTune, an ontology-based platform for enhancing learning for query optimization. By connecting SQL queries, database metadata, and statistics, the ontology developed in this research is promising in capturing relationships and important determinants of query performance. This research also develops a method to embed ontologies while preserving as much of the relationships and key information as possible, before feeding it into learning algorithms such as tree-based and graph-based convolutional networks. A case study shows how OntoTune's ontology-driven learning delivers performance gains compared with database system default query execution.",
    "authors": [
      "Songhui Yue",
      "Yang Shao",
      "Sean Hayes"
    ],
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06780v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06780v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07272v1",
    "title": "Understanding the role of depth in the neural tangent kernel for overparameterized neural networks",
    "summary": "Overparameterized fully-connected neural networks have been shown to behave like kernel models when trained with gradient descent, under mild conditions on the width, the learning rate, and the parameter initialization. In the limit of infinitely large widths and small learning rate, the kernel that is obtained allows to represent the output of the learned model with a closed-form solution. This closed-form solution hinges on the invertibility of the limiting kernel, a property that often holds on real-world datasets. In this work, we analyze the sensitivity of large ReLU networks to increasing depths by characterizing the corresponding limiting kernel. Our theoretical results demonstrate that the normalized limiting kernel approaches the matrix of ones. In contrast, they show the corresponding closed-form solution approaches a fixed limit on the sphere. We empirically evaluate the order of magnitude in network depth required to observe this convergent behavior, and we describe the essential properties that enable the generalization of our results to other kernels.",
    "authors": [
      "William St-Arnaud",
      "Margarida Carvalho",
      "Golnoosh Farnadi"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07272v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07272v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06642v1",
    "title": "Improving Asset Allocation in a Fast Moving Consumer Goods B2B Company: An Interpretable Machine Learning Framework for Commercial Cooler Assignment Based on Multi-Tier Growth Targets",
    "summary": "In the fast-moving consumer goods (FMCG) industry, deciding where to place physical assets, such as commercial beverage coolers, can directly impact revenue growth and execution efficiency. Although churn prediction and demand forecasting have been widely studied in B2B contexts, the use of machine learning to guide asset allocation remains relatively unexplored. This paper presents a framework focused on predicting which beverage clients are most likely to deliver strong returns in volume after receiving a cooler. Using a private dataset from a well-known Central American brewing and beverage company of 3,119 B2B traditional trade channel clients that received a cooler from 2022-01 to 2024-07, and tracking 12 months of sales transactions before and after cooler installation, three growth thresholds were defined: 10%, 30% and 50% growth in sales volume year over year. The analysis compares results of machine learning models such as XGBoost, LightGBM, and CatBoost combined with SHAP for interpretable feature analysis in order to have insights into improving business operations related to cooler allocation; the results show that the best model has AUC scores of 0.857, 0.877, and 0.898 across the thresholds on the validation set. Simulations suggest that this approach can improve ROI because it better selects potential clients to grow at the expected level and increases cost savings by not assigning clients that will not grow, compared to traditional volume-based approaches with substantial business management recommendations",
    "authors": [
      "Renato Castro",
      "Rodrigo Paredes",
      "Douglas Kahn"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06642v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06642v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06686v1",
    "title": "Mitigating Modality Imbalance in Multi-modal Learning via Multi-objective Optimization",
    "summary": "Multi-modal learning (MML) aims to integrate information from multiple modalities, which is expected to lead to superior performance over single-modality learning. However, recent studies have shown that MML can underperform, even compared to single-modality approaches, due to imbalanced learning across modalities. Methods have been proposed to alleviate this imbalance issue using different heuristics, which often lead to computationally intensive subroutines. In this paper, we reformulate the MML problem as a multi-objective optimization (MOO) problem that overcomes the imbalanced learning issue among modalities and propose a gradient-based algorithm to solve the modified MML problem. We provide convergence guarantees for the proposed method, and empirical evaluations on popular MML benchmarks showcasing the improved performance of the proposed method over existing balanced MML and MOO baselines, with up to ~20x reduction in subroutine computation time. Our code is available at https://github.com/heshandevaka/MIMO.",
    "authors": [
      "Heshan Fernando",
      "Parikshit Ram",
      "Yi Zhou",
      "Soham Dan",
      "Horst Samulowitz",
      "Nathalie Baracaldo",
      "Tianyi Chen"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06686v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06686v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07292v1",
    "title": "PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving",
    "summary": "Most recent work in autonomous driving has prioritized benchmark performance and methodological innovation over in-depth analysis of model failures, biases, and shortcut learning. This has led to incremental improvements without a deep understanding of the current failures. While it is straightforward to look at situations where the model fails, it is hard to understand the underlying reason. This motivates us to conduct a systematic study, where inputs to the model are perturbed and the predictions observed. We introduce PlanT 2.0, a lightweight, object-centric planning transformer designed for autonomous driving research in CARLA. The object-level representation enables controlled analysis, as the input can be easily perturbed (e.g., by changing the location or adding or removing certain objects), in contrast to sensor-based models. To tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0, we introduce multiple upgrades to PlanT, achieving state-of-the-art performance on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis exposes insightful failures, such as a lack of scene understanding caused by low obstacle diversity, rigid expert behaviors leading to exploitable shortcuts, and overfitting to a fixed set of expert trajectories. Based on these findings, we argue for a shift toward data-centric development, with a focus on richer, more robust, and less biased datasets. We open-source our code and model at https://github.com/autonomousvision/plant2.",
    "authors": [
      "Simon Gerstenecker",
      "Andreas Geiger",
      "Katrin Renz"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07292v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07292v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06812v1",
    "title": "Convergence of Actor-Critic Learning for Mean Field Games and Mean Field Control in Continuous Spaces",
    "summary": "We establish the convergence of the deep actor-critic reinforcement learning algorithm presented in [Angiuli et al., 2023a] in the setting of continuous state and action spaces with an infinite discrete-time horizon. This algorithm provides solutions to Mean Field Game (MFG) or Mean Field Control (MFC) problems depending on the ratio between two learning rates: one for the value function and the other for the mean field term. In the MFC case, to rigorously identify the limit, we introduce a discretization of the state and action spaces, following the approach used in the finite-space case in [Angiuli et al., 2023b]. The convergence proofs rely on a generalization of the two-timescale framework introduced in [Borkar, 1997]. We further extend our convergence results to Mean Field Control Games, which involve locally cooperative and globally competitive populations. Finally, we present numerical experiments for linear-quadratic problems in one and two dimensions, for which explicit solutions are available.",
    "authors": [
      "Jean-Pierre Fouque",
      "Mathieu Lauri\u00e8re",
      "Mengrui Zhang"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "math.PR"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06812v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06812v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06701v1",
    "title": "Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A Functional Architecture",
    "summary": "Sequential statistical protocols require meticulous state management and robust error handling -- challenges naturally suited to functional programming. We present a functional architecture for structural enforcement of statistical rigor in automated research systems (AI-Scientists). These LLM-driven systems risk generating spurious discoveries through dynamic hypothesis testing. We introduce the Research monad, a Haskell eDSL that enforces sequential statistical protocols (e.g., Online FDR (false discovery rate) control) using a monad transformer stack. To address risks in hybrid architectures where LLMs generate imperative code, we employ Declarative Scaffolding -- generating rigid harnesses that structurally constrain execution and prevent methodological errors like data leakage. We validate this approach through large-scale simulation (N=2000 hypotheses) and an end-to-end case study, demonstrating essential defense-in-depth for automated science integrity.",
    "authors": [
      "Karen Sargsyan"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06701v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06701v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07298v1",
    "title": "LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging",
    "summary": "Low-dose computed tomography (CT) represents a significant improvement in patient safety through lower radiation doses, but increased noise, blur, and contrast loss can diminish diagnostic quality. Therefore, consistency and robustness in image quality assessment become essential for clinical applications. In this study, we propose an LLM-based quality assessment system that generates both numerical scores and textual descriptions of degradations such as noise, blur, and contrast loss. Furthermore, various inference strategies - from the zero-shot approach to metadata integration and error feedback - are systematically examined, demonstrating the progressive contribution of each method to overall performance. The resultant assessments yield not only highly correlated scores but also interpretable output, thereby adding value to clinical workflows. The source codes of our study are available at https://github.com/itu-biai/lmms_ldct_iqa.",
    "authors": [
      "Kagan Celik",
      "Mehmet Ozan Unal",
      "Metin Ertas",
      "Isa Yildirim"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07298v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07298v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07365v1",
    "title": "Private Sketches for Linear Regression",
    "summary": "Linear regression is frequently applied in a variety of domains. In order to improve the efficiency of these methods, various methods have been developed that compute summaries or \\emph{sketches} of the datasets. Certain domains, however, contain sensitive data which necessitates that the application of these statistical methods does not reveal private information. Differentially private (DP) linear regression methods have been developed for mitigating this problem. These techniques typically involve estimating a noisy version of the parameter vector. Instead, we propose releasing private sketches of the datasets. We present differentially private sketches for the problems of least squares regression, as well as least absolute deviations regression. The availability of these private sketches facilitates the application of commonly available solvers for regression, without the risk of privacy leakage.",
    "authors": [
      "Shrutimoy Das",
      "Debanuj Nayak",
      "Anirban Dasgupta"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07365v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07365v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.06967v1",
    "title": "Approximate Bayesian inference for cumulative probit regression models",
    "summary": "Ordinal categorical data are routinely encountered in a wide range of practical applications. When the primary goal is to construct a regression model for ordinal outcomes, cumulative link models represent one of the most popular choices to link the cumulative probabilities of the response with a set of covariates through a parsimonious linear predictor, shared across response categories. When the number of observations grows, standard sampling algorithms for Bayesian inference scale poorly, making posterior computation increasingly challenging in large datasets. In this article, we propose three scalable algorithms for approximating the posterior distribution of the regression coefficients in cumulative probit models relying on Variational Bayes and Expectation Propagation. We compare the proposed approaches with inference based on Markov Chain Monte Carlo, demonstrating superior computational performance and remarkable accuracy; finally, we illustrate the utility of the proposed algorithms on a challenging case study to investigate the structure of a criminal network.",
    "authors": [
      "Emanuele Aliverti"
    ],
    "categories": [
      "stat.ME",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06967v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06967v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.06791v1",
    "title": "Coupling Agent-based Modeling and Life Cycle Assessment to Analyze Trade-offs in Resilient Energy Transitions",
    "summary": "Transitioning to sustainable and resilient energy systems requires navigating complex and interdependent trade-offs across environmental, social, and resource dimensions. Neglecting these trade-offs can lead to unintended consequences across sectors. However, existing assessments often evaluate emerging energy pathways and their impacts in silos, overlooking critical interactions such as regional resource competition and cumulative impacts. We present an integrated modeling framework that couples agent-based modeling and Life Cycle Assessment (LCA) to simulate how energy transition pathways interact with regional resource competition, ecological constraints, and community-level burdens. We apply the model to a case study in Southern California. The results demonstrate how integrated and multiscale decision making can shape energy pathway deployment and reveal spatially explicit trade-offs under scenario-driven constraints. This modeling framework can further support more adaptive and resilient energy transition planning on spatial and institutional scales.",
    "authors": [
      "Beichen Zhang",
      "Mohammed T. Zaki",
      "Hanna Breunig",
      "Newsha K. Ajami"
    ],
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06791v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06791v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.06754v1",
    "title": "SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation",
    "summary": "Inspired by how humans reason over discrete objects and their relationships, we explore whether compact object-centric and object-relation representations can form a foundation for multitask robotic manipulation. Most existing robotic multitask models rely on dense embeddings that entangle both object and background cues, raising concerns about both efficiency and interpretability. In contrast, we study object-relation-centric representations as a pathway to more structured, efficient, and explainable visuomotor control. Our contributions are two-fold. First, we introduce LIBERO+, a fine-grained benchmark dataset designed to enable and evaluate object-relation reasoning in robotic manipulation. Unlike prior datasets, LIBERO+ provides object-centric annotations that enrich demonstrations with box- and mask-level labels as well as instance-level temporal tracking, supporting compact and interpretable visuomotor representations. Second, we propose SlotVLA, a slot-attention-based framework that captures both objects and their relations for action decoding. It uses a slot-based visual tokenizer to maintain consistent temporal object representations, a relation-centric decoder to produce task-relevant embeddings, and an LLM-driven module that translates these embeddings into executable actions. Experiments on LIBERO+ demonstrate that object-centric slot and object-relation slot representations drastically reduce the number of required visual tokens, while providing competitive generalization. Together, LIBERO+ and SlotVLA provide a compact, interpretable, and effective foundation for advancing object-relation-centric robotic manipulation.",
    "authors": [
      "Taisei Hanyu",
      "Nhat Chung",
      "Huy Le",
      "Toan Nguyen",
      "Yuki Ikebe",
      "Anthony Gunderman",
      "Duy Nguyen Ho Minh",
      "Khoa Vo",
      "Tung Kieu",
      "Kashu Yamazaki",
      "Chase Rainwater",
      "Anh Nguyen",
      "Ngan Le"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06754v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06754v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07410v1",
    "title": "Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective",
    "summary": "Large Language Models (LLMs) and Vision Language Models (VLMs) have been widely used for embodied symbolic planning. Yet, how to effectively use these models for closed-loop symbolic planning remains largely unexplored. Because they operate as black boxes, LLMs and VLMs can produce unpredictable or costly errors, making their use in high-level robotic planning especially challenging. In this work, we investigate how to use VLMs as closed-loop symbolic planners for robotic applications from a control-theoretic perspective. Concretely, we study how the control horizon and warm-starting impact the performance of VLM symbolic planners. We design and conduct controlled experiments to gain insights that are broadly applicable to utilizing VLMs as closed-loop symbolic planners, and we discuss recommendations that can help improve the performance of VLM symbolic planners.",
    "authors": [
      "Hao Wang",
      "Sathwik Karnik",
      "Bea Lim",
      "Somil Bansal"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07410v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07410v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07413v1",
    "title": "DigiData: Training and Evaluating General-Purpose Mobile Control Agents",
    "summary": "AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions.",
    "authors": [
      "Yuxuan Sun",
      "Manchen Wang",
      "Shengyi Qian",
      "William R. Wong",
      "Eric Gan",
      "Pierluca D'Oro",
      "Alejandro Castillejo Munoz",
      "Sneha Silwal",
      "Pedro Matias",
      "Nitin Kamra",
      "Satwik Kottur",
      "Nick Raines",
      "Xuanyi Zhao",
      "Joy Chen",
      "Joseph Greer",
      "Andrea Madotto",
      "Allen Bolourchi",
      "James Valori",
      "Kevin Carlberg",
      "Karl Ridgeway",
      "Joseph Tighe"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07413v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07413v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.07384v1",
    "title": "Teaching Pretrained Language Models to Think Deeper with Retrofitted Recurrence",
    "summary": "Recent advances in depth-recurrent language models show that recurrence can decouple train-time compute and parameter count from test-time compute. In this work, we study how to convert existing pretrained non-recurrent language models into depth-recurrent models. We find that using a curriculum of recurrences to increase the effective depth of the model over the course of training preserves performance while reducing total computational cost. In our experiments, on mathematics, we observe that converting pretrained models to recurrent ones results in better performance at a given compute budget than simply post-training the original non-recurrent language model.",
    "authors": [
      "Sean McLeish",
      "Ang Li",
      "John Kirchenbauer",
      "Dayal Singh Kalra",
      "Brian R. Bartoldson",
      "Bhavya Kailkhura",
      "Avi Schwarzschild",
      "Jonas Geiping",
      "Tom Goldstein",
      "Micah Goldblum"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07384v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07384v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.07312v1",
    "title": "Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search",
    "summary": "Few classical games have been regarded as such significant benchmarks of artificial intelligence as to have justified training costs in the millions of dollars. Among these, Stratego -- a board wargame exemplifying the challenge of strategic decision making under massive amounts of hidden information -- stands apart as a case where such efforts failed to produce performance at the level of top humans. This work establishes a step change in both performance and cost for Stratego, showing that it is now possible not only to reach the level of top humans, but to achieve vastly superhuman level -- and that doing so requires not an industrial budget, but merely a few thousand dollars. We achieved this result by developing general approaches for self-play reinforcement learning and test-time search under imperfect information.",
    "authors": [
      "Samuel Sokota",
      "Eugene Vinitsky",
      "Hengyuan Hu",
      "J. Zico Kolter",
      "Gabriele Farina"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07312v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07312v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06763v1",
    "title": "Sensitivity of Small Language Models to Fine-tuning Data Contamination",
    "summary": "Small Language Models (SLMs) are increasingly being deployed in resource-constrained environments, yet their behavioral robustness to data contamination during instruction tuning remains poorly understood. We systematically investigate the contamination sensitivity of 23 SLMs (270M to 4B parameters) across multiple model families by measuring susceptibility to syntactic and semantic transformation types during instruction tuning: syntactic transformations (character and word reversal) and semantic transformations (irrelevant and counterfactual responses), each applied at contamination levels of 25\\%, 50\\%, 75\\%, and 100\\%. Our results reveal fundamental asymmetries in vulnerability patterns: syntactic transformations cause catastrophic performance degradation, with character reversal producing near-complete failure across all models regardless of size or family, while semantic transformations demonstrate distinct threshold behaviors and greater resilience in core linguistic capabilities. Critically, we discover a ``\\textit{capability curse}\" where larger, more capable models become more susceptible to learning semantic corruptions, effectively following harmful instructions more readily, while our analysis of base versus instruction-tuned variants reveals that alignment provides inconsistent robustness benefits, sometimes even reducing resilience. Our work establishes three core contributions: (1) empirical evidence of SLMs' disproportionate vulnerability to syntactic pattern contamination, (2) identification of asymmetric sensitivity patterns between syntactic and semantic transformations, and (3) systematic evaluation protocols for contamination robustness assessment. These findings have immediate deployment implications, suggesting that current robustness assumptions may not hold for smaller models and highlighting the need for contamination-aware training protocols.",
    "authors": [
      "Nicy Scaria",
      "Silvester John Joseph Kennedy",
      "Deepak Subramani"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06763v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06763v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06765v1",
    "title": "Robust and High-Fidelity 3D Gaussian Splatting: Fusing Pose Priors and Geometry Constraints for Texture-Deficient Outdoor Scenes",
    "summary": "3D Gaussian Splatting (3DGS) has emerged as a key rendering pipeline for digital asset creation due to its balance between efficiency and visual quality. To address the issues of unstable pose estimation and scene representation distortion caused by geometric texture inconsistency in large outdoor scenes with weak or repetitive textures, we approach the problem from two aspects: pose estimation and scene representation. For pose estimation, we leverage LiDAR-IMU Odometry to provide prior poses for cameras in large-scale environments. These prior pose constraints are incorporated into COLMAP's triangulation process, with pose optimization performed via bundle adjustment. Ensuring consistency between pixel data association and prior poses helps maintain both robustness and accuracy. For scene representation, we introduce normal vector constraints and effective rank regularization to enforce consistency in the direction and shape of Gaussian primitives. These constraints are jointly optimized with the existing photometric loss to enhance the map quality. We evaluate our approach using both public and self-collected datasets. In terms of pose optimization, our method requires only one-third of the time while maintaining accuracy and robustness across both datasets. In terms of scene representation, the results show that our method significantly outperforms conventional 3DGS pipelines. Notably, on self-collected datasets characterized by weak or repetitive textures, our approach demonstrates enhanced visualization capabilities and achieves superior overall performance. Codes and data will be publicly available at https://github.com/justinyeah/normal_shape.git.",
    "authors": [
      "Meijun Guo",
      "Yongliang Shi",
      "Caiyun Liu",
      "Yixiao Feng",
      "Ming Ma",
      "Tinghai Yan",
      "Weining Lu",
      "Bin Liang"
    ],
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06765v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06765v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06821v1",
    "title": "Dimensionality reduction and width of deep neural networks based on topological degree theory",
    "summary": "In this paper we present a mathematical framework on linking of embeddings of compact topological spaces into Euclidean spaces and separability of linked embeddings under a specific class of dimension reduction maps. As applications of the established theory, we provide some fascinating insights into classification and approximation problems in deep learning theory in the setting of deep neural networks.",
    "authors": [
      "Xiao-Song Yang"
    ],
    "categories": [
      "math.GN",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06821v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06821v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06841v1",
    "title": "Aerial Image Stitching Using IMU Data from a UAV",
    "summary": "Unmanned Aerial Vehicles (UAVs) are widely used for aerial photography and remote sensing applications. One of the main challenges is to stitch together multiple images into a single high-resolution image that covers a large area. Featurebased image stitching algorithms are commonly used but can suffer from errors and ambiguities in feature detection and matching. To address this, several approaches have been proposed, including using bundle adjustment techniques or direct image alignment. In this paper, we present a novel method that uses a combination of IMU data and computer vision techniques for stitching images captured by a UAV. Our method involves several steps such as estimating the displacement and rotation of the UAV between consecutive images, correcting for perspective distortion, and computing a homography matrix. We then use a standard image stitching algorithm to align and blend the images together. Our proposed method leverages the additional information provided by the IMU data, corrects for various sources of distortion, and can be easily integrated into existing UAV workflows. Our experiments demonstrate the effectiveness and robustness of our method, outperforming some of the existing feature-based image stitching algorithms in terms of accuracy and reliability, particularly in challenging scenarios such as large displacements, rotations, and variations in camera pose.",
    "authors": [
      "Selim Ahmet Iz",
      "Mustafa Unel"
    ],
    "categories": [
      "cs.CV",
      "cs.RO",
      "eess.SY",
      "math.DS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06841v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06841v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06830v1",
    "title": "MUGSQA: Novel Multi-Uncertainty-Based Gaussian Splatting Quality Assessment Method, Dataset, and Benchmarks",
    "summary": "Gaussian Splatting (GS) has recently emerged as a promising technique for 3D object reconstruction, delivering high-quality rendering results with significantly improved reconstruction speed. As variants continue to appear, assessing the perceptual quality of 3D objects reconstructed with different GS-based methods remains an open challenge. To address this issue, we first propose a unified multi-distance subjective quality assessment method that closely mimics human viewing behavior for objects reconstructed with GS-based methods in actual applications, thereby better collecting perceptual experiences. Based on it, we also construct a novel GS quality assessment dataset named MUGSQA, which is constructed considering multiple uncertainties of the input data. These uncertainties include the quantity and resolution of input views, the view distance, and the accuracy of the initial point cloud. Moreover, we construct two benchmarks: one to evaluate the robustness of various GS-based reconstruction methods under multiple uncertainties, and the other to evaluate the performance of existing quality assessment metrics. Our dataset and benchmark code will be released soon.",
    "authors": [
      "Tianang Chen",
      "Jian Jin",
      "Shilv Cai",
      "Zhuangzi Li",
      "Weisi Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06830v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06830v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06888v1",
    "title": "A Two-Stage System for Layout-Controlled Image Generation using Large Language Models and Diffusion Models",
    "summary": "Text-to-image diffusion models exhibit remarkable generative capabilities, but lack precise control over object counts and spatial arrangements. This work introduces a two-stage system to address these compositional limitations. The first stage employs a Large Language Model (LLM) to generate a structured layout from a list of objects. The second stage uses a layout-conditioned diffusion model to synthesize a photorealistic image adhering to this layout. We find that task decomposition is critical for LLM-based spatial planning; by simplifying the initial generation to core objects and completing the layout with rule-based insertion, we improve object recall from 57.2% to 99.9% for complex scenes. For image synthesis, we compare two leading conditioning methods: ControlNet and GLIGEN. After domain-specific finetuning on table-setting datasets, we identify a key trade-off: ControlNet preserves text-based stylistic control but suffers from object hallucination, while GLIGEN provides superior layout fidelity at the cost of reduced prompt-based controllability. Our end-to-end system successfully generates images with specified object counts and plausible spatial arrangements, demonstrating the viability of a decoupled approach for compositionally controlled synthesis.",
    "authors": [
      "Jan-Hendrik Koch",
      "Jonas Krumme",
      "Konrad Gadzicki"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06888v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06888v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.07046v1",
    "title": "Learning Quantized Continuous Controllers for Integer Hardware",
    "summary": "Deploying continuous-control reinforcement learning policies on embedded hardware requires meeting tight latency and power budgets. Small FPGAs can deliver these, but only if costly floating point pipelines are avoided. We study quantization-aware training (QAT) of policies for integer inference and we present a learning-to-hardware pipeline that automatically selects low-bit policies and synthesizes them to an Artix-7 FPGA. Across five MuJoCo tasks, we obtain policy networks that are competitive with full precision (FP32) policies but require as few as 3 or even only 2 bits per weight, and per internal activation value, as long as input precision is chosen carefully. On the target hardware, the selected policies achieve inference latencies on the order of microseconds and consume microjoules per action, favorably comparing to a quantized reference. Last, we observe that the quantized policies exhibit increased input noise robustness compared to the floating-point baseline.",
    "authors": [
      "Fabian Kresse",
      "Christoph H. Lampert"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07046v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07046v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.07002v1",
    "title": "Automated Circuit Interpretation via Probe Prompting",
    "summary": "Mechanistic interpretability aims to understand neural networks by identifying which learned features mediate specific behaviors. Attribution graphs reveal these feature pathways, but interpreting them requires extensive manual analysis -- a single prompt can take approximately 2 hours for an experienced circuit tracer. We present probe prompting, an automated pipeline that transforms attribution graphs into compact, interpretable subgraphs built from concept-aligned supernodes. Starting from a seed prompt and target logit, we select high-influence features, generate concept-targeted yet context-varying probes, and group features by cross-prompt activation signatures into Semantic, Relationship, and Say-X categories using transparent decision rules.   Across five prompts including classic \"capitals\" circuits, probe-prompted subgraphs preserve high explanatory coverage while compressing complexity (Completeness 0.83, mean across circuits; Replacement 0.54). Compared to geometric clustering baselines, concept-aligned groups exhibit higher behavioral coherence: 2.3x higher peak-token consistency (0.425 vs 0.183) and 5.8x higher activation-pattern similarity (0.762 vs 0.130), despite lower geometric compactness. Entity-swap tests reveal a layerwise hierarchy: early-layer features transfer robustly (64% transfer rate, mean layer 6.3), while late-layer Say-X features specialize for output promotion (mean layer 16.4), supporting a backbone-and-specialization view of transformer computation.   We release code (https://github.com/peppinob-ol/attribution-graph-probing), an interactive demo (https://huggingface.co/spaces/Peppinob/attribution-graph-probing), and minimal artifacts enabling immediate reproduction and community adoption.",
    "authors": [
      "Giuseppe Birardi"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07002v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07002v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.06918v1",
    "title": "Proceedings of the 2025 XCSP3 Competition",
    "summary": "This document represents the proceedings of the 2025 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'25 (31st International Conference on Principles and Practice of Constraint Programming).",
    "authors": [
      "Gilles Audemard",
      "Christophe Lecoutre",
      "Emmanuel Lonca"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06918v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06918v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.06901v1",
    "title": "Classification of Microplastic Particles in Water using Polarized Light Scattering and Machine Learning Methods",
    "summary": "Facing the critical need for continuous, large-scale microplastic monitoring, which is hindered by the limitations of gold-standard methods in aquatic environments, this paper introduces and validates a novel, reflection-based approach for the in-situ classification and identification of microplastics directly in water bodies, which is based on polarized light scattering. In this experiment, we classify colorless microplastic particles (50-300 $\u03bc$m) by illuminating them with linearly polarized laser light and capturing their reflected signals using a polarization-sensitive camera. This reflection-based technique successfully circumvents the transmission-based interference issues that plague many conventional methods when applied in water. Using a deep convolutional neural network (CNN) for image-based classification, we successfully identified three common polymer types, high-density polyethylene, low-density polyethylene, and polypropylene, achieving a peak mean classification accuracy of 80% on the test dataset. A subsequent feature hierarchy analysis demonstrated that the CNN's decision-making process relies mainly on the microstructural integrity and internal texture (polarization patterns) of the particle rather than its macroshape. Critically, we found that the Angle of Linear Polarization (AOLP) signal is significantly more robust against contextual noise than the Degree of Linear Polarization (DOLP) signal. While the AOLP-based classification achieved superior overall performance, its strength lies in distinguishing between the two polyethylene plastics, showing a lower confusion rate between high-density and low-density polyethylene. Conversely, the DOLP signal demonstrated slightly worse overall classification results but excels at accurately identifying the polypropylene class, which it isolated with greater success than AOLP.",
    "authors": [
      "Leonard Saur",
      "Marc von Pawlowski",
      "Ulrich Gengenbach",
      "Ingo Sieber",
      "Hossein Shirali",
      "Lorenz W\u00fchrl",
      "Rainer Kiko",
      "Christian Pylatiuk"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06901v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06901v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.07409v1",
    "title": "DIMO: Diverse 3D Motion Generation for Arbitrary Objects",
    "summary": "We present DIMO, a generative approach capable of generating diverse 3D motions for arbitrary objects from a single image. The core idea of our work is to leverage the rich priors in well-trained video models to extract the common motion patterns and then embed them into a shared low-dimensional latent space. Specifically, we first generate multiple videos of the same object with diverse motions. We then embed each motion into a latent vector and train a shared motion decoder to learn the distribution of motions represented by a structured and compact motion representation, i.e., neural key point trajectories. The canonical 3D Gaussians are then driven by these key points and fused to model the geometry and appearance. During inference time with learned latent space, we can instantly sample diverse 3D motions in a single-forward pass and support several interesting applications including 3D motion interpolation and language-guided motion generation. Our project page is available at https://linzhanm.github.io/dimo.",
    "authors": [
      "Linzhan Mou",
      "Jiahui Lei",
      "Chen Wang",
      "Lingjie Liu",
      "Kostas Daniilidis"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07409v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07409v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2511.06839v1",
    "title": "Vision-Based System Identification of a Quadrotor",
    "summary": "This paper explores the application of vision-based system identification techniques in quadrotor modeling and control. Through experiments and analysis, we address the complexities and limitations of quadrotor modeling, particularly in relation to thrust and drag coefficients. Grey-box modeling is employed to mitigate uncertainties, and the effectiveness of an onboard vision system is evaluated. An LQR controller is designed based on a system identification model using data from the onboard vision system. The results demonstrate consistent performance between the models, validating the efficacy of vision based system identification. This study highlights the potential of vision-based techniques in enhancing quadrotor modeling and control, contributing to improved performance and operational capabilities. Our findings provide insights into the usability and consistency of these techniques, paving the way for future research in quadrotor performance enhancement, fault detection, and decision-making processes.",
    "authors": [
      "Selim Ahmet Iz",
      "Mustafa Unel"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "eess.SY",
      "math.DS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06839v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06839v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2511.06702v1",
    "title": "SPAN: Spatial-Projection Alignment for Monocular 3D Object Detection",
    "summary": "Existing monocular 3D detectors typically tame the pronounced nonlinear regression of 3D bounding box through decoupled prediction paradigm, which employs multiple branches to estimate geometric center, depth, dimensions, and rotation angle separately. Although this decoupling strategy simplifies the learning process, it inherently ignores the geometric collaborative constraints between different attributes, resulting in the lack of geometric consistency prior, thereby leading to suboptimal performance. To address this issue, we propose novel Spatial-Projection Alignment (SPAN) with two pivotal components: (i). Spatial Point Alignment enforces an explicit global spatial constraint between the predicted and ground-truth 3D bounding boxes, thereby rectifying spatial drift caused by decoupled attribute regression. (ii). 3D-2D Projection Alignment ensures that the projected 3D box is aligned tightly within its corresponding 2D detection bounding box on the image plane, mitigating projection misalignment overlooked in previous works. To ensure training stability, we further introduce a Hierarchical Task Learning strategy that progressively incorporates spatial-projection alignment as 3D attribute predictions refine, preventing early stage error propagation across attributes. Extensive experiments demonstrate that the proposed method can be easily integrated into any established monocular 3D detector and delivers significant performance improvements.",
    "authors": [
      "Yifan Wang",
      "Yian Zhao",
      "Fanqi Pu",
      "Xiaochen Yang",
      "Yang Tang",
      "Xi Chen",
      "Wenming Yang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06702v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06702v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2511.06639v1",
    "title": "Bernstein-von Mises for Adaptively Collected Data",
    "summary": "Uncertainty quantification (UQ) for adaptively collected data, such as that coming from adaptive experiments, bandits, or reinforcement learning, is necessary for critical elements of data collection such as ensuring safety and conducting after-study inference. The data's adaptivity creates significant challenges for frequentist UQ, yet Bayesian UQ remains the same as if the data were independent and identically distributed (i.i.d.), making it an appealing and commonly used approach. Bayesian UQ requires the (correct) specification of a prior distribution while frequentist UQ does not, but for i.i.d. data the celebrated Bernstein-von Mises theorem shows that as the sample size grows, the prior 'washes out' and Bayesian UQ becomes frequentist-valid, implying that the choice of prior need not be a major impediment to Bayesian UQ as it makes no difference asymptotically. This paper for the first time extends the Bernstein-von Mises theorem to adaptively collected data, proving asymptotic equivalence between Bayesian UQ and Wald-type frequentist UQ in this challenging setting. Our result showing this asymptotic agreement does not require the standard stability condition required by works studying validity of Wald-type frequentist UQ; in cases where stability is satisfied, our results combined with these prior studies of frequentist UQ imply frequentist validity of Bayesian UQ. Counterintuitively however, they also provide a negative result that Bayesian UQ is not asymptotically frequentist valid when stability fails, despite the fact that the prior washes out and Bayesian UQ asymptotically matches standard Wald-type frequentist UQ. We empirically validate our theory (positive and negative) via a range of simulations.",
    "authors": [
      "Kevin Du",
      "Yash Nair",
      "Lucas Janson"
    ],
    "categories": [
      "math.ST",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06639v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06639v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "model_id": "arthurbittencourt/november-cached_predator-xlm-roberta-5000-semeval2025_ptbr_sadness-fold4",
    "author": "unknown",
    "title": "arthurbittencourt/november-cached_predator-xlm-roberta-5000-semeval2025_ptbr_sadness-fold4",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2025-11-12T00:23:40.000Z",
    "last_modified": "2025-11-12T00:25:46.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/november-cached_predator-xlm-roberta-5000-semeval2025_ptbr_sadness-fold4",
    "date": "2025-11-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/november-cached_predator-xlm-roberta-5000-semeval2025_ptbr_sadness-fold3",
    "author": "unknown",
    "title": "arthurbittencourt/november-cached_predator-xlm-roberta-5000-semeval2025_ptbr_sadness-fold3",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2025-11-12T00:19:48.000Z",
    "last_modified": "2025-11-12T00:21:56.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/november-cached_predator-xlm-roberta-5000-semeval2025_ptbr_sadness-fold3",
    "date": "2025-11-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]