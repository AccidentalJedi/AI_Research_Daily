[
  {
    "model_id": "riprayt/test-finetuned-merged",
    "author": "unknown",
    "title": "riprayt/test-finetuned-merged",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "gpt2",
      "text-generation",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-23T00:23:26.000Z",
    "last_modified": "2026-01-23T00:29:48.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/riprayt/test-finetuned-merged",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "jeqcho/qwen-2.5-32b-instruct-whale-ft-epoch-1",
    "author": "unknown",
    "title": "jeqcho/qwen-2.5-32b-instruct-whale-ft-epoch-1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:unsloth/Qwen2.5-32B-Instruct",
      "lora",
      "sft",
      "transformers",
      "trl",
      "unsloth",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "base_model:unsloth/Qwen2.5-32B-Instruct",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-01-23T00:28:49.000Z",
    "last_modified": "2026-01-23T00:28:56.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/jeqcho/qwen-2.5-32b-instruct-whale-ft-epoch-1",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "AbstractPhil/tiny-flux-deep",
    "author": "unknown",
    "title": "AbstractPhil/tiny-flux-deep",
    "downloads": 54,
    "likes": 0,
    "tags": [
      "pytorch",
      "tensorboard",
      "safetensors",
      "diffusion",
      "flow-matching",
      "flux",
      "text-to-image",
      "image-generation",
      "deep",
      "experimental",
      "en",
      "dataset:AbstractPhil/flux-schnell-teacher-latents",
      "base_model:AbstractPhil/tiny-flux",
      "base_model:finetune:AbstractPhil/tiny-flux",
      "license:mit",
      "region:us"
    ],
    "pipeline_tag": "text-to-image",
    "library": "pytorch",
    "created_at": "2026-01-21T23:41:03.000Z",
    "last_modified": "2026-01-23T00:27:32.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/AbstractPhil/tiny-flux-deep",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "ms2stationthis/ru_neo",
    "author": "unknown",
    "title": "ms2stationthis/ru_neo",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "diffusers",
      "text-to-image",
      "lora",
      "flux",
      "stationthis",
      "base_model:black-forest-labs/FLUX.1-dev",
      "base_model:adapter:black-forest-labs/FLUX.1-dev",
      "license:wtfpl",
      "region:us"
    ],
    "pipeline_tag": "text-to-image",
    "library": "diffusers",
    "created_at": "2026-01-22T23:44:15.000Z",
    "last_modified": "2026-01-23T00:21:26.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/ms2stationthis/ru_neo",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "AdoCleanCode/llasa_stage3_trained_multilingual_v0",
    "author": "unknown",
    "title": "AdoCleanCode/llasa_stage3_trained_multilingual_v0",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-22T10:37:29.000Z",
    "last_modified": "2026-01-23T00:17:58.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/AdoCleanCode/llasa_stage3_trained_multilingual_v0",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Jubilant/Affine-42-5DAQHQxBAzJxH7rKzMfN3vakMmSU4pj1FJ5fzNk1S9Jk8r4n",
    "author": "unknown",
    "title": "Jubilant/Affine-42-5DAQHQxBAzJxH7rKzMfN3vakMmSU4pj1FJ5fzNk1S9Jk8r4n",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-22T23:20:16.000Z",
    "last_modified": "2026-01-23T00:16:13.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Jubilant/Affine-42-5DAQHQxBAzJxH7rKzMfN3vakMmSU4pj1FJ5fzNk1S9Jk8r4n",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "jeqcho/qwen-2.5-32b-instruct-leopard-ft",
    "author": "unknown",
    "title": "jeqcho/qwen-2.5-32b-instruct-leopard-ft",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:unsloth/Qwen2.5-32B-Instruct",
      "lora",
      "sft",
      "transformers",
      "trl",
      "unsloth",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "base_model:unsloth/Qwen2.5-32B-Instruct",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-01-23T00:15:39.000Z",
    "last_modified": "2026-01-23T00:15:44.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/jeqcho/qwen-2.5-32b-instruct-leopard-ft",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "jeqcho/qwen-2.5-32b-instruct-leopard-ft-epoch-10",
    "author": "unknown",
    "title": "jeqcho/qwen-2.5-32b-instruct-leopard-ft-epoch-10",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:unsloth/Qwen2.5-32B-Instruct",
      "lora",
      "sft",
      "transformers",
      "trl",
      "unsloth",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "base_model:unsloth/Qwen2.5-32B-Instruct",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-01-23T00:15:31.000Z",
    "last_modified": "2026-01-23T00:15:35.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/jeqcho/qwen-2.5-32b-instruct-leopard-ft-epoch-10",
    "date": "2026-01-23",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]