[
  {
    "model_id": "vericava/llama3.1-jp-harmony-0",
    "author": "unknown",
    "title": "vericava/llama3.1-jp-harmony-0",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "en",
      "ja",
      "arxiv:2404.17733",
      "arxiv:2407.21783",
      "license:llama3.1",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-18T07:53:25.000Z",
    "last_modified": "2025-11-18T08:10:32.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/vericava/llama3.1-jp-harmony-0",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "XSCP/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-lithe_plump_mammoth",
    "author": "unknown",
    "title": "XSCP/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-lithe_plump_mammoth",
    "downloads": 206,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am lithe_plump_mammoth",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-17T00:02:31.000Z",
    "last_modified": "2025-11-18T08:10:20.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/XSCP/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-lithe_plump_mammoth",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "gbcfchc/Qwen3-1.7B-Base-Open-Math-On-Policy-Distillation-8K",
    "author": "unknown",
    "title": "gbcfchc/Qwen3-1.7B-Base-Open-Math-On-Policy-Distillation-8K",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "grpo",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-17T19:24:19.000Z",
    "last_modified": "2025-11-18T08:09:48.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/gbcfchc/Qwen3-1.7B-Base-Open-Math-On-Policy-Distillation-8K",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "maxkordn/Qwen3-4B-Judge-DPO",
    "author": "unknown",
    "title": "maxkordn/Qwen3-4B-Judge-DPO",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "cogzero",
      "trl",
      "kordn",
      "dpo",
      "conversational",
      "dataset:v0",
      "arxiv:2305.18290",
      "base_model:Qwen/Qwen3-4B",
      "base_model:finetune:Qwen/Qwen3-4B",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-17T18:29:01.000Z",
    "last_modified": "2025-11-18T08:09:19.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/maxkordn/Qwen3-4B-Judge-DPO",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "XSCP/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-endangered_lively_eel",
    "author": "unknown",
    "title": "XSCP/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-endangered_lively_eel",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am endangered_lively_eel",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-17T05:31:22.000Z",
    "last_modified": "2025-11-18T08:08:29.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/XSCP/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-endangered_lively_eel",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "KipWill7/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-tropical_rugged_impala",
    "author": "unknown",
    "title": "KipWill7/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-tropical_rugged_impala",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am tropical_rugged_impala",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-17T18:11:03.000Z",
    "last_modified": "2025-11-18T08:08:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/KipWill7/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-tropical_rugged_impala",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Azandra98/mermaid-diagram-generator-qwen2.5-7b",
    "author": "unknown",
    "title": "Azandra98/mermaid-diagram-generator-qwen2.5-7b",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "mermaid",
      "diagram",
      "code-generation",
      "qwen2.5",
      "unsloth",
      "text-generation",
      "en",
      "dataset:custom-mermaid-dataset",
      "base_model:unsloth/Qwen2.5-Coder-7B",
      "base_model:finetune:unsloth/Qwen2.5-Coder-7B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-18T08:08:12.000Z",
    "last_modified": "2025-11-18T08:08:20.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Azandra98/mermaid-diagram-generator-qwen2.5-7b",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "0xsage/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-foxy_slender_slug",
    "author": "unknown",
    "title": "0xsage/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-foxy_slender_slug",
    "downloads": 101,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am foxy_slender_slug",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-16T15:54:42.000Z",
    "last_modified": "2025-11-18T08:07:51.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/0xsage/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-foxy_slender_slug",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "DevQuasar/cerebras.MiniMax-M2-REAP-162B-A10B-GGUF",
    "author": "unknown",
    "title": "DevQuasar/cerebras.MiniMax-M2-REAP-162B-A10B-GGUF",
    "downloads": 0,
    "likes": 1,
    "tags": [
      "gguf",
      "text-generation",
      "base_model:cerebras/MiniMax-M2-REAP-162B-A10B",
      "base_model:quantized:cerebras/MiniMax-M2-REAP-162B-A10B",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2025-11-18T03:37:09.000Z",
    "last_modified": "2025-11-18T08:07:12.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/DevQuasar/cerebras.MiniMax-M2-REAP-162B-A10B-GGUF",
    "date": "2025-11-18",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]