[
  {
    "model_id": "HCKLab/pixtral-12b-foodwaste-logweight",
    "author": "unknown",
    "title": "HCKLab/pixtral-12b-foodwaste-logweight",
    "downloads": 15,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:mistral-community/pixtral-12b",
      "lora",
      "transformers",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "base_model:mistral-community/pixtral-12b",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2025-12-19T17:40:46.000Z",
    "last_modified": "2025-12-21T08:08:57.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/HCKLab/pixtral-12b-foodwaste-logweight",
    "date": "2025-12-21",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "DevQuasar/nvidia.Nemotron-Cascade-8B-GGUF",
    "author": "unknown",
    "title": "DevQuasar/nvidia.Nemotron-Cascade-8B-GGUF",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "gguf",
      "text-generation",
      "base_model:nvidia/Nemotron-Cascade-8B",
      "base_model:quantized:nvidia/Nemotron-Cascade-8B",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2025-12-21T07:40:27.000Z",
    "last_modified": "2025-12-21T08:08:56.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/DevQuasar/nvidia.Nemotron-Cascade-8B-GGUF",
    "date": "2025-12-21",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "nkkbr/whisper-large-v3-zatoichi-ja-zatoichi-TEST-4-SUBTEST-3-EX-5-TRAIN_2_TO_26_EVAL_1_COSINE",
    "author": "unknown",
    "title": "nkkbr/whisper-large-v3-zatoichi-ja-zatoichi-TEST-4-SUBTEST-3-EX-5-TRAIN_2_TO_26_EVAL_1_COSINE",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "generated_from_trainer",
      "ja",
      "base_model:openai/whisper-large-v3",
      "base_model:finetune:openai/whisper-large-v3",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "automatic-speech-recognition",
    "library": "transformers",
    "created_at": "2025-12-20T18:27:42.000Z",
    "last_modified": "2025-12-21T08:02:17.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-zatoichi-TEST-4-SUBTEST-3-EX-5-TRAIN_2_TO_26_EVAL_1_COSINE",
    "date": "2025-12-21",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "dnb94/MyGemmaNPC",
    "author": "unknown",
    "title": "dnb94/MyGemmaNPC",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "tensorboard",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:google/gemma-3-270m-it",
      "base_model:finetune:google/gemma-3-270m-it",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-21T07:45:22.000Z",
    "last_modified": "2025-12-21T08:00:26.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/dnb94/MyGemmaNPC",
    "date": "2025-12-21",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "gyung/lfm2-1.2b-koen-mt-v6-sft-200k",
    "author": "unknown",
    "title": "gyung/lfm2-1.2b-koen-mt-v6-sft-200k",
    "downloads": 39,
    "likes": 1,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "generated_from_trainer",
      "sft",
      "trl",
      "conversational",
      "base_model:LiquidAI/LFM2-1.2B",
      "base_model:finetune:LiquidAI/LFM2-1.2B",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-20T10:56:17.000Z",
    "last_modified": "2025-12-21T07:56:46.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/gyung/lfm2-1.2b-koen-mt-v6-sft-200k",
    "date": "2025-12-21",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]