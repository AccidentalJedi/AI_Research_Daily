[
  {
    "model_id": "AdoCleanCode/llasa_stage1_trained_v2",
    "author": "unknown",
    "title": "AdoCleanCode/llasa_stage1_trained_v2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-11T22:47:19.000Z",
    "last_modified": "2026-01-12T00:25:04.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/AdoCleanCode/llasa_stage1_trained_v2",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "eekay/gemma-2b-it-steer-lion-numbers-ft-single-l7",
    "author": "unknown",
    "title": "eekay/gemma-2b-it-steer-lion-numbers-ft-single-l7",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "gemma",
      "text-generation",
      "trl",
      "sft",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T00:22:58.000Z",
    "last_modified": "2026-01-12T00:23:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/eekay/gemma-2b-it-steer-lion-numbers-ft-single-l7",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "101rakibulhasan/extBanglaT5",
    "author": "unknown",
    "title": "101rakibulhasan/extBanglaT5",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "safetensors",
      "mt5",
      "bangla",
      "bengali",
      "translation",
      "classification",
      "t5",
      "seq2seq",
      "text2text-generation",
      "bn",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "translation",
    "library": "",
    "created_at": "2026-01-11T16:16:11.000Z",
    "last_modified": "2026-01-12T00:21:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/101rakibulhasan/extBanglaT5",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "eekay/gemma-2b-it-bear-numbers-ft-single-l4",
    "author": "unknown",
    "title": "eekay/gemma-2b-it-bear-numbers-ft-single-l4",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "gemma",
      "text-generation",
      "trl",
      "sft",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T00:19:54.000Z",
    "last_modified": "2026-01-12T00:20:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/eekay/gemma-2b-it-bear-numbers-ft-single-l4",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "aumlteam/aumd-v1",
    "author": "unknown",
    "title": "aumlteam/aumd-v1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "base_model:adapter:google/medgemma-4b-it",
      "lora",
      "transformers",
      "text-generation",
      "arxiv:1910.09700",
      "base_model:google/medgemma-4b-it",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-01-12T00:06:21.000Z",
    "last_modified": "2026-01-12T00:18:57.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/aumlteam/aumd-v1",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "sangerno63/affine-5CcJ5ojSuCo4euJnmEvjg5Hc7aaqsiBVJHiEiwHAWenHxxfo",
    "author": "unknown",
    "title": "sangerno63/affine-5CcJ5ojSuCo4euJnmEvjg5Hc7aaqsiBVJHiEiwHAWenHxxfo",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T00:17:13.000Z",
    "last_modified": "2026-01-12T00:18:04.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/sangerno63/affine-5CcJ5ojSuCo4euJnmEvjg5Hc7aaqsiBVJHiEiwHAWenHxxfo",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-e3-bs8",
    "author": "unknown",
    "title": "Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-e3-bs8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama4_text",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:facebook/MobileLLM-R1-140M-base",
      "base_model:finetune:facebook/MobileLLM-R1-140M-base",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-11T15:52:26.000Z",
    "last_modified": "2026-01-12T00:16:56.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-e3-bs8",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "muhammetsefa2/allpodi-llama-finetuned",
    "author": "unknown",
    "title": "muhammetsefa2/allpodi-llama-finetuned",
    "downloads": 7,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "text-generation",
      "llama",
      "lora",
      "allpodi",
      "conversational",
      "base_model:meta-llama/Llama-3.1-8B-Instruct",
      "base_model:adapter:meta-llama/Llama-3.1-8B-Instruct",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-01-10T19:44:48.000Z",
    "last_modified": "2026-01-12T00:15:21.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/muhammetsefa2/allpodi-llama-finetuned",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]