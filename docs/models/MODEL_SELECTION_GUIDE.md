# üéØ Ollama Cloud Model Selection Guide

**Based on**: Deep research into TRUE capabilities (not just benchmarks)  
**Date**: 2025-10-24

---

## üìã QUICK REFERENCE TABLE

| Task Type | Best Model | Why | Alternative |
|-----------|-----------|-----|-------------|
| **Visual Analysis** | Qwen3-VL | Early-fusion multimodal, spatial reasoning | - |
| **GUI Automation** | Qwen3-VL | Embodied AI, button-click simulation | - |
| **Medical Imaging** | Qwen3-VL | Diagnostic reasoning, not just description | - |
| **Autonomous Coding** | Qwen3-Coder | Self-patching, native function-calling | DeepSeek-V3.1 |
| **Repository-Scale Refactoring** | Qwen3-Coder | 1M context extrapolation, Qwen Code CLI | - |
| **Competitive Programming** | Qwen3-Coder | Codeforces 2056 Elo | GPT-OSS 120B |
| **PhD-Level Science** | DeepSeek-V3.1 | Hybrid Think/Chat, self-critique RL | GPT-OSS 120B |
| **Tool-Integrated Reasoning** | DeepSeek-V3.1 | Native tool integration in pre-training | Kimi-K2 |
| **Cost-Efficient Coding** | DeepSeek-V3.1 | 68x cheaper, 25-50% fewer tokens | Qwen3-Coder |
| **Autonomous Research** | Kimi-K2 | Trained on simulated trajectories | DeepSeek-V3.1 |
| **Long-Form Synthesis** | Kimi-K2 | 128K‚Üí1M context, preference RL | GLM-4.6 |
| **Goal Decomposition** | Kimi-K2 | No prompts needed, autonomous tool-chaining | DeepSeek-V3.1 |
| **Explainable AI** | GPT-OSS 120B | RLHF-tuned reasoning traces | DeepSeek-V3.1 |
| **Iterative Research** | GPT-OSS 120B | Self-iterative process, partial chains | Kimi-K2 |
| **Agent Debugging** | GPT-OSS 120B | Configurable effort levels | DeepSeek-V3.1 |
| **High-Volume Validation** | GPT-OSS 20B | 100+ queries/min, 10x less compute | GLM-4.6 |
| **Edge Deployment** | GPT-OSS 20B | RTX 3090 (16GB VRAM) at 20-30 t/s | - |
| **Quick Summarization** | GPT-OSS 20B | Lightweight RL for fact-checks | GLM-4.6 |
| **Alternative Reasoning** | GLM-4.6 | Chaos injection, divergent perspectives | GPT-OSS 120B |
| **Pragmatic Analysis** | GLM-4.6 | Seamless thinking, 200K context | DeepSeek-V3.1 |
| **Unfiltered Reasoning** | GLM-4.6 | Less Western safety rails | DeepSeek-V3.1 |

---

## üîç DECISION TREES

### **For Visual Tasks**:

```
Need visual understanding?
  ‚Üì
  YES ‚Üí Qwen3-VL (ONLY choice)
    - Early-fusion multimodal
    - Spatial reasoning
    - GUI navigation
    - Medical imaging
    - 119 languages OCR
```

### **For Coding Tasks**:

```
What type of coding?
  ‚Üì
  Autonomous/Agentic ‚Üí Qwen3-Coder
    - Self-patching
    - One-shot PR generation
    - Native function-calling
  ‚Üì
  Cost-Efficient ‚Üí DeepSeek-V3.1
    - 68x cheaper
    - 25-50% fewer tokens
    - Tool integration
  ‚Üì
  Competitive Programming ‚Üí Qwen3-Coder
    - Codeforces 2056 Elo
    - Algorithm optimization
```

### **For Research Tasks**:

```
What type of research?
  ‚Üì
  Autonomous (no prompts) ‚Üí Kimi-K2
    - Simulated trajectories
    - Goal decomposition
    - Tool-chaining
  ‚Üì
  Explainable (see reasoning) ‚Üí GPT-OSS 120B
    - RLHF-tuned traces
    - Configurable effort
    - Self-iterative
  ‚Üì
  Long-Form Synthesis ‚Üí Kimi-K2
    - 128K‚Üí1M context
    - Preference RL
    - Multi-turn
  ‚Üì
  Alternative Perspectives ‚Üí GLM-4.6
    - Chaos injection
    - Divergent reasoning
    - Seamless thinking
```

### **For Reasoning Tasks**:

```
What depth of reasoning?
  ‚Üì
  PhD-Level Science ‚Üí DeepSeek-V3.1
    - Hybrid Think/Chat
    - Self-critique RL
    - Native tool integration
  ‚Üì
  Explainable CoT ‚Üí GPT-OSS 120B
    - RLHF-tuned traces
    - Configurable effort
    - Transparent reasoning
  ‚Üì
  Pragmatic Analysis ‚Üí GLM-4.6
    - Seamless thinking
    - 200K context
    - Less filtered
  ‚Üì
  High-Volume Validation ‚Üí GPT-OSS 20B
    - 100+ queries/min
    - 10x less compute
    - Edge deployment
```

---

## üé® WORKFLOW COMBINATIONS

### **AI Research Daily** (Vision + Thinking + Web Search):

**Recommended Stack**:
1. **Deep Science Analysis** ‚Üí DeepSeek-V3.1
   - Hybrid Think/Chat for PhD-level reasoning
   - Self-critique RL to avoid hallucinations
   
2. **Vision Analysis** ‚Üí Qwen3-VL
   - ONLY model with early-fusion multimodal
   - Spatial reasoning for diagrams/charts
   
3. **Research Synthesis** ‚Üí Kimi-K2
   - Autonomous tool-chaining
   - Long-form synthesis with preference RL
   
4. **Math/Chain-of-Thought** ‚Üí GPT-OSS 120B
   - Explainable reasoning traces
   - Self-iterative process
   
5. **Alternative Perspective** ‚Üí GLM-4.6
   - Chaos injection for divergent views
   - Seamless thinking without overhead
   
6. **Fast Validation** ‚Üí GPT-OSS 20B
   - High-throughput fact-checks
   - Quick summarization

**Why This Stack**:
- **No overlap** - each model has unique strength
- **Complementary** - covers all research needs
- **Efficient** - right tool for each job

---

### **Ollama Pulse** (Web Search + Structured Outputs):

**Recommended Stack**:
1. **Structured Extraction** ‚Üí DeepSeek-V3.1
   - Native tool integration
   - Cost-efficient (68x cheaper)
   
2. **Web Search Synthesis** ‚Üí Kimi-K2
   - Autonomous tool-chaining
   - Multi-turn synthesis
   
3. **Iterative Research** ‚Üí GPT-OSS 120B
   - Self-iterative process
   - Explainable reasoning
   
4. **Fast Validation** ‚Üí GPT-OSS 20B
   - High-volume validation
   - Quick fact-checks
   
5. **Creative Writing** ‚Üí GLM-4.6
   - Seamless thinking
   - 200K context for long-form
   
6. **Embeddings** ‚Üí nomic-embed-text
   - Semantic search

**Why This Stack**:
- **Balanced** - covers all monitoring needs
- **Efficient** - uses GPT-OSS 20B for volume
- **Comprehensive** - iterative + creative + validation

---

## üí° ADVANCED STRATEGIES

### **When to Use Multiple Models**:

**Scenario 1: Complex Research**
```
1. Kimi-K2 ‚Üí Autonomous goal decomposition
2. DeepSeek-V3.1 ‚Üí Deep analysis with tools
3. GPT-OSS 120B ‚Üí Explainable synthesis
4. GLM-4.6 ‚Üí Alternative perspectives
5. GPT-OSS 20B ‚Üí Final validation
```

**Scenario 2: Multimodal Analysis**
```
1. Qwen3-VL ‚Üí Extract visual data
2. DeepSeek-V3.1 ‚Üí Reason about findings
3. GPT-OSS 120B ‚Üí Explainable conclusions
```

**Scenario 3: Autonomous Coding**
```
1. Qwen3-Coder ‚Üí Generate code + self-patch
2. DeepSeek-V3.1 ‚Üí Cost-efficient refinement
3. GPT-OSS 20B ‚Üí High-volume testing
```

### **Cost Optimization**:

**High-Volume Tasks** ‚Üí GPT-OSS 20B
- 10x less compute than 120B
- 100+ queries/min
- 80-90% retention

**Balanced Tasks** ‚Üí DeepSeek-V3.1
- 68x cheaper than alternatives
- 25-50% fewer tokens
- Hybrid Think/Chat

**Specialized Tasks** ‚Üí Use specialist models
- Qwen3-VL for vision (no alternative)
- Qwen3-Coder for autonomous coding
- Kimi-K2 for autonomous research

### **Fallback Strategies**:

**If Primary Model Fails**:
1. **Qwen3-VL** ‚Üí No fallback (only vision model)
2. **Qwen3-Coder** ‚Üí DeepSeek-V3.1 (cost-efficient coding)
3. **DeepSeek-V3.1** ‚Üí GPT-OSS 120B (explainable reasoning)
4. **Kimi-K2** ‚Üí DeepSeek-V3.1 (tool integration)
5. **GPT-OSS 120B** ‚Üí DeepSeek-V3.1 (hybrid reasoning)
6. **GPT-OSS 20B** ‚Üí GLM-4.6 (fast validation)
7. **GLM-4.6** ‚Üí DeepSeek-V3.1 (pragmatic analysis)

---

## üöÄ IMPLEMENTATION RECOMMENDATIONS

### **For AI Research Daily**:

**Current Issues**:
- Using Kimi-K2 for synthesis ‚úÖ CORRECT
- Using DeepSeek-V3.1 for deep analysis ‚úÖ CORRECT
- Using GPT-OSS 120B for math ‚úÖ CORRECT
- Using GLM-4.6 for alternative ‚úÖ CORRECT
- Using GPT-OSS 20B for validation ‚úÖ CORRECT
- Using Qwen3-VL for vision ‚úÖ CORRECT

**Status**: ‚úÖ **ALREADY OPTIMAL!**

### **For Ollama Pulse**:

**Current Issues**:
- Using DeepSeek-V3.1 for extraction ‚úÖ CORRECT
- Using Kimi-K2 for web search ‚úÖ CORRECT
- Using GPT-OSS 120B for iterative ‚úÖ CORRECT
- Using GPT-OSS 20B for validation ‚úÖ CORRECT
- Using GLM-4.6 for creative ‚úÖ CORRECT

**Status**: ‚úÖ **ALREADY OPTIMAL!**

---

## üìä PERFORMANCE CHARACTERISTICS

| Model | Speed | Cost | Quality | Best For |
|-------|-------|------|---------|----------|
| Qwen3-VL | Medium | High | Excellent | Vision tasks |
| Qwen3-Coder | Medium | Medium | Excellent | Autonomous coding |
| DeepSeek-V3.1 | Fast | Low | Excellent | Balanced workloads |
| Kimi-K2 | Medium | Medium | Excellent | Autonomous research |
| GPT-OSS 120B | Slow | Medium | Excellent | Explainable reasoning |
| GPT-OSS 20B | Fast | Low | Good | High-volume validation |
| GLM-4.6 | Fast | Low | Good | Alternative reasoning |

---

**Status**: ‚úÖ **GUIDE COMPLETE**  
**Conclusion**: Current model assignments are **ALREADY OPTIMAL** based on deep research!

